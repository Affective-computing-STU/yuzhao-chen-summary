# Emotion recognition in conversation(ERC)

2016:

2017:

2018

2019:

2020:

2021:

# Recognizing emotion cause

2016：

2017：

2018：

2019：

2020：

2021：



# Commonsense knowledge

2016：

2017：

2018：

2019：

2020：

2021：

# Self-supervised Learning in conversation

2016:

2017:

2018:

2019:

2020:

2021:

# Affective Computing

2016:

2017:

2018:

2019:

2020:

2021:

# Others (NLP)

2016:

2017:

2018:

1. $SenticNet\;5:\;Discovering\;Conceptual\;Primitives\;for\;Sentiment\;Analysis\;by\;Means\;of\;Context\;Embeddings$$\textcolor{Red}{(AAAI,\;CCF-A)}$

   $\bullet\;Motivation:$

      在自然语言处理领域中，虽然一种自下而上的方法对于模式识别是可行的，但推理和理解通常需要一种自上而下的方法。

   $\bullet\;Method:$

      本文将人工智能领域中统计学习和符号逻辑的方法结合起来，首先设计了一种LSTM模型通过词语替换发现“动词-名词”概念原语，自动从文本中发现概念基元，并将它们与常识性概念和命名实体连接在一个新的三层知识表示框架SenticNet5中，用于情感分析。利用递归神经网络通过词汇替换来推断原语，并通过多维尺度来建立共识和常识。

   $\bullet\;Experimental\;Result:$

      实验主要评估了深度学习方法的性能和SenticNet5作为知识库在情感分析任务中的效果，实验结果表明本文的方法比两个基准线方法都有3%左右的提升。**(Written by Yuzhao Chen)**  [(BibTex)](https://ojs.aaai.org/index.php/AAAI/article/view/11559)

2019:

1. $Interpretation\;of\;Neural\;Networks\;Is\;Fragile$$\textcolor{Red}{(AAAI,\;CCF-A)}$

   $\bullet\;Motivation:$

      为了使机器学习在许多应用程序中得到信任，能够可靠地解释为什么机器学习算法会做出某些预测是至关重要的。出于鲁棒性和安全性的原因，重要的是要知道，对输入数据的微小系统扰动可以在多大程度上改变解释，而这些扰动可能是由对抗或测量偏差产生的。

   $\bullet\;Method:$

      本文演示了如何产生对抗性扰动，这些扰动产生的感知上难以区分的输入被赋予相同的预测标签，但有非常不同的解释。在ImageNet和CIFAR-10上系统地描述了几种常用的特征重要性解释方法(特征重要性图、综合梯度和DeepLIFT)生成的解释的鲁棒性。

   $\bullet\;Experimental\;Result:$

      实验结果表明，系统的扰动可以在不改变标签的情况下导致截然不同的解释。本文将这些结果扩展，以表明基于范例的解释同样容易受到对抗性攻击。对Hessian矩阵几何结构的分析，让我们了解了为什么鲁棒性是当前解释方法的普遍挑战。**(Written by Yuzhao Chen)**  [(BibTex)](https://ojs.aaai.org/index.php/AAAI/article/view/4252)

   

2020:

2021:

1. $Regularizing\;Attention\;Networks\;for\;Anomaly\;Detection\;in\;Visual\;Question\;Answering$$\textcolor{Red}{(AAAI,\;CCF-A)}$

   $\bullet\;Motivation:$

      目前仅有少量研究关注于VQA模型可能会遇到反常/异常场景的问题，本文评估了VQA模型对5种反常场景下的鲁棒性。之前的单模态方法不能从VQA模型的输出的最大置信度答案中检测出输入是否不正常，一些后训练VQA模型输出的方法，例如离群值曝光，也不行。

   $\bullet\;Method:$

      因此，本文提出一种基于注意力的方法，在输入的图像和问题之间进行置信度推理。表明了一种最大正则化的注意力网络能够显著提升基于注意力的VQA模型对于异常场景的检测精度。另外，本文提出的方法可以应用到不同的跨模态注意力VQA模型中，进一步增强了对反常输入的鲁棒性。

   $\bullet\;Experimental\;Result:$

      结果表明，VQA中的跨模态注意不仅对提高VQA的准确性，而且对各种异常的鲁棒性具有重要意义。**(Written by Yuzhao Chen)**  [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-3951.LeeD.pdf)

   

   
