# Emotion recognition in conversation(ERC)

2016:

2017:

2018

2019:

​	1.$Context-aware\;Embedding\;for\;Targeted\;Aspect-based\;Sentiment\;Analysis$$\textcolor{Red}{(ACL,\;CCF-A)}$

​     $\bullet\;Motivation:$

   本文是针对TABSA中，现有的基于注意力机制的神经网络模型虽然取得了较好的效果，但是由于这些方法中表示target和aspect的向量都是随机初始化的，导致在表示目标（target）和方面（aspect）时往往会脱离上下文。

​    $\bullet\;Method:$

   本文提出了一种结合上下文信息优化目标和方面向量表示的方法，该方法可以直接和现有基于神经网络的目标-方面级别情感分析模型相结合。能够通过稀疏系数向量从上下文中选择一组高度相关的词，然后调整目标和方面的表示。因此，可以提取特定目标、对应方面和上下文之间的相互依赖关系，从而生成更好的嵌入。

​	$\bullet\;Experimental\;Result:$

   结果显示本文提出的优化目标和方面向量表示的方法在目标识别和情感分类任务中都取得了更好的表现，在SentiHood和 Semeval两个基准数据集上均取得了更加优秀的成绩，这说明了上下文相关的目标和方面表示能提升模型在细粒度情感分析任务中的效果。**(Written by Yuzhao Chen)**   [(BibTex)](https://arxiv.org/abs/1906.06945)

2020:

​	1.$Context-Guided\;BERT\;for\;Targeted\;Aspect-Based\;Sentiment\;Analysis$$\textcolor{Red}{(AAAI,\;CCF-A)}$

​	$\bullet\;Motivation:$

   在本文中，作者研究了在自我注意模型中加入上下文是否能提高(T)ABSA的表现。

​	$\bullet\;Method:$

   本文提出了两种上下文引导的BERT(CGBERT)的变体，首先是采用上下文感知的Transformer来生成使用上下文引导的softmax-attention的CG-BERT，将之前提出的上下文感知自注意网络扩展到(T)ABSA任务。然后，提出了一种改进的准注意CG-BERT模型(QACG-BERT)，该模型可以学习支持减法注意的合成注意。

​	$\bullet\;Experimental\;Result:$

   在SentiHood和SemEval数据集上，两种模型都取得了更好的表现，两种模型的性能均优于以前的SOTA模型。**(Written by Yuzhao Chen)**    [(BibTex)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Context-Guided+BERT+for+Targeted+Aspect-Based+Sentiment+Analysis&btnG=)

​	2.$Contextualized\;Emotion\;Recognition\;in\;Conversation\;as\;Sequence\;Tagging$$\textcolor{Red}{(ACL,\;CCF-A)}$

​	$\bullet\;Motivation:$

   作者发现关于ERC的预测情绪标签的方法大多会忽略情绪标签之间的内在联系，并且观察到情绪一致性现象广泛存在于对话中，也就是说，相似的情绪更有可能出现，而不是不同的情绪，所以认为对情绪一致性进行建模有助于找到更合理的情绪标签分布，从而进一步提高情绪分类的性能。

​	$\bullet\;Method:$

   作者首次将ERC任务建模为序列标记，并使用CRF来建模对话中的情绪一致性，CRF层利用上文和下文的情感标签来联合解码整个对话的最佳标签序列。应用一个多层Transformer编码器来增强基于LSTM的全局上下文编码器，因为增强的编码器能够捕获长程连续上下文。作者提出了Contextualized Emotion Sequence Tagging（CESTa）模型，首先通过CNN网络获取每个句子的表示 ut ，随后每个句子分别被送入全局编码器（Global Context Encoder）和独立编码器（Individual Context Encoder)，最后全局编码器的结果和局部编码器的结果拼接，经过全连接层送入CRF层产生最终的预测，并选择最大分数的序列作为输出。

​	$\bullet\;Experimental\;Result:$

   本文在三个对话数据集上做了实验，与baseline相比，本文的模型在三个数据集上均取得了SOTA结果，实验表明对情感一致性和远程上下文依赖关系进行建模可以提高情感分类的性能。**(Written by Yuzhao Chen)**   [(BibTex)](https://aclanthology.org/2020.sigdial-1.23/)

​	3.$An\;End-to-End\;Visual-Audio\;Attention\;Network\;for\;Emotion\;Recognition\;in\;User-Generated\;Videos$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

​	$\bullet\;Motivation:$

​	用户生成视频中的情感识别在以人为中心的计算中起着重要的作用。现有的方法主要采用传统的两阶段浅层管道，即提取视觉和/或音频特征，并训练分类器。

​	$\bullet\;Method:$

​	本文提出了一种基于卷积神经网络(CNNs)的端到端视频情感识别方法。开发了一种深度视觉音频注意力网络(VAANet)，这是一种新颖的架构，将空间、渠道和时间注意力集成到可视化3D CNN中，将时间注意力集成到音频2D CNN中。

​	$\bullet\;Experimental\;Result:$

​	所建立的新型V - AANet模型包含了一种新颖的注意机制和一种新颖的交叉熵损失，使用了较少的辅助数据。通过综合考虑各方面的关注，VAANet可以更好地关注具有区别性的关键细分市场及其关键区域。	**(Written by Hao Fu)**      [(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=An+End-to-End+Visual-Audio+Attention+Network+for+Emotion+Recognition+in+User-Generated+Videos&btnG=)

​	4.$Exploiting \; Unsupervised \; Data \; for \; Emotion \; Recognition \; in \; Conversations$ $\textcolor{Red}{(EMNLP,CCF-B)}$

​	$\bullet Motivation:$

​	对话中的情绪识别（ERC）旨在预测对话中说话者的情绪状态，这本质上是一项文本分类任务。 与句子级文本分类问题不同，ERC 任务可用的监督数据是有限的，这可能会阻止模型发挥其最大作用。

​	$\bullet Method:$

​	在本文中，作者提出了一种利用更易于访问的无监督对话数据的新方法。 具体来说，作者提出了 Conversation Completion (ConvCom) 任务，该任务尝试从候选答案中选择正确答案以填充对话中的掩码话语。 然后，作者在 ConvCom 任务上预训练一个基本的上下文相关编码器（PRE-CODE）。 最后，作者在 ERC 的数据集上微调 PRECODE。 

​	$\bullet Experimental \; Result:$

​	这篇文章的实验结果表明，对无监督数据进行预训练可以显着提高 ERC 数据集的性能，尤其是在少数情绪类别上。**(Written by Hongfei Xue)**      [(BibTex)](https://arxiv.org/pdf/2010.01908)

​    5.$CH-SIMS\;A Chinese\;Multimodal\;Sentiment\;Analysis\;Dataset\;with\;Fine-grained\;Annotation\;of\;Modality$$\textcolor{Red}{(ACL,\;CCF-A)}$

​    $\bullet\;Motivation:$

   以往多模态情感分析的研究都是使用有限的数据集，这些数据集只包含统一的多模态注释。然而，统一的注释并不总是反映单一模态的独立情感，并且限制了模型对模态之间差异的捕捉。

​    $\bullet\;Method:$

   本文介绍了一个中文单模态和多模态情感分析数据集CH-SIMS，同时具有多模态和独立的单模态注释。它允许研究人员研究模态之间的相互作用，或者使用独立的单模态注释进行单模态情感分析。此外，本文还提出了一个基于后期融合的多模态多任务学习框架，并在这个框架中引入了三个后期融合模型作为SIMS的强基线。

​    $\bullet\;Experimental\;Result:$

   实验结果表明，在多模态情感分析中引入独立的单模态标注，可以显著提高现有方法的性能，多模态标签不能总是反映单模态的情感状态，统一的多模态标注可能会误导模型学习单模态表征的固有特征。单模态标注可以帮助模型获得更多的差异化信息，提高模态间的互补性。作者还进行了消融实验，发现在进行多任务学习时，不同子任务的学习不同步可能会对多模态情感分析造成不利影响。**(Written by Yuzhao Chen)**  [(BibTex)](https://aclanthology.org/2020.acl-main.343/)

​    6.$A \; Self-Attentive \; Emotion \; Recognition \; Network$$\textcolor{Red}{(ICASSP,CCF-B)}$

​    $\bullet Motivation:$

​    现代深度学习方法在序列数据建模和分类方面取得了突破性进展。特别是，注意力网络构成了捕捉长时间动态的最先进范式。作者探讨了这一范式在二元对话中情绪识别这一具有挑战性的任务中的有效性。

​    $\bullet Method:$

​    作者的工作引入了一种新的注意机制，能够推断出过去的每一次话语对当前说话人情绪状态的巨大影响。所提出的注意机制在不需要解码器网络的情况下执行该推断过程；这是通过创新的自我关注论点实现的。作者提出的自我注意网络捕获了连续编码器网络状态之间的相关模式，从而允许在任意长的时间范围内对时间动态进行稳健而有效的建模。

​    $\bullet Experimental \; Result:$

​    该网络能够在长时间的讨论过程中捕捉强烈的情感模式。在具有挑战性的IEMO、CAP基准上面，作者的方法也具备有效性。**(Written by Hongfei Xue)**[(BibTex)](https://arxiv.org/pdf/1905.01972.pdf)

2021:

​    1.$Towards\; Emotional\; Support\; Dialog \;Systems  $ $\textcolor{Red}{(ACL,\;CCF-A)}$

​     $\bullet\;Motivation :$

​	在对话系统中能提供情绪支持是十分重要的，但是目前来说，之前的研究基本是关注如何对于该会话做出合理的回应，但是并不考虑该回应是否可以帮助到对方，而且，由于缺乏好的任务设计和有效的情绪支持对话语料库，现有研究依旧没有将情绪支持融入对话系统。

​     $\bullet\;Method :$

​	 本文定义了情绪支持对话任务（ESC）和基于Hill的帮助技巧理论提出ESC框架，此外还构建了一个情绪支持对话数据集(ESConv)。以Hill理论为核心模拟人类与朋友，家人等的交互关系而不是直接采取专业咨询过程，这有利于普通情绪分析。其中包括三个状态：探索，安慰和行动；每一个状态又包含了多个支持略，状态顺序可以根据个人对话需要而变化，而不是固定的探索，安慰然后行动。策略有9种，包括提问，重述，建议等，在不同状态，采用这些策略去达成目的，比如探索阶段，可以通过提问获取更多信息，或者重述对方问题以刺激对方真实想法等策略去明确对方的问题是什么，有利于后面的安慰和行为状态。最后还有情绪评估的方法，通过情绪强度值去判断我们的行为是否对help-seeker有帮助。

​     $\bullet Experimental \; Result:$

​	实验结果表示，对于数据集（ESConv):评估它能对经典生成式对话模型（以BlenderBot和DialoGPT作为预训练模型，Vanilla和Variants with strategy作为变体）提高多少性能，结果显示该数据集对于生成式对话性能提升帮助很大，此外这些模型能从ESConv数据集中学习到如何提供有效的情绪支持。 **(Written by  Wenhua Zhu)**[(BibTex)](https://aclanthology.org/2021.acl-long.269.pdf)

2.$Learning\; Modality-Specific\; Representations \;with \;Self-Supervised \;Multi-Task \;Learning \;for \;Multimodal \;Sentiment\; Analysis$$\textcolor{red}{(AAAI,\;CCF-A)}$

​    $\bullet\;Motivation :$

​	表示学习是多模态学习中一项重要且具有挑战性的任务，有效的模态表示应该包含一致性和差异性两部分特征。由于统一的多模态注释，现有方法在捕获差	异化信息方面受到限制。然而，额外的单模态注释是高时间和劳动力成本。

​    $\bullet\;Method :$

​	在表示学习的指引差异中主要分为前向和后向，本文主要关注后向指引。基于标签差异和模态表示与类中心的距离差异是绝对相关的，和单模态标签与多模  态标签有关两个方面，本文设计了一个基于自监督学习策略的标签生成模块来获得独立的单模态监督；联合训练多模态任务和单模态任务，分别学习一致性和差异性；在训练阶段，设计了权重调整策略来平衡不同子任务之间的学习进度，即引导子任务专注于模态监督差异较大的样本。

​    $\bullet\;Experiment \;Result$

​	对三个公共多模态基线数据集进行了广泛的实验。实验结果验证了自动生成的单模态监督的可靠性和稳定性。在MOSI和MOSEI数据集上，本文的方法超越了 	当前最先进的方法。在SIMS数据集上，本文方法实现了与人工注释的单模态标签相当的性能。 **(Written  by  Wenhua Zhu)**[(BibTex)](https://www.researchgate.net/publication/349159330_Learning_Modality-Specific_Representations_with_Self-Supervised_Multi-Task_Learning_for_Multimodal_Sentiment_Analysis)

3.$Bridging\; Towers\; of\; Multi-task\; Learning\; with \;a \;Gating\; Mechanism\; for\; Aspect-based\; Sentiment \;Analysis\; and\; Sequential$ 		  		$Metaphor\; Identification  $ $\textcolor{red}{(AAAI,\; CCF-A)}$

​    $\bullet\; Motivation :$

​	多任务学习（MTL）已广泛应用于自然语言处理，一个主要任务及其相关的辅助任务共享同一个编码器；因此，MTL编码器可以学习主要任务和副主任吴之间共享抽象信息。然后在共享编码器上使用特定于任务的塔来学习特定于任务的信息。以前的工作表明，在特定的塔之间交换信息会产生额外的收益，这被称为软参数共享MTL。

​     $\bullet\; Method :$

​	 本文中提出了一种用于桥接 MTL 塔的新型门控机制， 对Aspect-Based 的情感分析和顺序隐喻识别任务进行评估。框架结构：首先采用BERT对输入序列编码获取共享隐藏状态，对于三个子任务（aspect,opinion,sentiment提取)，首先用Transformer作为具体任务塔，接来了是一系列由桥和transformer组成的块, 这其中的每一层，三个任务之间的信息在桥之间传递，其中以同列的位主要任务，另外两列为辅助任务进行学习，获取额外的收益，如下图所示<img src="D:\桌面\21-汕头大学\研究生科研\先冲在说\图片\MTL.png" alt="MTL" style="zoom:75%;" />，序列隐喻识别任务的流程也是一样的架构。

​     $\bullet\;Experiment \;Result :$

​      在两个任务上都可以产生比基线更好的性能。基于相同的 Transformer 主干，本文将门控机制与其他信息转换机制进行了比较，例如十字绣、注意力和香草门	控。实验表明，本文的方法也超越了这些基线。 **(Written  by  Wenhua Zhu)**[(BibTex)]([Bridging Towers of Multi-task Learning with a Gating Mechanism for Aspect-based Sentiment Analysis and Sequential Metaphor Identification | Proceedings of the AAAI Conference on Artificial Intelligence](https://ojs.aaai.org/index.php/AAAI/article/view/17596))

4. $A \;Joint\; Training\; Dual-MRC\; Framework \;for\; Aspect \;Based \;Sentiment\; Analysis$ $\textcolor{red}{(AAAI,\;CCF-A)}$

​     $\bullet\;Motivation :$

​	 Aspect-Based 的情感分析 (ABSA) 涉及三个基本子任务：aspect term extraction, opinion term extraction, and aspect-level sentiment classification。前期的工作只专注于单独解决这些子任务之一。最近的一些工作侧重于解决两个子任务的组合，例如，aspect term extraction 以及 sentiment polarities or extracting the aspect and opinion terms pair-wisely。最近提出了三元组提取任务，即从句子中提取（方面项、意见项、情感极性）三元组。然而，以前的方法无法在统一的端到端框架中解决所有子任务。

​    $\bullet\;Method :$

​	  为 ABSA 提出了一个完整的解决方案。本文构建了两个机器阅读理解（MRC）问题，并通过联合训练两个共享参数的 BERT-MRC 模型来解决所有子任务，如下图所示![Dual-MRC](D:\桌面\21-汕头大学\研究生科研\先冲在说\图片\Dual-MRC.png)左边提取出输入文本中所有的方面项，右边提取出意见项，并根据左边提取的方面项获取情感极性。

​    $\bullet\;Experiment\;Result :$

​	本文对这些子任务进行了实验，在几个基准数据集上的结果证明了本文提出的框架的有效性，它明显优于现有的最先进方法。 **(Written  by  Wenhua Zhu)**[(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-5353.MaoY.pdf)

​	5.$Contrastive\;Adversarial\;Learning\;for\;Person\;Independent\;Facial\;Emotion\;Recognition$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

​      $\bullet\;Motivation:$

​	大多数人脸情绪识别方法显著依赖于监督信息，在独立于人进行情绪分析方面存在一定的局限性。另一方面，对抗学习是一种众所周知的广义表示学习方法，因为它不需要监督信息。

​     $\bullet\;Method:$

​	作者提出了一种新的对抗学习方法。通过基于强情绪样本的对抗性学习弱情绪样本，使得FER网络能够更好地理解强情绪中蕴含的复杂情绪元素。并且提出了一个有效对抗学习的对比损失函数。

​    $\bullet\;Experimental\;Result:$

​	传统方法试图通过改进CNN来提高AV域FER的性能，而作者提出的方法则侧重于通过对抗性学习来学习情绪变化的程度。本文研究将对目前只关注网络结构的研究具有很大的启示意义。	**(Written by Hao Fu)**      [(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Contrastive+Adversarial+Learning+for+Person+Independent+Facial+Emotion+Recognition&btnG=)

​    6.$Distributed\;Representations\;of\;Emotion\;Categories\;in\;Emotion\;Space$$\textcolor{Red}{(ACL,\;CCF-A)}$

​    $\bullet\;Motivation:$

   现有的情绪检测研究主要致力于提升模型预测的准确度，情感类别通常被表示为one-hot向量形式，但是，这种表示方式会忽略情感类别之间的关联。

​    $\bullet\;Method:$

   因此，为了更好的表达情感关系，本文提出了一个框架，可以从给定的情感分类数据集学习情感空间中情感类别的分布式表示。此外，基于预训练神经网络模型预测的软标签，给出了一种简单有效的算法。

​    $\bullet\;Experimental\;Result:$

   实验结果表明，本文的方法在情感空间中的表征比在单词嵌入中的表征能更好地表达情感关系。**(Written by Yuzhao Chen)**  [(BibTex)](https://aclanthology.org/2021.acl-long.184/)

​    7.$Context-Guided\; BERT\; for \;Targeted \;Aspect-Based \;Sentiment\; Analysis$$\textcolor{red}{(AAAI,\;CCF-A)}$

​	$\bullet\;Motivation :$

​	Aspect-Based 的情感分析 (ABSA) 和有针对性的 ASBA (TABSA) 允许根据上下文从同一文本中对情感进行更细粒度的推断。例如，给定的文本可以有不同的目标和不同的 Aspect （例如，价格或安全），每个目标-Aspect 对关联不同的情绪。

​	$\bullet\; Methods :$

​	本文研究了向自注意力模型添加上下文是否可以提高 (T)ABSA 的性能。提出了上下文引导的 BERT (CG-BERT) 的两种变体，它们学习在不同的上下文中分配注意力。首先采用上下文感知 Transformer 来生成使用上下文引导的 softmax-attention 的 CG-BERT。接下来，提出了一种改进的 Quasi-Attention CG-BERT 模型，该模型学习支持减法注意力的组合注意力。

​	$\bullet\; Experiment\; Result :$

​	本文在两个 (T)ABSA 数据集上使用预训练的 BERT 训练两个模型：SentiHood 和 SemEval-2014（任务 4）。其中 QACG-BERT 模型具有最佳性能，这两种模型都取得了最新的最新结果。此外，还分析了本文提出的模型中上下文的影响。本文的工作为将上下文相关性添加到基于上下文的自然语言任务的预训练的基于自我注意的语言模型的效用提供了更多证据。 **(Written  by  Wenhua Zhu)**[(BibTex)]([PRELIMINARY VERSION DO NOT CITE (aaai.org)](https://www.aaai.org/AAAI21Papers/AAAI-7955.WuZ.pdf))

​    8.$Quantum \;Cognitively\; Motivated\; Decision\; Fusion\; for\; Video\; Sentiment\; Analysis$$\textcolor{red}{(AAAI,\;CCF-A)}$

​	$\bullet\;Motivation :$

​	视频情感分析作为一个决策过程本质上是复杂的，涉及来自多种模式的决策和由此引起的认知偏差的融合。受量子认知最新进展的启发，我们表明来自一种模态的情绪判断可能与来自另一种模态的判断不相容，即顺序很重要，它们不能联合测量以产生最终决定。因此，认知过程表现出经典概率理论无法捕捉到的“类量子”偏差。

​	$\bullet\; Methods :$

​	提出了一种全新的、量子认知驱动的融合策略，用于预测情绪判断。特别是，我们将话语表述为正面和负面情绪判断的量子叠加态，并将单模态分类器表述为互不相容的可观察量，在复值希尔伯特空间中，具有正运算符值度量。

​	$\bullet\; Experiment\; Result :$

​	在两个基准数据集上的实验表明，本文的模型明显优于各种现有的决策级别和一系列最先进的内容级别融合方法。不兼容的概念允许有效处理所有组合模式，包括那些被所有单模态分类器错误预测的极端情况。 **(Written  by  Wenhua Zhu)**[(BibTex)]([Quantum Cognitively Motivated Decision Fusion Framework for Video Sentiment Analysis - Qiuchi Li](https://qiuchili.github.io/publication/aaai20-2))

​    9.$BoB:\; BERT\; Over \;BERT\; for\; Training\; Persona-based\; Dialogue\; Models \;from\; Limited\; Personalized \;Data$$\textcolor{red}{(ACL,\;CCF-A)}$

​	$\bullet\;Motivation :$

​	对话中的人设（Persona）代表某个说话者的身份元素的组合，例如个人资料和背景个人事实。在对话生成中，传统模型难以保证生成的回复符合预设的人设。同时，现有的社交媒体对话中人设信息较少，如推特上不到10%的消息会透露个人轶事或在家或工作中的活动，甚至更少的个人身份信息。因此在有限的个性化数据上训练的模型无法充分理解人设的一致性。

​	$\bullet\; Methods :$

​	作者提出了BERTover-BERT (BoB) 模型。该模型由一个编码器和两个解码器构成。其中编码器是一个标准的 BERT 模型；解码器 D1 是响应生成解码器，由 BERT 和随机初始化的编码器-解码器注意力层构成；解码器 D2 是一致性理解解码器，也是一个标准的 BERT 模型。Bob主要包含两类训练数据，一类是带人设的对话数据 (P，Q，R)，分别代表人设 Persona、上下文查询 Query、响应 Response；另一类是非对话推理数据 (D+, D-)，其中D由前提和假设构成，D+代表正样本（即“假设”是符合“前提”的），而D-代表负样本。训练时，E和D1组成了一个标准的 Transformer 模型，使用正常的带人设的对话数据可以计算得到负对数似然L1；D2则在D1的基础上，使用了两次 self-attention，第一次得到自身和人设 P（不包含Q）的注意力表示，然后再得到自身和D1的隐藏层输出的注意力表示，那么带有人设和D1输出的特征作为D2的输出层表示。

​	$\bullet\; Experiment\; Result :$

​	作者分别报告了在 PersonaChat 和 PersonalDialog 测试集上的评价指标，从表3中可以看出，BoB模型在所有的指标都显著优于基线模型。从表5中可以看出，BoB模型随机测试集中的一致性指标没有明显优于基线模型，但是另外制作的一个有偏测试集中的所有指标都明显优于基线模型。作者猜想这是因为 PersonalDialog 中的人设是比较稀疏的，所以人工挑选的有偏测试集特意筛选了部分带人设的子集。从表4中可以看出，BoB模型在低资源的条件下仍然表现优秀，只需要八分之一的训练数据模型表现即可超过基线模型。表5中的消融分析可以看出，BoB的编码器和两个解码器都是有效的，减少其中的组件将降低模型性能。 **(Written  by  Wenhua Zhu)**[(BibTex)]([[2106.06169\] BoB: BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data (arxiv.org)](https://arxiv.org/abs/2106.06169))



10.$Quantum-inspired\;Neural\;Network\;for\;Conversational\;Emotion\; Recognition$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

​      $\bullet\;Motivation:$

​	作者提供了一个新的视角，对话情绪识别的类比之间的任务和一个完整的量子化测量。我们描述了在对话中识别说话人情绪的过程中，量子测量的不同步骤，并将它们与一个量子类神经网络缝合起来。

​     $\bullet\;Method:$

​	作者借用现有的算法来学习复值网络权值，使类量子过程以数据驱动的方式进行。我们的模型在两个基准数据集上可以与最先进的方法相比较，并提供了一个理解对话情绪识别的量子观点。

​    $\bullet\;Experimental\;Result:$

​	本研究为对话情绪识别问题提供了一个新的量子视角。构建了一个完整的量子激发网络，融合多模态数据，构建会话上下文，并在此基础上识别每一个话语的情感。	**(Written by Hao Fu)**     [(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Quantum-inspired+Neural+Network+for+Conversational+Emotion+Recognition&btnG=)



11. $Inferring\;Emotion\;from\;Large-scale\;Internet\;Voice\;Data:\;A\;Semi-supervised\;Curriculum\;Augmentation\;based\;Deep\;Learning\;Approach$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

​      $\bullet\;Motivation:$

​	从用户查询中进行有效的情感推理有助于语音对话应用程序(VDAs)提供更人性化的响应。大量的VDA用户带来了不同的情感表达。如何在vda中实现大规模互联网V语音数据的高情绪推断性能?传统的语音情感识别研究是基于行为语音数据集进行的，该数据集的说话人数量有限，但情感表达强烈而清晰。

​     $\bullet\;Method:$

​	作者提出了一种利用具有强烈情绪表达的行为语音数据来增强具有不同情绪表达的大规模无标签网络语音数据来进行情绪推断的新方法。具体来说，我们提出了一种新的半监督多模态课程强化深度学习框架。

​    $\bullet\;Experimental\;Result:$

​	设计了一种基于课程学习的划时代训练策略，它训练作者的模型，该模型由来自行动语音数据的强而平衡的情绪样本引导，然后利用来自互联网语音数据的弱而不平衡的情绪样本。然后，利用Realworld数据集的大规模无标记数据，引入多路径混合匹配多模态深度神经网络(MMMD)，以混合半监督方法有效地训练有标记和无标记数据，具有较好的泛化和鲁棒性。	**(Written by Hao Fu)**     [(BibTex)](https://ojs.aaai.org/index.php/AAAI/article/view/16753)

# Recognizing emotion cause

2016：

2017：

2018：

2019：

2020：

2021：

​    1.$Emotion-Infused\;Models\;for\;Explainable\;Psychological\;Stress\;Detection$ $\textcolor{Red}{(NAACL,\;CCF-C)}$

​    $\bullet\;Motivation:$

​	在网络帖子中检测心理压力的问题，更广泛地说，检测处于困境或需要帮助的人的问题，是一个敏感的应用，其中解释模型的能力至关重要。    

​    $\bullet\;Method:$

​	作者提出了一项工作，探索使用一个语义相关的任务，情绪检测，与黑箱模型相比，同样有能力，但更可解释和类似人类的心理压力检测。特别是，作者探索了多任务学习的使用以及基于情感的语言模型微调。

​    $\bullet\;Experimental\;Result:$

​	作者提出了一套情绪增强模型，以不同的方式纳入情绪信息，以增强二元压力预测任务。提出的所有三种模型都实现了与最先进的微调BERT基线相当的性能，而且，更重要的是，我们展示了它们导致了更可解释的模型。	**(Written by Hao Fu)**	[(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=%24Emotion-Infused%5C%3BModels%5C%3Bfor%5C%3BExplainable%5C%3BPsychological%5C%3BStress%5C%3BDetection&btnG=)

# Commonsense knowledge

2016：

2017：

2018：

2019：

1. $KagNet:\;Knowledge-Aware\;Graph\;Networks\;for\;Commonsense\;Reasoning$ $\textcolor{Red}{(EMNLP,\;CCF-B)}$

   $\bullet\;Motivation:$

      针对很多有关机器推理的数据集，常识推理的任务就是从候选答案集合中选择正确的。由于错误答案通常也和上下文相关，所以增大了推理的难度。

   $\bullet\;Method:$

      作者提出一种用于回答常识问题的文本推理框架，该框架使用外部的结构化知识库，用来增强推理结果的可解释性。该框架首先根据Q&A pair从外部知识库中获取子图shema graph。然后使用本文提出的框架KagNet（Knowledge-aware Graph Network）对shema graph进行表示学习，并利用该representations对答案进行评分。KagNet基于GCN和LSTMs，并结合了基于路径的分层注意力网络。使用注意力机制产生的中间注意力得分，让推理过程更加具有可解释性。

   $\bullet\;Experimental\;Result:$

      该论文使用ConceptNet作为外部知识库，在问答（推理）数据集CommonsenseQA上取得了SOA效果。**(Written by Weilun Yu)**  [(BibTex)](https://static.aminer.cn/storage/pdf/arxiv/19/1909/1909.02151.pdf)


2020：

1. $Graph-Based\;Reasoning\;over\;Heterogeneous\;External\;Knowledge\;for\;Commonsense\;Question\;Answering$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

   $\bullet\;Motivation:$

      常识问答往往需要没有在问题中显著表达的背景知识，即如何从外部知识中获取证据并根据证据做出预测。

      来自结构化的知识源包含概念之间的结构关系，对于推理很有帮助，但是它们的覆盖率低。而纯文本知识源是对结构化知识的补充，可以提供丰富且覆盖面广的证据。最近的研究还没有同时利用这两类知识源进行推理的，因此在这项工作中，自动从这两个异构知识源中提取证据，并根据提取的证据回答问题。

   $\bullet\;Method:$

      分为知识提取和基于图的推理两个部分。知识提取：根据给定的问题和选项，从ConceptNet中自动提取图路径，从维基百科纯文本中自动提取句子，再为两种知识源分别构建图。基于图的推理：包含两个模块，基于图的上下文表示学习模块和基于图的推理模块。

   $\bullet\;Experimental\;Result:$

      使用CommonsenseQA数据集进行了实验。实验证实了结合使用ConceptNet和Wikipedia效果得到了很大的提升，说明异构知识源的性能要优于单个知识源和不同知识源。  **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/pdf/1909.05311.pdf)

   

2. $PIQA:\;Reasoning\;about\;Physical\;Commonsense\;in\;Natural\;Language$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

   $\bullet\;Motivation:$

      作者希望人工智能系统能够在不经历物理世界的情况下可靠地回答物理常识问题，捕获有关日常物品的常识知识，包括它们的物理特性、承受能力以及如何操纵它们。因此设计了一个关于物理常识推理任务和相应的基准数据集 PIQA（Physical Interaction： Question Answering）进行评估。

   $\bullet\;Method:$

      PIQA 数据集由 16,000 多个训练的 QA 对组成，另外分别提供了约 2K 和 3K 进行开发和测试。目的长度平均为 7.8 个单词，正确和不正确的解决方案平均长度为 21.3  个单词，正确和不正确解决方案所使用的单词之间至少有 85%  的重叠。通过对名词，动词，形容词，副词出现的词频统计，验证了数据集确实是和物理现象强相关的。比如，出现词频最高的形容词中包括状态（干燥的、干净的、烫的），形状（小的、锋利的、平坦的），形式（快速的、仔细的），这些属性通常决定了解决方案的正确与否。

   $\bullet\;Experimental\;Result:$

      作者在 GPT ，BERT 和 RoBERTa 模型上进行了实验测试，结果表明最好的模型距离人类仍有差不多20%的差距（GPT 69.2%, BERT 66.8%, RoBERTa 77.1%。人类是94.9%。）    **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/pdf/1911.11641.pdf)

2021：

# Self-supervised Learning in conversation

2016:

2017:

2018:

2019:

2020:

​	1.**$Latent\;Emotion\;Memory\;for\;Multi-Label\;Emotion\;Classification$ $\textcolor{Red}{(AAAI,\;CCF-A)}$**

​	$\bullet\;Motivation:$

​	现有的方法通常将问题建模为多标签分类任务。然而，以前的方法有两个问题，限制了任务的性能。首先，这些模型没有考虑句子中先前的情绪分布。二是不能有效地捕捉到与相应情绪密切相关的情境信息。

​	$\bullet\;Method:$

​	本文提出了一种用于多标签情绪分类的潜在情绪记忆网络(LEM)。该模型可以在不需要外部知识的情况下学习潜在情绪分布，并有效地将其引入分类网络。

​	$\bullet\;Experimental\;Result:$

​	在两个数据集上的结果显示，作者的模型优于强大的基线，实现了最先进的性能，证明了为任务建模丰富的情绪相关性的有用性。	**(Written by Hao Fu)**       [(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Latent+Emotion+Memory+for+Multi-Label+Emotion+Classification&btnG=)

​    2.$Self-supervised \; Learning \; for \; ECG-based \; Emotion \; Recognition$$\textcolor{Red}{(ICASSP,CCF-B)}$

​    $\bullet Motivation:$

​    作者意图使用自监督学习且基于心电图 (ECG) 的来进行情绪识别。

​    $\bullet Method:$

​     作者提出的架构由两个主要网络组成，一个信号转换识别网络和一个情感识别网络。首先，在自监督学习步骤中，使用未标记的数据成功地训练前一个网络来检测特定的预先确定的信号转换。接下来，该网络的卷积层的权重被转移到情感识别网络，并训练两个密集层以对唤醒和效价分数进行分类。

​    $\bullet Experimental \; Result:$

​     作者提出的自监督方法有助于模型学习情感识别所需的 ECG 特征流形，其性能与模型的完全监督版本相同或更好。作者提出的方法通过两个公开可用的数据集 SWELL 和 AMIGOS 在基于 ECG 的情绪识别方面优于最先进的方法。进一步的分析突出了本文自我监督方法的优势，即需要更少的数据来获得可接受的结果。**(Written by Hongfei Xue)**[(BibTex)](https://static.aminer.cn/storage/pdf/arxiv/19/1910/1910.07497.pdf)

3.$SELF-SUPERVISED \; ADVERSARIAL \; TRAINING$$\textcolor{Red}{(ICASSP,CCF-B)}$

​	$\bullet Motivation:$

   最近的工作表明，神经网络容易受到对抗样本的影响。为了摆脱困境，许多工作尝试以各种方式强化模型，其中对抗性训练是学习鲁棒特征表示以抵抗对抗性攻击的有效方法。同时，自监督学习旨在从数据本身中学习鲁棒性和语义嵌入。基于这些观点，作者在本文中引入了针对对抗性示例的自监督学习。

​	$\bullet Method:$

   作者提出了结合 k-最近邻的自监督表示进行分类。为了进一步加强防御能力，提出了自监督对抗训练，最大化原始示例和相应对抗示例之间的互信息。

​	$\bullet Experimental \; Result:$

   实验结果表明，自监督表示在鲁棒性方面优于其监督版本，自监督对抗训练可以进一步有效地提高防御能力**(Written by Hongfei Xue)**[(BibTex)](https://static.aminer.cn/storage/pdf/arxiv/19/1911/1911.06470.pdf)     

2021:

​	1.$Self-Supervised \; Test-Time \; Learning \; for \; Reading \; Comprehension$ $\textcolor{Red}{(NAACL,CCF-C)}$		

​	$\bullet Motivation:$

​	1)常见的QA模型在回答问题时依赖于所使用的训练数据集，而在所提供的数据集当中有些信息可能会随着时间的推移发生改变，这就会导致模型输出错误的结果。 

​	2)与此同时，有监督的QA模型在对抗性样本(adversarial example)、域外样本(domain shift out of domain)和含有偏见(bias)的样本上表现很差。

​	3)阅读理解任务需要大规模标注，成本较高。 

​	$\bullet Method:$

​	作者提出了一种无监督方法“test-time learning” (TTL)来完成阅读理解任务。让模型在进测试(预测)时根据问题的context上下文，通过自我监督的形式合成训练所需要的问答对，从而进行无监督式的学习，省去了在训练集上的训练过程。

​	$\bullet Experimental \; Result:$

​	提出了Test-time-learning（TTL），一种无监督抽取式问答的训练框架。并根据训练和上下文扩展方法的不同给出了TTL的四个变体，其中使用K-neighboring contexts of the test context方法效果最好。使用四种问答对生成方法进行无监督的抽取式阅读理解模型训练，其中使用QA-SRL作为问答对的生成方法效果最好。文中还比较了大模型（BERT-large）和小模型（DistilBERT)的效果，结果显示两者之间差距不大。**(Written by Hongfei Xue)** [(BibTex)](https://arxiv.org/pdf/2103.11263)

​	2.$Self-supervised \; Bilingual \; Syntactic \; Alignment \; for \; Neural \; Machine \; Translation$ $\textcolor{Red}{(AAAI,CCF-A)}$

​	$\bullet Motivation:$

​	虽然各种神经机器翻译 (NMT) 方法已将单语言句法知识集成到序列的语言表示中，但尚无关于将目标语言的句法结构与相应的源语言句法结构对齐的研究

​	$\bullet Method:$

​	基于 NMT 的词对齐，我们的 SyntAligner 首先对齐源句和目标句的句法结构，然后通过在它们的互信息上引入下限来最大化它们的相互依赖性。在 SyntAligner 中，跨度粒度的句法结构通过将源或目标词隐藏状态转换为源或目标句法跨度向量来表示。边界敏感的跨度注意机制然后捕获源和目标句法跨度向量之间的相关性，它还捕获跨度边界词之间的自我注意作为对齐偏差。最后，基于自监督双语句法互信息最大化的学习目标动态采样对齐的句法跨度以最大化它们的相互依赖性。

​	$\bullet Experimental \; Result:$

​	虽然单语言句法知识已被广泛用于 NMT 任务，但一个开放的挑战是在经典的序列到序列建模中表征源和目标句法结构之间的依赖关系。 作者向前迈进了一步，不仅对齐双语句法结构，还引入了基于自监督互信息最大化的训练目标，结合传统的监督交叉熵训练目标，实现了基于双语句法一致性的翻译。**(Written by Hongfei Xue)** [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-452.ZhangT.pdf)

​    3.$Learning\;Modality-Specific\;Representations\;with\;Self-Supervised\;Multi-Task\;Learning\;for\;Multimodal\;Sentiment\;Analysis$$\textcolor{Red}{(AAAI,\;CCF-A)}$

​    $\bullet\;Motivation:$

   由于多模态标注只能给三个模态定一个统一的标签，现有的方法在获取差异化信息方面受到限制。但是，额外的单模态注释会带来很高的时间和劳动力成本。

​    $\bullet\;Method:$

   本文基于自监督学习策略设计了标签生成模块用于获得每一个单独模态的标签，并且联合多模态和单模态学习任务分别学习一致性和不同性。另外，还在训练阶段设计了权重调节策略来平衡不同子任务之间的学习进展，这是为了指导子任务将重点放在模态之间差异较大的采样上。

​    $\bullet\;Experimental\;Result:$

   本文在MOSI和MOSEI数据集上做了实验，实验结果证明本文的方法优于当前SOTA方法，并且在具有人工标注的SIMS数据上，验证了该方法取得了与人工标注的单模态标签相当的性能。**(Written by Yuzhao Chen)**  [(BibTex)](https://arxiv.org/abs/2102.04830)

​    4.$Learning \; Modality-Specific \; Representations \; with \; Self-Supervised \; Multi-Task Learning \; for \; Multimodal \; Sentiment \; Analysis$$\textcolor{Red}{(AAAI,CCF-A)}$

​	$\bullet Motivation:$

​    有效的模态表示应该包含两部分特征：一致性和差异性。由于统一的多模态注释，现有方法在捕获差异化信息方面受到限制。然而，额外的单模态注释是高时间和劳动力成本。

​	$\bullet Method:$

​    在本文中，作者设计了一个基于自监督学习策略的标签生成模块来获得独立的单峰监督。然后，联合训练多模态和单模态任务，分别学习一致性和差异性。此外，在训练阶段，作者设计了权重调整策略来平衡不同子任务之间的学习进度。即引导子任务专注于模态监督差异较大的样本。

​	$\bullet Experimental \; Result:$

​    作者设计了一种基于自监督方法的单峰标签生成策略，节省了大量人力成本。 大量实验验证了自动生成的单峰标签的可靠性和稳定性，这为多模态表示学习提供一个新的视角。但是在生成的音频和视觉标签受预处理特征的限制不够显着，所以单模态和多模态学习之间的关系还需要继续探索。**(Written by Hongfei Xue)**[(BibTex)](https://arxiv.org/pdf/2102.04830)

# Others (NLP)

2016:

2017:

2018:

2019:

1.$Utilizing \; BERT \; for \; Aspect-Based \; Sentiment \; Analysis \; via \; Constructing \; Auxiliary \; Sentence$$\textcolor{Red}{(NAACL,CCF-C)}$

​	$\bullet Motivation:$

   最近，预训练的语言模型，已经显示出它们在缓解特征工程的努力。 尤其是BERT在QA和NLI方面取得了优异的成绩。 然而，直接使用预训练的 BERT 模型在ABSA 任务中并没有太大的改进。 我们认为这是由于对预训练的 BERT 模型使用不当造成的。

​	$\bullet Method:$

   BERT 的输入表示既可以表示单个文本句子，也可以表示一对文本句子，可以将ABSA 转换为句子对分类任务，并对预训练的 BERT 进行微调。

​	$\bullet Experimental \; Result:$

   提出了ABSA（细粒度情感分析任务）的新解决方案，将其转换为句子对分类任务。对预训练的 BERT 模型进行了微调，并在 SentiHood 和 SemEval-2014 任务 4 数据集上取得了最新的最新成果。**(Written by Hongfei Xue)**[(BibTex)](https://arxiv.org/pdf/1903.09588.pdf)



2020:

1.$Enhancing\;Extractive\;Text\;Summarization\;with\;Topic-Aware\;Graph\;Neural\;Networks$ $\textcolor{Red}{(COLING,\;CCF-B)}$

$\bullet\;Motivation:$

   现有的摘要抽取模型很难捕捉到内部关系，尤其是在长文档中。同时经常忽略主题信息对获取重要内容的影响。基于此，作者提出一种基于图神经网络的抽    取摘要模型，能够通过图结构的文档表示来有效地捕获内容间的关系。

$\bullet\;Method:$

   模型由三部分组成，1) document encoder文档编码器, 2) neural topic model神经主题模型,3) graph  attention  layer图形注意层。文档编码器是在给定输入文档的情况下，通过预训练的BERT学习每个句子的上下文表示。神经主题模型用来学习文档主题分布和一组主题表示。图形关注层构建一个包含主题和句子的异构文档图，然后同时更新它们的节点表示。在图形编码后，句子表示进一步与主题结合，然后发送到句子分类器来计算最终的标签。

$\bullet\;Experimental\;Result:$

   在四个数据集上进行了实验，模型在新闻文章数据集上取得了与最先进的摘要模型相当的结果，在科学论文数据集上显著优于现有的方法，表明它在各种文档类型和长度上具有很强的鲁棒性。   **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/ftp/arxiv/papers/2010/2010.06253.pdf)

2.$Where\;to\;Go\;Next:\;Modeling\;Long-\;and\;Short-TermUser\;Preferences\;for\;Point-of-Interest\;Recommendation\;$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

 $\bullet\;Motivation:$

​	本文作者指出现有基于rnn的方法在对用户的短期偏好建模时，要么忽略了用户的长期偏好，要么忽略了最近访问的Point-of-Interest (POI)之间的地理关系，导致推荐结果不可靠。

 $\bullet\;Method:$

​	本文提出了一种基于长短期偏好模型( Long- and Short-Term Preference Mod-eling (LSTPM))的下一个(POI)推荐方法。特别地，该模型由一个用于长期偏好建模的非局部网络和一个用于短期偏好学习的地理扩张RNN组成。

 $\bullet\;Experimental\;Result:$

​	与现有的推荐方法相比，作者在本文中提出的方法大大提高了推荐的精度。虽然作者提出的方法优于所有基线，但是低回忆的NDGG分数仍是POI推荐中的一个共同问题。	**(Written by Hao Fu)**      [(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Where+to+Go+Next%3A+Modeling+Long-+and+Short-Term+User+Preferences+for+Point-of-Interest+Recommendation&btnG=)

3.$A\;Co-Interactive\;Transformer\;for\;Joint\;Slot\;Filling\;and\;Intent\;Detection$ $\textcolor{Red}{(ICASSP,\;CCF-B)}$

 $\bullet\;Motivation:$

​	意图检测和插槽填充是构建口语理解系统的两个主要任务。这两个任务是密切相关的，一个任务的信息可以在另一个任务中利用。以往的研究要么分别模拟两个任务，要么只考虑从意图到槽的单一信息流。

  $\bullet\;Method:$

​	作者提出了一个协同互动变压器，以考虑两个任务之间的交叉影响。提出了一个协同交互模块，通过建立两个相关任务之间的双向连接来考虑交叉影响，而不是采用普通Transformer中的自注意机制。

  $\bullet\;Experimental\;Result:$

​	作者提出了一个联合模型槽填充和意图检测的协同交互转换器，以建立两个任务之间的方向连接，从而充分利用相互交互的知识。此外，所提出的协同交互模块可以进行堆叠，逐步更好地模拟相互之间的交互。	**(Written by Hao Fu)**      [(BibTex)](https://ieeexplore.ieee.org/abstract/document/9414110)

4.$Two-Level\;Transformer\;and\;Auxiliary\;Coherence\;Modeling\;for\;Improved\;Text\;Segmentation$ $\textcolor{Red}{(AAAI, \;CCF-A)}$

$\bullet\;Motivation:$

   文本的连贯性与文本的分割具有本质上的紧密联系，分割后同一部分的文本之间的连贯性强于不同部分的文本。依据语义连贯性解构长文本能够提升文本的可读性，有益于下游任务，而现存的文本分割方法都仅仅隐式的使用连贯性这项特征。作者希望提出一种监督模型除了以预测分割结果作为目标以外，还能对连贯性进行建模并应用在训练过程中。

$\bullet\;Method:$

   由两层Transformer构成的监督模型，低层编码句子，高层编码句子序列。接收定长句子序列作为输入，字符编码由预训练词嵌入和位置嵌入连接得到。句子序列首先通过字符级Transformer得到句子表示，再经句子级Transformer强化上下文信息。编码器输出经过一前馈二分类器对各句进行分类。另将编码后的句子序列输入另一前馈网络获取一个连贯性分数。

$\bullet\;Experimental\;Result:$

   在两项任务上进行训练，分别为预测句子分段标签和对比正确分段和错误分段的连贯性。该模型在多个文本分割数据集上取得sota，且能够实现向其他语言的零样本迁移。  **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/abs/1710.10903)

5.$Revisiting \; Pre-trained \; Models \; for \; Chinese \; Natural \; Language \; Processing$$\textcolor{Red}{(EMNLP,CCF-B)}$

$\bullet Motivation:$

   来自 Transformers (BERT) 的双向编码器表示在各种 NLP 任务中显示出惊人的改进，并且已经提出了连续的变体以进一步提高预训练语言模型的性能。 本文的目标是重新审视中文预训练语言模型，以检查它们在非英语语言中的有效性，并向社区发布中文预训练语言模型系列。

$\bullet Method:$

   提出了一个新的预训练模型MacBERT，通过用其相似的单词来掩盖单词，从而缩小训练前和微调阶段之间的差距。为了进一步加快对中文NLP的研究，创建了中文预训练模型系列并发布到社区。

$\bullet Experimental \; Result:$

   MacBERT 在BERT(Bidirectional Encoder Representations from Transformers )的各个改进版本之上的，持续优化训练的策略：（1）对于MLM任务，使用全词mask和ngram mask策略，mask的词使用相似词替换，减少训练和微调之间的误差：（2）使用albert的SOP任务；在下游的任务中，比之前的bert版本效果均要好。**(Written by Hongfei Xue)**[(BibTex)](https://aclanthology.org/2020.findings-emnlp.58.pdf)



2021:

1.$Who\;Responded\;to\;Whom:\;The\;Joint\;Effects\;of\;Latent\;Topics\;and\;Discourse\;in\;Conversation\;Structure$ $\textcolor{Red}{(EMNLP,\;CCF-B)}$

$\bullet\;Motivation:$

   捕捉多方对话中谁对谁的回应是至关重要的，这是建立和理解对话结构的基础。

$\bullet\;Method:$

   作者定义了initiation-response pairs（发起-响应 对），并参考了来自不同参与者的对话话语的发起和响应。首先在结合上下文cr和cq的情况下学习响应r和候选发起q的潜在主题和潜在话语因素。然后，进行话语匹配，用来测量主题一致性和话语依赖性。最后，预测S(q,r)-r响应q的可能性。

$\bullet\;Experimental\;Result:$

   收集两个对话数据集，来自CMV subreddit的英文CMV数据集和来自Wangwang客户服务平台的另一个中文名称为CS的CMV数据集用于实验。两个数据集的比较结果，本文提出的模型在所有设置下都取得了最好的结果。   **(Written by Weilun Yu)**  [(BibTex)](https://static.aminer.cn/storage/pdf/arxiv/21/2104/2104.08601.pdf)

2.$Informer:\;Beyond\;Efficient\;Transformer\;for\;Long\;Sequence\;Time-Series\;Forecasting$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

   Transformer存在self-attention时间复杂度和空间复杂度过高、多层会导致长输入消耗的显存过多和预测长输出时速度太慢的问题。基于此，作者提出了Informer改进Transformer。

$\bullet\;Method:$

   Informer的改进有三个部分，用ProbSparse self-attention代替普通self-attention，降低时空复杂度。self-attention distilling operation：在每两层之间过滤出决定性的attention score，降低网络宽度，解决消耗显存过多的问题。Generative Style Decoder使输出长序列只需一步，解决输出速度太慢的问题。

$\bullet\;Experimental\;Result:$

   作者在单变量和多变量时间序列下进行预测，单变量下，Informer的表现比其他模型都好，且随时间窗口长度增加，预测错误率的增加缓慢；Informer比使用传统self-attention的Informer表现好，说明sparse的假设是正确的。多变量下，比其他模型好，但没有单变量那么突出。   **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/pdf/2012.07436.pdf)



3.$TWAG:\;A\;Topic-guided\;Wikipedia\;Abstract\;Generator$$\textcolor{Red}{(ACL,\;CCF-A)}$

$\bullet\;Motivation:$

   目前，大多数的摘要生成方法都将文档视作为普通文本(plain text)，而忽略了文档中的实体信息和文档结构信息。而维基百科的词条介绍本身附带人工归纳的目录信息(content table)，其中涉及的方面(aspect)可以作为相应段落话题(topic)的归纳。

$\bullet\;Method:$

   该篇文章便是将目录页所归纳的方面作为摘要生成的关键指导信息，进一步优化生成式摘要的效果。作者提出了TWAG，一种利用维基百科中的主题信息建立的两阶段抽象神经维基百科摘要生成模型，它能够生成全面的摘要。模拟了人类识别对象的方式，使用分类器将输入文档划分为主题，然后根据每个抽象句子预测的主题分布进行主题感知抽象生成。

$\bullet\;Experimental\;Result:$

   文章在WikiCatSum数据集上进行了实验，其包含了商业、电影、动物3个领域的词条。作者通过词条目录构造了相应的主题标签。与摘要生成的基础模型相比，文章提出的模型都有较大提升。**(Written by Yuzhao Chen)**  [(BibTex)](https://arxiv.org/abs/2106.15135)



4.$An\;Adaptive\;Hybrid\;Framework\;for\;Cross-domain\;Aspect-based\;Sentiment\;Analysis$$\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

   跨领域细粒度情感分析任务旨在利用源域中的有用知识来提取方面项并预测它们在目标域中的情感极性。在这些方法中，源数据和目标数据都被用来通过欺骗域鉴别器来学习域不变特征。但是，任务分类器只在源数据上进行训练，导致任务分类器无法利用目标数据中的aspect和sentiment信息。

$\bullet\;Method:$

   本文提出了一个关于跨领域细粒度情感分析任务的自适应混合框架(AHF)。将基于伪标签的半监督学习和对抗训练整合到一个统一的网络中。因此，目标数据不仅可以通过域识别器的训练来对特征进行对齐，还可以用来细化任务分类器。此外，作者还设计了一个自适应mean teacher模型作为网络的半监督部分，它可以缓解噪声伪标签对目标数据的影响。

$\bullet\;Experimental\;Result:$

   在公共数据集上的大量实验结果表明，本文的AHF框架始终优于其他的方法。**(Written by Yuzhao Chen)** [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-2184.ZhouY.pdf)



5.$A\;Joint\;Training\;Dual-MRC\;Framework\;for\;Aspect\;Based\;Sentiment\;Analysis$$\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

   细粒度的情感分析任务(ABSA)任务中涉及三类对象：方面项提取、观点项提取和方面级别的情感分类。在最近的工作中，3个提取任务同时进行被提出，如在一个句子中提取（方面项、观点项、情感极性）的三元组。然而，早先的方法都难以在一个统一的端到端的结构中处理所有的子任务。

$\bullet\;Method:$

   作者将主要工作放在了提取(a,o,s)三元组上，在该论文中，作者提出了一个合并的训练结构来处理所有的ABSA子任务。作者使用了BERT作为骨干网络，并且使用了一个基于跨度的模型来预测ATs/OTs在句子中的起始位置。将原始的三元组的提取任务转化为两个机器阅读理解(MRC)问题。这个三元组的提取任务可以被分解为AE(AT Extraction)，AOE(aspect-oriented OT extraction)和SC(aspect-level sentiment classification)任务，用left MRC处理AE，用right MRC处理AOE和SC。

$\bullet\;Experimental\;Result:$

   本文在这些子任务上进行了实验，在几个基准数据集上得到的结果证明了提出的框架的有效性，它显著优于现有的最先进的方法。**(Written by Yuzhao Chen)** [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-5353.MaoY.pdf)



6.$Hi-Transformer:\;Hierarchical\;Interactive\;Transformer\;for\;Efficient\;and\;Effective\;Long\;Document\;Modeling$ $\textcolor{Red}{(ACL, \;CCF-A)}$ 

$\bullet\;Motivation:$

   文档的长度较长，如果用 Transformer 去建模长文档，计算开销会很大。通常的做法是对长文档进行截断，但是这样会造成文档输入信息不全，影响最终的文档建模效果。对此，作者希望基于长文档由多个句子组成，不同句子的语义既相对完整自洽这两个点进行改进。

$\bullet\;Method:$

   作者设计了层次化和交互式的Transformer模型Hi-Transformer来实现高效和准确的长文档建模。首先用 Sentence Transformer来学习每个句子的语义表示。然后用Document Transformer从文档内部所有句子的语义表示中建模整个文档的 Global context，并得到 Document context-aware 的句子语义表示，进而将其输入到另一个 Sentence Transformer 中，以实现利用 Global document context 来增强每个句子语义学习的目标。最后，使用层次池化方法获得文档的表示。

$\bullet\;Experimental\;Result:$

   在 Amazon、IMDB 和 MIND 等三个长文档数据集上开展了实验。实验结果显示 Hi-Transformer 在长文档建模上的性能要优于 Transformer及其多个加速变体， Hi-Transformer 的计算复杂度显著小于 Transformer，并与已有的一些加速变体相当。之后进一步比较了 Transformer 和 Hi-Transformer 在不同文档长度下的性能和速度。当输入同样长度文档时，二者的性能非常接近。当文档长度较长时，Hi-Transformer 的速度显著优于 Transformer。因此，Hi-Transformer 能够处理  Transformer 由于速度和显存限制而无法处理的较长文档，并且能够取得和 Transformer 接近的效果。   **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/abs/2106.01040)

7.$DeepRapper:\;Neural\;Rap\;Generation\;with\;Rhyme\;and\;Rhythm\;Modeling$ $\textcolor{Red}{(ACL, \;CCF-A)}$ 

$\bullet\;Motivation:$

   作者想要设计出自动生成rap的模型。但是还存在一些挑战：一方面，由于没有现存的含有节奏信息的数据集，之前的 Rap 生成系统只能生成纯歌词；另一方面，之前的 Rap 生成系统对于押韵的建模也有所欠缺，很难自动生成多押、连押和连环押等高质量 Rap 的必要成分。作者希望设计出一个基于 Transformer 的 Rap 生成模型，来生成押韵且有节奏信息的 Rap 歌词。

$\bullet\;Method:$

   针对数据缺乏的问题，首先设计了一个收集数据的 Pipeline，收集了大量歌曲数据，并且对歌曲进行了一系列处理，建立了三个大规模的数据集：D-RAP、D-SONG、D-LYRIC。

   DeepRapper 采用了基于 Transformer 的自回归语言生成模型。为了更好地对“押韵“建模，首先采用了反向生成的方式，从右到左生成一句话里的歌词。因为押韵词语通常位于句子末尾，这样的反向处理有利于生成多押（N-gram rhyme）的 Rap。然后又引入了韵母 Embedding 和相对位置 Embedding，以更好捕捉押韵词语与句子中位置的关系，这同样利于生成多押的 Rap。最后在生成时引入韵脚约束，以灵活调整下一个词的概率，在不影响自动生成 Rap 的同时，给押韵的词语分配更多的概率，这不仅有利于生成多押，还有利于连押。而且对于可以获得的极少的连环押数据，DeepRapper 也在连环押句子中的每个韵脚后嵌入了一个特殊Token，从而赋予了 DeepRapper 生成连环押 Rap 句子的能力。对于节奏的建模，DeepRapper 在歌词中插入了一个特殊的 [BEAT] Token，显式地将节奏信息和歌词信息融合，将节奏预测简化成语言模型里特殊 Token 的预测。

$\bullet\;Experimental\;Result:$

   比较了 DeepRapper 客观和主观的评估结果，并与两个基线模型进行了比较。Baseline 与 DeepRapper 结构相同，但是没有韵律模型；Baseline+PT 则是采用了预训练的 Baseline。结果显示，DeepRapper 在客观指标 Perplexity (PPL)、Rhyme Accuracy (RA)、 Rhyme Density (RD)和主观指标 Theme (主题是否鲜明)、Fluency (语言是否流畅)、Quality (韵脚质量)、 Diversity (韵脚多样化)上都远远超出了各个 Baseline。   **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/abs/2107.01875)

8.$Fast\; Multi-Instance\; Multi-Label \;Learning\; $$\textcolor{Red}{(AAAI,\;CCF-A)}$

​	$\bullet\;Motivation :$

​	在多案例多标签学习中（MIML），一个复杂目标往往被多个案例表示且同时与多个标签相关，MIML方法可以有效的用于很多应用，但是因为大的时间消耗无法有效处理大数据集。

​	$\bullet\;Method :$

​	本文首先构建了一个由所有标签共享的低维子空间，然后训练标签的具体线性模型，通过随机梯度下降去优化近似ranking损失。具体过程，首先将一个问题分解成案例级任务，预测每个案例的标签，然后即可得到该问题的多标签类别。这个过程中设计了一个Ranking loss函数去评估模型，训练参数，Ranking是指如果该案例对于不相关标签的预测值，越大说明性能越差。

​	$\bullet\;Experiment\; Result :$

​	实验结果显示，fastMIML方法明显优于经典方法，时间消耗最少，尤其是在处理30K bags和279K instances时，目前没有方法可以在24小时内返回结果，但是本文的方法只需要12分钟，此外，本文方法还能找到对每个标签最优代表性的案例，可以提供一个理解输入模式和输出语义关系的机会。**(Written by Wenhua Zhu)**     [(BibTex)]([Fast Multi-Instance Multi-Label Learning. - AMiner](https://www.aminer.cn/pub/53e9ade2b7602d97037ea35b/fast-multi-instance-multi-label-learning))

9.$Multitask\;Learning\;for\;Emotion\;and\;Personality\;Detection\;$ $\textcolor{Red}{(TAC,\;CCF-B)}$

​	$\bullet\;Motivation :$

​	由于个人数字足迹的大量出现，基于学习的深度个性检测越发重要。很多研究者认为性格特点和情绪有很强烈的关联，本文基于此做了一些多任务学习的工作。

​	$\bullet\;Method :$

​	本文设计了一个新的多任务学习框架（SOGMTL），可以同时预测性格特点和情绪。主体框架是由嵌入层，卷积层，池化层，稠密层构成，为了实现不同任务之间的信息共享，在每一层后添加一个门机制。文中比较了三个门机制，SiG, CAG和SiLG，他们各有自己的优势和不足，为了克服这些问题，作者提出了SOG方法，它在SIG中将sigmoid函数改成softmax函数去构造一个选择门。在多任务训练中由于不同任务面对的数据集是不同的，因此需要设计好自适应的训练框架用于不同的子任务。

​	$\bullet\;Experiment\; Result :$

​	实验结果显示，CNN在这些任务上是要优于BERT和LSTM的，本文所添加的MAML结构对于框架的性能提升也起了很大的作用。**(Written by Wenhua Zhu)**     [(BibTex)]([Multitask Learning for Emotion and Personality Detection - AMiner](https://www.aminer.cn/pub/5ff8278791e0116ed225e223/multitask-learning-for-emotion-and-personality-detection))

10.$Topic-driven\;and\;Knowledge-Aware\;Transformer\;for\;Dialogue\;Emotion\;Detection\;$ $\textcolor{Red}{(ACL,\;CCF-A)}$

​	$\bullet\;Motivation :$

​	情感检测在对话中是具有极大挑战的，因为好的识别效果往往需要对对话主题，相关常识以及情感状态之间复杂的转换模式有很好的识别。

​	$\bullet\;Method :$

​	本文提出了一个主题驱动和知识感知转换器来解决这些问题，首先设计了主题扩充语言模型，然后有一个专门用于主题检测的层，将主题扩充与导出的常识语句结合起来。更具体来说，首先是获得会话的主题，采用VHRED用于主题发现，用预训练语言模型取代其中的RNN编码器和解码器，此外，使用多头注意力取代LSTM去对潜在主题矢量之间的依赖性的建模。在常识结合过程中。首先以知识图形式表示各事件的关联，有SBERT 和COMET两种计算会话与事件相关性的方法，将相关性最高的事件作为常识与主题结合，进行对话情感检测。

​	$\bullet\;Experiment\; Result :$

​	在四个数据集上和四个基准模型进行比较实验，本文的模型在多数结果上要由于他们，在消融实验中，也表明框架设置是十分有效的。**(Written by Wenhua Zhu)**     [(BibTex)]([Topic-Driven And Knowledge-Aware Transformer For Dialogue Emotion Detection - AMiner](https://www.aminer.cn/pub/60bad81191e01102e59b6a80/topic-driven-and-knowledge-aware-transformer-for-dialogue-emotion-detection))

11.**$Multi-modal\;Multi-label\;Emotion\;Recognition\;Heterogeneous\;Hierarchical\;Message\;Passing$ $\textcolor{Red}{(AAAI,\;CCF-A)}$**

​    $\bullet\;Motivation:$

​	多模态情绪识别是情感计算领域的一个重要研究课题，近年来已成为研究热点。然而，几乎所有现有的研究都对每种情绪进行多重二值分类，主要集中在完整的时间序列数据上。

​    $\bullet\;Method:$

​	本文提出了一个异构层次的消息传递网络来有效地建模上面的依赖关系。此外，我们提出了一种新的基于部分时间序列内容的多模式多标签情感数据集，以显示我们的模型的优势泛化。

​    $\bullet\;Experimental\;Result:$

​	针对多模式多标签情感识别所面临的挑战，提出了一种异构层次信息传递网络(HHMPN)。这种方法可以很容易地在完整时间序列数据和部分时间序列数据上执行。此外，特性到特性、特性到标签、标签到标签和模式到标签的依赖问题可以通过作者方法中的核心模块很好地捕获。	**(Written by Hao Fu)**      [(BibTex)](https://ojs.aaai.org/index.php/AAAI/article/view/17686)
