# Emotion recognition in conversation(ERC)

2016:

2017:

2018

2019:

​	1.$Context-aware\;Embedding\;for\;Targeted\;Aspect-based\;Sentiment\;Analysis$$\textcolor{Red}{(ACL,\;CCF-A)}$

​     $\bullet\;Motivation:$

   本文是针对TABSA中，现有的基于注意力机制的神经网络模型虽然取得了较好的效果，但是由于这些方法中表示target和aspect的向量都是随机初始化的，导致在表示目标（target）和方面（aspect）时往往会脱离上下文。

​    $\bullet\;Method:$

   本文提出了一种结合上下文信息优化目标和方面向量表示的方法，该方法可以直接和现有基于神经网络的目标-方面级别情感分析模型相结合。能够通过稀疏系数向量从上下文中选择一组高度相关的词，然后调整目标和方面的表示。因此，可以提取特定目标、对应方面和上下文之间的相互依赖关系，从而生成更好的嵌入。

​	$\bullet\;Experimental\;Result:$

   结果显示本文提出的优化目标和方面向量表示的方法在目标识别和情感分类任务中都取得了更好的表现，在SentiHood和 Semeval两个基准数据集上均取得了更加优秀的成绩，这说明了上下文相关的目标和方面表示能提升模型在细粒度情感分析任务中的效果。**(Written by Yuzhao Chen)**   [(BibTex)](https://arxiv.org/abs/1906.06945)

2020:

​	1.$Context-Guided\;BERT\;for\;Targeted\;Aspect-Based\;Sentiment\;Analysis$$\textcolor{Red}{(AAAI,\;CCF-A)}$

​	$\bullet\;Motivation:$

   在本文中，作者研究了在自我注意模型中加入上下文是否能提高(T)ABSA的表现。

​	$\bullet\;Method:$

   本文提出了两种上下文引导的BERT(CGBERT)的变体，首先是采用上下文感知的Transformer来生成使用上下文引导的softmax-attention的CG-BERT，将之前提出的上下文感知自注意网络扩展到(T)ABSA任务。然后，提出了一种改进的准注意CG-BERT模型(QACG-BERT)，该模型可以学习支持减法注意的合成注意。

​	$\bullet\;Experimental\;Result:$

   在SentiHood和SemEval数据集上，两种模型都取得了更好的表现，两种模型的性能均优于以前的SOTA模型。**(Written by Yuzhao Chen)**    [(BibTex)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Context-Guided+BERT+for+Targeted+Aspect-Based+Sentiment+Analysis&btnG=)

​	2.$Contextualized\;Emotion\;Recognition\;in\;Conversation\;as\;Sequence\;Tagging$$\textcolor{Red}{(ACL,\;CCF-A)}$

​	$\bullet\;Motivation:$

   作者发现关于ERC的预测情绪标签的方法大多会忽略情绪标签之间的内在联系，并且观察到情绪一致性现象广泛存在于对话中，也就是说，相似的情绪更有可能出现，而不是不同的情绪，所以认为对情绪一致性进行建模有助于找到更合理的情绪标签分布，从而进一步提高情绪分类的性能。

​	$\bullet\;Method:$

   作者首次将ERC任务建模为序列标记，并使用CRF来建模对话中的情绪一致性，CRF层利用上文和下文的情感标签来联合解码整个对话的最佳标签序列。应用一个多层Transformer编码器来增强基于LSTM的全局上下文编码器，因为增强的编码器能够捕获长程连续上下文。作者提出了Contextualized Emotion Sequence Tagging（CESTa）模型，首先通过CNN网络获取每个句子的表示 ut ，随后每个句子分别被送入全局编码器（Global Context Encoder）和独立编码器（Individual Context Encoder)，最后全局编码器的结果和局部编码器的结果拼接，经过全连接层送入CRF层产生最终的预测，并选择最大分数的序列作为输出。

​	$\bullet\;Experimental\;Result:$

   本文在三个对话数据集上做了实验，与baseline相比，本文的模型在三个数据集上均取得了SOTA结果，实验表明对情感一致性和远程上下文依赖关系进行建模可以提高情感分类的性能。**(Written by Yuzhao Chen)**   [(BibTex)](https://aclanthology.org/2020.sigdial-1.23/)

​	3.$An\;End-to-End\;Visual-Audio\;Attention\;Network\;for\;Emotion\;Recognition\;in\;User-Generated\;Videos$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

​	$\bullet\;Motivation:$

​	用户生成视频中的情感识别在以人为中心的计算中起着重要的作用。现有的方法主要采用传统的两阶段浅层管道，即提取视觉和/或音频特征，并训练分类器。

​	$\bullet\;Method:$

​	本文提出了一种基于卷积神经网络(CNNs)的端到端视频情感识别方法。开发了一种深度视觉音频注意力网络(VAANet)，这是一种新颖的架构，将空间、渠道和时间注意力集成到可视化3D CNN中，将时间注意力集成到音频2D CNN中。

​	$\bullet\;Experimental\;Result:$

​	所建立的新型V - AANet模型包含了一种新颖的注意机制和一种新颖的交叉熵损失，使用了较少的辅助数据。通过综合考虑各方面的关注，VAANet可以更好地关注具有区别性的关键细分市场及其关键区域。	**(Written by Hao Fu)**      [(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=An+End-to-End+Visual-Audio+Attention+Network+for+Emotion+Recognition+in+User-Generated+Videos&btnG=)

​	4.$Exploiting \; Unsupervised \; Data \; for \; Emotion \; Recognition \; in \; Conversations$ $\textcolor{Red}{(EMNLP,CCF-B)}$

​	$\bullet Motivation:$

​	对话中的情绪识别（ERC）旨在预测对话中说话者的情绪状态，这本质上是一项文本分类任务。 与句子级文本分类问题不同，ERC 任务可用的监督数据是有限的，这可能会阻止模型发挥其最大作用。

​	$\bullet Method:$

​	在本文中，作者提出了一种利用更易于访问的无监督对话数据的新方法。 具体来说，作者提出了 Conversation Completion (ConvCom) 任务，该任务尝试从候选答案中选择正确答案以填充对话中的掩码话语。 然后，作者在 ConvCom 任务上预训练一个基本的上下文相关编码器（PRE-CODE）。 最后，作者在 ERC 的数据集上微调 PRECODE。 

​	$\bullet Experimental \; Result:$

​	这篇文章的实验结果表明，对无监督数据进行预训练可以显着提高 ERC 数据集的性能，尤其是在少数情绪类别上。**(Written by Hongfei Xue)**      [(BibTex)](https://arxiv.org/pdf/2010.01908)

​    5.$CH-SIMS\;A Chinese\;Multimodal\;Sentiment\;Analysis\;Dataset\;with\;Fine-grained\;Annotation\;of\;Modality$$\textcolor{Red}{(ACL,\;CCF-A)}$

​    $\bullet\;Motivation:$

   以往多模态情感分析的研究都是使用有限的数据集，这些数据集只包含统一的多模态注释。然而，统一的注释并不总是反映单一模态的独立情感，并且限制了模型对模态之间差异的捕捉。

​    $\bullet\;Method:$

   本文介绍了一个中文单模态和多模态情感分析数据集CH-SIMS，同时具有多模态和独立的单模态注释。它允许研究人员研究模态之间的相互作用，或者使用独立的单模态注释进行单模态情感分析。此外，本文还提出了一个基于后期融合的多模态多任务学习框架，并在这个框架中引入了三个后期融合模型作为SIMS的强基线。

​    $\bullet\;Experimental\;Result:$

   实验结果表明，在多模态情感分析中引入独立的单模态标注，可以显著提高现有方法的性能，多模态标签不能总是反映单模态的情感状态，统一的多模态标注可能会误导模型学习单模态表征的固有特征。单模态标注可以帮助模型获得更多的差异化信息，提高模态间的互补性。作者还进行了消融实验，发现在进行多任务学习时，不同子任务的学习不同步可能会对多模态情感分析造成不利影响。**(Written by Yuzhao Chen)**  [(BibTex)](https://aclanthology.org/2020.acl-main.343/)

​    6.$A \; Self-Attentive \; Emotion \; Recognition \; Network$$\textcolor{Red}{(ICASSP,CCF-B)}$

​    $\bullet Motivation:$

​    现代深度学习方法在序列数据建模和分类方面取得了突破性进展。特别是，注意力网络构成了捕捉长时间动态的最先进范式。作者探讨了这一范式在二元对话中情绪识别这一具有挑战性的任务中的有效性。

​    $\bullet Method:$

​    作者的工作引入了一种新的注意机制，能够推断出过去的每一次话语对当前说话人情绪状态的巨大影响。所提出的注意机制在不需要解码器网络的情况下执行该推断过程；这是通过创新的自我关注论点实现的。作者提出的自我注意网络捕获了连续编码器网络状态之间的相关模式，从而允许在任意长的时间范围内对时间动态进行稳健而有效的建模。

​    $\bullet Experimental \; Result:$

​    该网络能够在长时间的讨论过程中捕捉强烈的情感模式。在具有挑战性的IEMO、CAP基准上面，作者的方法也具备有效性。**(Written by Hongfei Xue)**[(BibTex)](https://arxiv.org/pdf/1905.01972.pdf)

​     7.$HiTrans:\;A\;Transformer-Based\;Context-\;and\;Speaker-Sensitive\;Model\;for\;Emotion\;Detection\;in Conversation$ $\textcolor{Red}{(COLING, \;CCF-B)}$ 

   $\bullet\;Motivation:$

​	  普通的Transformer在做NLP任务时，只能处理局部上下文表征，但是在ERC任务中，除了局部的上下文话语表征，远程上下文编码也需要被考虑到，这样能做到对话全局上下文的建模。

   $\bullet\;Method:$

​      利用预训练模型Bert作为低级Transformer去处理局部话语表征，然后将Bert处理的结果传给更高一层的transformer。作为一个更高级的Transformer，这一层除了用标准的transformer，还将position encoder加入到了上一层输出的话语表征中，用于建模话语中会话的相对位置。

   $\bullet\;Experimental\;Result:$

​      在MELD, IEMOCAP, EmoryNLP三个数据集上实验结果均优于当时的SOTA模型。  **(Written by Weilun Yu)**  [(BibTex)](aclanthology.org/2020.coling-main.370/)

8.$DialogXL: \;All-in-One\; XLNet\; for\; Multi-Party\; Conversation\; Emotion\; Recognition  $ $\textcolor{Red}{(AAAI,\;CCF-A)}$

​	$\bullet\;Motivation:$

​	   对话中的会话通常以分级结构来组织，这对于预训练语言模型（XLNet）的应用不太好。情绪在短上下文中保持不变对于通过不同对象有效建模是很重要的，对于ERC有效采用预训练模型，有两个挑战：对话通常是多元的，且在说话这内部之间具有依赖性，已有的预训练模型不能灵活的编码这些依赖关系。第二几乎所有语言模型都被输入长度约束，这会导致信息损失。

​    $\bullet\;Method:$

​	   本文采用一个all-in-one XLNet模型用于多轮多元对话，它首先将XLNet的段循环用更灵活和记忆存储的会话循环替代，以此获取历史信息；会话循环在记忆银行保存历史会话的隐藏状态，当识别一个查询会话时重复使用他们。然后，XLNet的transformer里的自注意力层用对话意识自注意力替换，包含local,global self-attention, speaker , listener self-attention层。以此在历史上下文的不同接收领域建模发言者之间和发言者内部的依赖关系。

​	 $\bullet\;Experimental\;Result:$

​	    在四种ERC基准上进行了广泛的实验，并展示了主流进行比较，实验结果表明，该模型在所有数据集上均优于基线。消融实验和误差分析也证实了DialogXL关键模块的作用**(Written by Wenhua Zhu)**     [(BibTex)]([DialogXL: All-in-One XLNet for Multi-Party Conversation Emotion Recognition | Proceedings of the AAAI Conference on Artificial Intelligence](https://ojs.aaai.org/index.php/AAAI/article/view/17625))

9.$An\;End-to-End\;Visual-Audio\;Attention\;Network\;for\;Emotion\;Recognition\;in\;User-Generated\;Videos$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

​	用户生成视频中的情感识别在以人为中心的计算中起着重要的作用。现有的方法主要采用传统的两阶段浅层管道，即提取视觉和/或音频特征，并训练分类器。

$\bullet\;Method:$

​	本文提出了一种基于卷积神经网络(CNNs)的端到端视频情感识别方法。开发了一种深度视觉音频注意力网络(VAANet)，这是一种新颖的架构，将空间、渠道和时间注意力集成到可视化3D CNN中，将时间注意力集成到音频2D CNN中。

$\bullet\;Experimental\;Result:$

​	所建立的新型V - AANet模型包含了一种新颖的注意机制和一种新颖的交叉熵损失，使用了较少的辅助数据。通过综合考虑各方面的关注，VAANet可以更好地关注具有区别性的关键细分市场及其关键区域。	**(Written by Hao Fu)**      [(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=An+End-to-End+Visual-Audio+Attention+Network+for+Emotion+Recognition+in+User-Generated+Videos&btnG=)

   10.$Context-Guided; BERT; for; Targeted; Aspect-Based; Sentiment; Analysis$$\textcolor{Red}{(AAAI,; CCF-A)}$

​    $\bullet\; Motivation:$

​    基于方面的情感分析(ABSA)和基于目标的情感分析(TABSA)允许根据上下文从同一文本中提取关于情感的更细粒度的推断。

​    $\bullet\; Method:$

​    在本文中作者研究了在自我注意模型中加入上下文是否能提高(T)ABSA的表现。作者提出了两种不同情境下学习分配注意力的情境引导BERT (CGBERT)变体。在两个(T)ABSA数据集上使用预先训练过的BERT对两个模型进行训练:SentiHood和SemEval-2014 (Task 4)。

   $\bullet\;Experimental\;Result:$

​    针对ABSA和TABSA提出了两个基于bert的上下文感知模型，在两个数据集上的结果都优于最新的结果。 **(Written by Hao Fu)** [(BibTex)](https://scholar.google.com.hk/scholar?hl=zh-CN&as_sdt=0%2C5&q=Context-Guided+BERT+for+Targeted+Aspect-Based+Sentiment+Analysis&btnG=)

  11.$Exploiting ; Unsupervised ; Data ; for ; Emotion ; Recognition ; in ; Conversations$ $\textcolor{Red}{(EMNLP,CCF-B)}$

  $\bullet Motivation:$

 会话中的情绪识别(ERC)旨在预测会话中说话人的情绪状态，本质上是一个文本分类任务。与句子级文本分类问题不同，ERC任务可用的监督数据有限，这可能会阻碍模型发挥最大效果。

  $\bullet Method:$

 在本文中，作者提出了一种新的方法来利用无监督的会话数据，它更容易访问。具体来说，提出了会话完成(ConvCom)任务，该任务试图从候选答案中选择正确的答案来填充对话中的隐藏话语。

  $\bullet Experimental ; Result:$

 本文提出的会话完成任务对情景依赖模型的预训练是有效的，并进一步对其进行了调整，显著提高了ERC的表现。 **(Written by Hao Fu)** [(BibTex)](https://arxiv.org/pdf/2010.01908)



2021:

​    1.$Towards\; Emotional\; Support\; Dialog \;Systems  $ $\textcolor{Red}{(ACL,\;CCF-A)}$

​     $\bullet\;Motivation :$

​	在对话系统中能提供情绪支持是十分重要的，但是目前来说，之前的研究基本是关注如何对于该会话做出合理的回应，但是并不考虑该回应是否可以帮助到对方，而且，由于缺乏好的任务设计和有效的情绪支持对话语料库，现有研究依旧没有将情绪支持融入对话系统。

​     $\bullet\;Method :$

​	 本文定义了情绪支持对话任务（ESC）和基于Hill的帮助技巧理论提出ESC框架，此外还构建了一个情绪支持对话数据集(ESConv)。以Hill理论为核心模拟人类与朋友，家人等的交互关系而不是直接采取专业咨询过程，这有利于普通情绪分析。其中包括三个状态：探索，安慰和行动；每一个状态又包含了多个支持略，状态顺序可以根据个人对话需要而变化，而不是固定的探索，安慰然后行动。策略有9种，包括提问，重述，建议等，在不同状态，采用这些策略去达成目的，比如探索阶段，可以通过提问获取更多信息，或者重述对方问题以刺激对方真实想法等策略去明确对方的问题是什么，有利于后面的安慰和行为状态。最后还有情绪评估的方法，通过情绪强度值去判断我们的行为是否对help-seeker有帮助。

​     $\bullet Experimental \; Result:$

​	实验结果表示，对于数据集（ESConv):评估它能对经典生成式对话模型（以BlenderBot和DialoGPT作为预训练模型，Vanilla和Variants with strategy作为变体）提高多少性能，结果显示该数据集对于生成式对话性能提升帮助很大，此外这些模型能从ESConv数据集中学习到如何提供有效的情绪支持。 **(Written by  Wenhua Zhu)**[(BibTex)](https://aclanthology.org/2021.acl-long.269.pdf)

2.$Learning\; Modality-Specific\; Representations \;with \;Self-Supervised \;Multi-Task \;Learning \;for \;Multimodal \;Sentiment\; Analysis$$\textcolor{red}{(AAAI,\;CCF-A)}$

​    $\bullet\;Motivation :$

​	表示学习是多模态学习中一项重要且具有挑战性的任务，有效的模态表示应该包含一致性和差异性两部分特征。由于统一的多模态注释，现有方法在捕获差	异化信息方面受到限制。然而，额外的单模态注释是高时间和劳动力成本。

​    $\bullet\;Method :$

​	在表示学习的指引差异中主要分为前向和后向，本文主要关注后向指引。基于标签差异和模态表示与类中心的距离差异是绝对相关的，和单模态标签与多模  态标签有关两个方面，本文设计了一个基于自监督学习策略的标签生成模块来获得独立的单模态监督；联合训练多模态任务和单模态任务，分别学习一致性和差异性；在训练阶段，设计了权重调整策略来平衡不同子任务之间的学习进度，即引导子任务专注于模态监督差异较大的样本。

​    $\bullet\;Experiment \;Result$

​	对三个公共多模态基线数据集进行了广泛的实验。实验结果验证了自动生成的单模态监督的可靠性和稳定性。在MOSI和MOSEI数据集上，本文的方法超越了 	当前最先进的方法。在SIMS数据集上，本文方法实现了与人工注释的单模态标签相当的性能。 **(Written  by  Wenhua Zhu)**[(BibTex)](https://www.researchgate.net/publication/349159330_Learning_Modality-Specific_Representations_with_Self-Supervised_Multi-Task_Learning_for_Multimodal_Sentiment_Analysis)

3.$Bridging\; Towers\; of\; Multi-task\; Learning\; with \;a \;Gating\; Mechanism\; for\; Aspect-based\; Sentiment \;Analysis\; and\; Sequential$ 		  		$Metaphor\; Identification  $ $\textcolor{red}{(AAAI,\; CCF-A)}$

​    $\bullet\; Motivation :$

​	多任务学习（MTL）已广泛应用于自然语言处理，一个主要任务及其相关的辅助任务共享同一个编码器；因此，MTL编码器可以学习主要任务和副主任吴之间共享抽象信息。然后在共享编码器上使用特定于任务的塔来学习特定于任务的信息。以前的工作表明，在特定的塔之间交换信息会产生额外的收益，这被称为软参数共享MTL。

​     $\bullet\; Method :$

​	 本文中提出了一种用于桥接 MTL 塔的新型门控机制， 对Aspect-Based 的情感分析和顺序隐喻识别任务进行评估。框架结构：首先采用BERT对输入序列编码获取共享隐藏状态，对于三个子任务（aspect,opinion,sentiment提取)，首先用Transformer作为具体任务塔，接来了是一系列由桥和transformer组成的块, 这其中的每一层，三个任务之间的信息在桥之间传递，其中以同列的位主要任务，另外两列为辅助任务进行学习，获取额外的收益，如下图所示<img src="D:\桌面\21-汕头大学\研究生科研\先冲在说\图片\MTL.png" alt="MTL" style="zoom:75%;" />，序列隐喻识别任务的流程也是一样的架构。

​     $\bullet\;Experiment \;Result :$

​      在两个任务上都可以产生比基线更好的性能。基于相同的 Transformer 主干，本文将门控机制与其他信息转换机制进行了比较，例如十字绣、注意力和香草门	控。实验表明，本文的方法也超越了这些基线。 **(Written  by  Wenhua Zhu)**[(BibTex)]([Bridging Towers of Multi-task Learning with a Gating Mechanism for Aspect-based Sentiment Analysis and Sequential Metaphor Identification | Proceedings of the AAAI Conference on Artificial Intelligence](https://ojs.aaai.org/index.php/AAAI/article/view/17596))

4. $A \;Joint\; Training\; Dual-MRC\; Framework \;for\; Aspect \;Based \;Sentiment\; Analysis$ $\textcolor{red}{(AAAI,\;CCF-A)}$

​     $\bullet\;Motivation :$

​	 Aspect-Based 的情感分析 (ABSA) 涉及三个基本子任务：aspect term extraction, opinion term extraction, and aspect-level sentiment classification。前期的工作只专注于单独解决这些子任务之一。最近的一些工作侧重于解决两个子任务的组合，例如，aspect term extraction 以及 sentiment polarities or extracting the aspect and opinion terms pair-wisely。最近提出了三元组提取任务，即从句子中提取（方面项、意见项、情感极性）三元组。然而，以前的方法无法在统一的端到端框架中解决所有子任务。

​    $\bullet\;Method :$

​	  为 ABSA 提出了一个完整的解决方案。本文构建了两个机器阅读理解（MRC）问题，并通过联合训练两个共享参数的 BERT-MRC 模型来解决所有子任务，如下图所示![Dual-MRC](D:\桌面\21-汕头大学\研究生科研\先冲在说\图片\Dual-MRC.png)左边提取出输入文本中所有的方面项，右边提取出意见项，并根据左边提取的方面项获取情感极性。

​    $\bullet\;Experiment\;Result :$

​	本文对这些子任务进行了实验，在几个基准数据集上的结果证明了本文提出的框架的有效性，它明显优于现有的最先进方法。 **(Written  by  Wenhua Zhu)**[(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-5353.MaoY.pdf)

​	5.$Contrastive\;Adversarial\;Learning\;for\;Person\;Independent\;Facial\;Emotion\;Recognition$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

​      $\bullet\;Motivation:$

​	大多数人脸情绪识别方法显著依赖于监督信息，在独立于人进行情绪分析方面存在一定的局限性。另一方面，对抗学习是一种众所周知的广义表示学习方法，因为它不需要监督信息。

​     $\bullet\;Method:$

​	作者提出了一种新的对抗学习方法。通过基于强情绪样本的对抗性学习弱情绪样本，使得FER网络能够更好地理解强情绪中蕴含的复杂情绪元素。并且提出了一个有效对抗学习的对比损失函数。

​    $\bullet\;Experimental\;Result:$

​	传统方法试图通过改进CNN来提高AV域FER的性能，而作者提出的方法则侧重于通过对抗性学习来学习情绪变化的程度。本文研究将对目前只关注网络结构的研究具有很大的启示意义。	**(Written by Hao Fu)**      [(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Contrastive+Adversarial+Learning+for+Person+Independent+Facial+Emotion+Recognition&btnG=)

​    6.$Distributed\;Representations\;of\;Emotion\;Categories\;in\;Emotion\;Space$$\textcolor{Red}{(ACL,\;CCF-A)}$

​    $\bullet\;Motivation:$

   现有的情绪检测研究主要致力于提升模型预测的准确度，情感类别通常被表示为one-hot向量形式，但是，这种表示方式会忽略情感类别之间的关联。

​    $\bullet\;Method:$

   因此，为了更好的表达情感关系，本文提出了一个框架，可以从给定的情感分类数据集学习情感空间中情感类别的分布式表示。此外，基于预训练神经网络模型预测的软标签，给出了一种简单有效的算法。

​    $\bullet\;Experimental\;Result:$

   实验结果表明，本文的方法在情感空间中的表征比在单词嵌入中的表征能更好地表达情感关系。**(Written by Yuzhao Chen)**  [(BibTex)](https://aclanthology.org/2021.acl-long.184/)

​    7.$Context-Guided\; BERT\; for \;Targeted \;Aspect-Based \;Sentiment\; Analysis$$\textcolor{red}{(AAAI,\;CCF-A)}$

​	$\bullet\;Motivation :$

​	Aspect-Based 的情感分析 (ABSA) 和有针对性的 ASBA (TABSA) 允许根据上下文从同一文本中对情感进行更细粒度的推断。例如，给定的文本可以有不同的目标和不同的 Aspect （例如，价格或安全），每个目标-Aspect 对关联不同的情绪。

​	$\bullet\; Methods :$

​	本文研究了向自注意力模型添加上下文是否可以提高 (T)ABSA 的性能。提出了上下文引导的 BERT (CG-BERT) 的两种变体，它们学习在不同的上下文中分配注意力。首先采用上下文感知 Transformer 来生成使用上下文引导的 softmax-attention 的 CG-BERT。接下来，提出了一种改进的 Quasi-Attention CG-BERT 模型，该模型学习支持减法注意力的组合注意力。

​	$\bullet\; Experiment\; Result :$

​	本文在两个 (T)ABSA 数据集上使用预训练的 BERT 训练两个模型：SentiHood 和 SemEval-2014（任务 4）。其中 QACG-BERT 模型具有最佳性能，这两种模型都取得了最新的最新结果。此外，还分析了本文提出的模型中上下文的影响。本文的工作为将上下文相关性添加到基于上下文的自然语言任务的预训练的基于自我注意的语言模型的效用提供了更多证据。 **(Written  by  Wenhua Zhu)**[(BibTex)]([PRELIMINARY VERSION DO NOT CITE (aaai.org)](https://www.aaai.org/AAAI21Papers/AAAI-7955.WuZ.pdf))

​    8.$Quantum \;Cognitively\; Motivated\; Decision\; Fusion\; for\; Video\; Sentiment\; Analysis$$\textcolor{red}{(AAAI,\;CCF-A)}$

​	$\bullet\;Motivation :$

​	视频情感分析作为一个决策过程本质上是复杂的，涉及来自多种模式的决策和由此引起的认知偏差的融合。受量子认知最新进展的启发，我们表明来自一种模态的情绪判断可能与来自另一种模态的判断不相容，即顺序很重要，它们不能联合测量以产生最终决定。因此，认知过程表现出经典概率理论无法捕捉到的“类量子”偏差。

​	$\bullet\; Methods :$

​	提出了一种全新的、量子认知驱动的融合策略，用于预测情绪判断。特别是，我们将话语表述为正面和负面情绪判断的量子叠加态，并将单模态分类器表述为互不相容的可观察量，在复值希尔伯特空间中，具有正运算符值度量。

​	$\bullet\; Experiment\; Result :$

​	在两个基准数据集上的实验表明，本文的模型明显优于各种现有的决策级别和一系列最先进的内容级别融合方法。不兼容的概念允许有效处理所有组合模式，包括那些被所有单模态分类器错误预测的极端情况。 **(Written  by  Wenhua Zhu)**[(BibTex)]([Quantum Cognitively Motivated Decision Fusion Framework for Video Sentiment Analysis - Qiuchi Li](https://qiuchili.github.io/publication/aaai20-2))

​    9.$BoB:\; BERT\; Over \;BERT\; for\; Training\; Persona-based\; Dialogue\; Models \;from\; Limited\; Personalized \;Data$$\textcolor{red}{(ACL,\;CCF-A)}$

​	$\bullet\;Motivation :$

​	对话中的人设（Persona）代表某个说话者的身份元素的组合，例如个人资料和背景个人事实。在对话生成中，传统模型难以保证生成的回复符合预设的人设。同时，现有的社交媒体对话中人设信息较少，如推特上不到10%的消息会透露个人轶事或在家或工作中的活动，甚至更少的个人身份信息。因此在有限的个性化数据上训练的模型无法充分理解人设的一致性。

​	$\bullet\; Methods :$

​	作者提出了BERTover-BERT (BoB) 模型。该模型由一个编码器和两个解码器构成。其中编码器是一个标准的 BERT 模型；解码器 D1 是响应生成解码器，由 BERT 和随机初始化的编码器-解码器注意力层构成；解码器 D2 是一致性理解解码器，也是一个标准的 BERT 模型。Bob主要包含两类训练数据，一类是带人设的对话数据 (P，Q，R)，分别代表人设 Persona、上下文查询 Query、响应 Response；另一类是非对话推理数据 (D+, D-)，其中D由前提和假设构成，D+代表正样本（即“假设”是符合“前提”的），而D-代表负样本。训练时，E和D1组成了一个标准的 Transformer 模型，使用正常的带人设的对话数据可以计算得到负对数似然L1；D2则在D1的基础上，使用了两次 self-attention，第一次得到自身和人设 P（不包含Q）的注意力表示，然后再得到自身和D1的隐藏层输出的注意力表示，那么带有人设和D1输出的特征作为D2的输出层表示。

​	$\bullet\; Experiment\; Result :$

​	作者分别报告了在 PersonaChat 和 PersonalDialog 测试集上的评价指标，从表3中可以看出，BoB模型在所有的指标都显著优于基线模型。从表5中可以看出，BoB模型随机测试集中的一致性指标没有明显优于基线模型，但是另外制作的一个有偏测试集中的所有指标都明显优于基线模型。作者猜想这是因为 PersonalDialog 中的人设是比较稀疏的，所以人工挑选的有偏测试集特意筛选了部分带人设的子集。从表4中可以看出，BoB模型在低资源的条件下仍然表现优秀，只需要八分之一的训练数据模型表现即可超过基线模型。表5中的消融分析可以看出，BoB的编码器和两个解码器都是有效的，减少其中的组件将降低模型性能。 **(Written  by  Wenhua Zhu)**[(BibTex)]([[2106.06169\] BoB: BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data (arxiv.org)](https://arxiv.org/abs/2106.06169))



10.$Quantum-inspired\;Neural\;Network\;for\;Conversational\;Emotion\; Recognition$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

​      $\bullet\;Motivation:$

​	作者提供了一个新的视角，对话情绪识别的类比之间的任务和一个完整的量子化测量。我们描述了在对话中识别说话人情绪的过程中，量子测量的不同步骤，并将它们与一个量子类神经网络缝合起来。

​     $\bullet\;Method:$

​	作者借用现有的算法来学习复值网络权值，使类量子过程以数据驱动的方式进行。我们的模型在两个基准数据集上可以与最先进的方法相比较，并提供了一个理解对话情绪识别的量子观点。

​    $\bullet\;Experimental\;Result:$

​	本研究为对话情绪识别问题提供了一个新的量子视角。构建了一个完整的量子激发网络，融合多模态数据，构建会话上下文，并在此基础上识别每一个话语的情感。	**(Written by Hao Fu)**     [(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Quantum-inspired+Neural+Network+for+Conversational+Emotion+Recognition&btnG=)



11. $Inferring\;Emotion\;from\;Large-scale\;Internet\;Voice\;Data:\;A\;Semi-supervised\;Curriculum\;Augmentation\;based\;Deep\;Learning\;Approach$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

    $\bullet\;Motivation:$

       从用户查询中进行有效的情感推理有助于语音对话应用程序(VDAs)提供更人性化的响应。大量的VDA用户带来了不同的情感表达。如何在vda中实现大规模互联网V语音数据的高情绪推断性能?传统的语音情感识别研究是基于行为语音数据集进行的，该数据集的说话人数量有限，但情感表达强烈而清晰。

     $\bullet\;Method:$

    ​	作者提出了一种利用具有强烈情绪表达的行为语音数据来增强具有不同情绪表达的大规模无标签网络语音数据来进行情绪推断的新方法。具体来说，我们提出了一种新的半监督多模态课程强化深度学习框架。

    $\bullet\;Experimental\;Result:$

    ​	设计了一种基于课程学习的划时代训练策略，它训练作者的模型，该模型由来自行动语音数据的强而平衡的情绪样本引导，然后利用来自互联网语音数据的弱而不平衡的情绪样本。然后，利用Realworld数据集的大规模无标记数据，引入多路径混合匹配多模态深度神经网络(MMMD)，以混合半监督方法有效地训练有标记和无标记数据，具有较好的泛化和鲁棒性。	**(Written by Hao Fu)**     [(BibTex)](https://ojs.aaai.org/index.php/AAAI/article/view/16753)

12. $Directed\;Acyclic\;Graph\;Network\;for\;Conversation\;Emotion\;Recognition\;$ $\textcolor{Red}{(ACL, \;CCF-A)}$ 

    $\bullet\;Motivation:$

       过去基于图的方法做情感会话检测时，容易忽略远处话语和顺序结构。传统的GCN和GAT在处理ERC任务时，在对话语结点周围特征进行迭代聚合时，如果想对远程说话人上下文编码需要堆叠很多层才能做到，但是过多的GNN层可能会由于过度平滑而导致性能下降。

    $\bullet\;Method:$

       将每个会话视为有向无环图。话语构成了节点，话语之间的关系视为边，边的类型1表示这两个相连的话语是由同一说话者说的，0表示其他。这样一来同一个speaker的历史话语就可以由此建模。除此之外，在构建边的时候考虑了remote以及local信息的不同，因为与当前话语相邻的则具有更高的影响力。因此，边需要由以下三点特殊性：1、Direction。这个在类似的论文里都有应用，有向边表示在传递过程中，未来的话语不能被当前所见。2、Remote information。3、Local information。

    $\bullet\;Experimental\;Result:$

       本文构建的DAG-ERC在数据集上的F1-SCORE分别是：MELD : 63.35 ; IEMOCAP : 68.03 ; DailyDialogue : 59.33 ; EmoryNLP : 39.02.因为权小军给的代码及超参数比较详细，所以我尝试复现了他的论文，F1-SCORE分别是： MELD：63.22 ; IEMOCAP : 67.54 ; DailyDialogue : 59.12 ; EmoryNLP : 38.98. 效果都比较接近，且优于之前用图神经网络处理ERC任务的结果。 **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/pdf/2105.12907.pdf)

13. .$Retrieve \;\&\; Memorize\;:\; Dialog \;Policy\; Learning\; with\; Multi-Action\; Memory  $$\textcolor{Red}{(ACL,\;CCF-A)}$

    $\bullet\;Motivation:$

       对话策略学习，决定系统回应生成内容和任务完成度，对于任务引导的对话系统是至关重要的。但是，对话数据集中系统行为的不平衡分布给学习如何产生满意行为和回应带来困难。本文目标是为了提高在task-oriented对话系统中的context-to-response的质量。作者针对现有解决对话中的one-to-many问题的模型方法进行优化，提高候选actions的多样性和对话历史表示的隐藏信息量，从而提高response生成的质量。

    $\bullet\;Method:$

    ​	提出的模型可以分为两部分，context-aware neural retrieval module (CARM) 和 memory-augmented multi-decoder network(MAMD)。CARM是使用预训练语言模型将对话历史和 state 转换为每个样本的context表示，然后使用 context vector 和其他样本的 latent space 表示之间的距离度量来检索多个候选 system actions，这样使得获得的 system actions更加多样化且包含context信息。这些system actions并不是直接用于模型的解码，而是现将其编码成一个memory bank，然后使用MAMD网络在训练过程中动态地配合memory bank生成system actions。除此之外，为了更好的提升模型的稳定性，作者在训练过程中加入了 random sampling机制，即以一定概率随机替换候选的 system actions。

    $\bullet\;Experimental\;Result:$

    ​	本文在面向多领域任务的大规模对话数据集MultiWOZ 2.0和MultiWOZ 2.1上进行了实验。实验结果表明，该方法在上下文-响应生成任务中，在几个最先进的模型中取得了卓越的性能表现**(Written by Wenhua Zhu)**     [(BibTex)]([Retrieve & Memorize: Dialog Policy Learning with Multi-Action Memory (aclanthology.org)](https://aclanthology.org/2021.findings-acl.39.pdf))

14. $Deep \; Context- \; and \; Relation-Aware \; Learning \; for \; Aspect-based \; Sentiment Analysis$$\textcolor{Red}{(ACL,CCF-A)}$

    $\bullet\;Motivation:$

       现有的基于方面的情绪分析（ABSA）采用了统一的方法，允许子任务之间的交互关系。然而，根据作者观察到，这些方法倾向于预测的极性，根据字面意义的方面和意见条款，主要考虑关系隐含在子任务在字级。此外，识别多方面意见对及其极性更具挑战性。因此，在ABSA中，需要全面理解上下文信息w.r.t.方面和观点。

    $\bullet\;Method:$

       在本文中，提出了深层情境化关系感知网络（DCRAN），该网络基于两个模块（即方面和观点传播和显式自我监督策略）允许具有深层情境信息的子任务之间的交互关系。

    $\bullet\;Experimental \; Result:$

       作者为ABSA设计了新颖的自我监督策略，该策略在处理多个方面具有优势。实验结果表明，DCRAN在三个广泛使用的基准测试上显著优于以前最先进的方法。**(Written by Hongfei Xue)**[(BibTex)](https://arxiv.org/pdf/2106.03806.pdf)

15. $Towards \; Generative \; Aspect-Based \; Sentiment \; Analysis$$\textcolor{Red}{(ACL,CCF-A)}$

    $\bullet\;Motivation:$

       基于方面的情感分析（ABSA）最近受到越来越多的关注。 大多数现有工作以区分方式处理 ABSA，为预测设计各种特定于任务的分类网络。 尽管它们有效，但这些方法忽略了 ABSA 问题中丰富的标签语义，并且需要广泛的特定于任务的设计。

    $\bullet\;Method:$

       在本文中，作者建议在统一的生成框架中处理各种 ABSA 任务。 两种类型的范式，即注释式和提取式建模，旨在通过将每个 ABSA 任务制定为文本生成问题来实现训练过程。

    $\bullet\;Experimental \; Result:$

    ​    作者在多个基准数据集上对四个 ABSA 任务进行了实验，其中作者提出的生成方法几乎在所有情况下都实现了最新的最新结果。 这也验证了所提出框架的强大通用性，该框架可以轻松适应任意 ABSA 任务，而无需额外的特定于任务的模型设计。**(Written by Hongfei Xue)**[(BibTex)](https://aclanthology.org/2021.acl-short.64.pdf)

16. $MMGCN:\;Multimodal\;Fusion\;via\;Deep\;Graph\;Convolution\;Network\;for\;Emotion\;Recognition\;in\;Conversation$ $\textcolor{Red}{(ACL, \;CCF-A)}$ 

    $\bullet\;Motivation:$

       在做ERC任务时，往往忽略了对话中多模态的信息。作者希望有效地利用多模态的信息以提升模型的效果，因此探索了一种更有效的方式来对多模态信息和长距离依赖进行建模以提升ERC的效果。

    $\bullet\;Method:$

       首先利用Modality Encoder对三个模态的原始特征进行上下文的编码，然后将对话中一句话对应三个模态的特征和speaker embedding分别进行拼接来构建多模态的图，之后通过多层GCN来进行编码，最后让GCN编码后的特征和图的节点初始化特征进行拼接并送入一个全连接层来完成情感分类。

    $\bullet\;Experimental\;Result:$

       作者一共做了三个实验。一是为了验证MMGCN的效果，基于MELD和IEMOCAP两个数据集，均得到了较SOTA方法更优的的效果。二是为了验证MMGCN多模态融合的有效性，将其与early fusion、lated fusion、fusion through gated attention以及MFN和MulT等融合方法进行了比较，结果显示MMGCN优于其他的多模态融合方法。三是验证了听觉和视觉可以带来额外的信息以提高性能。 **(Written by Weilun Yu)**  [(BibTex)](https://static.aminer.cn/storage/pdf/arxiv/21/2107/2107.06779.pdf)

17. $DialogueCRN:\;Contextual\;Reasoning\;Networks\;for\;Emotion\;Recognition\;in\;Conversations$ 

    $\textcolor{Red}{(ACL, \;CCF-A)}$ 

    $\bullet\;Motivation:$

       作者的motivation来自心理学中的情绪认知理论（Cognitive Theory of Emotion），有人指出人类产生情绪时，通常不是基于对事件的直接认知，而是基于一个迭代的认知-反思-认知-反思的过程。基于此设计出模型，基于Attention机制和LSTM结构，模拟了这一迭代过程。

    $\bullet\;Method:$

       首先使用两个LSTM，分别全局编码以及每个说话人的上下文信息，并将其称为全局记忆；随后对每个句子会经过若干个迭代的reasoning module。Reasoning module的结构：对于每个句子，首先经过一个纵向的LSTM，其hidden state来自上一层reasoning module，这是模拟迭代认知的过程；随后，经过LSTM后的隐藏状态会对Global memory做attention，并且将attention的结果作为本层reasoning module的输出，这是模拟反思的过程。重复以上两个步骤，结束后获得最终的特征，随后将situation-level 与 speaker-level特征相拼接，用于预测最终的结果。

    $\bullet\;Experimental\;Result:$

       在IEMOCAP和SEMAINE数据集上均做出了SOTA效果。 **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/abs/2106.01978)
    
    18.$Efficient\; Speech \;Emotion\; Recognition\; using\; Multi-scale \;CNN \;and\; Attention  $$\textcolor{Red}{(ICASSP,\;CCF-B)}$
    
    ​	$\bullet\;Motivation:$
    
    ​	情感分析在质检， 交互，风控，舆论监督等方面都有着重要的应用。企业可以通过情感分析把握客户的感情偏向，从分析结果中企业可以发现客户希望的服务内容，以及发现当前服务所存在的问题，以便进一步提高服务质量、获客量以及客户满意度。随着通讯技术的发展，当前的沟通方式从单模态的文本形式逐渐发展到包含音频通话的多模态形式，因此情感分析技术也需要从原来只对文本进行情感分析的单模态情况，延伸到结合语音与文本双模态方式。而从技术角度来说，模态的增加也意味着输入信号的增加，是可以进一步提升仅基于文本的情感分析的表现效果。
    
    ​	$\bullet\;Method:$
    
    ​	我们提出采用MSCNN（Multi-scale CNN）来提取音频与文本两种模态的特征，并通过SUP（Statistics Pooling Unit）将提取的多通道特征进行融合，最后利用Attention机制来融合两种模态的特征并进行感情极性的判断，首先对于音频我们提取MFCC特征，对于文本我们提取词向量，MSCNN通过一组卷积核分别对这两者提取特征，我们可以分别用多个卷积核按照上述方法对音频与文本都提取特征。然后使用SPU（Statistical Pooling Unit）对提取出来的特征进行进一步处理。SPU单元采用了多种池化机制来完成对卷积特征的进一步处理，具体的做法是采用三种池化在沿着序列长度的方向进行统计量进行池化。然后attention机制将两种模态进行融合，最后，我们将得到的注意力特征、两个模态所有的SPU特征以及SWEM特征（即用词向量直接平均池化，最大池化）拼接起来作为模型输入分类器前的最终特征使用。
    
    ​	$\bullet\;Experimental\;Result:$
    
    ​	我们在双模态情感分析数据集IEMOCAP上与多个不同的双模态情感分析方法进行了对比，结果表明在双模态时，我们的模型表现全部优于此前的方法，达到了该数据集目前的最佳成绩，同时我们对论文中提出的集中新的模型结构进行了消融实验，结果表明所有的结构都对最后的效果有帮助作用，而其中音频部分的SPU特征提供了最大的贡献。**(Written by Wenhua Zhu)**      [(BibTex)]([Efficient Speech Emotion Recognition Using Multi-Scale CNN and Attention - AMiner](https://www.aminer.cn/pub/60c2b6c491e0117e30ca26b3/efficient-speech-emotion-recognition-using-multi-scale-cnn-and-attention))
    
    

# Recognizing emotion cause

2016：

2017：

2018：

2019：

2020：

2021：

​    1.$Emotion-Infused\;Models\;for\;Explainable\;Psychological\;Stress\;Detection$ $\textcolor{Red}{(NAACL,\;CCF-C)}$

​    $\bullet\;Motivation:$

​	在网络帖子中检测心理压力的问题，更广泛地说，检测处于困境或需要帮助的人的问题，是一个敏感的应用，其中解释模型的能力至关重要。    

​    $\bullet\;Method:$

​	作者提出了一项工作，探索使用一个语义相关的任务，情绪检测，与黑箱模型相比，同样有能力，但更可解释和类似人类的心理压力检测。特别是，作者探索了多任务学习的使用以及基于情感的语言模型微调。

​    $\bullet\;Experimental\;Result:$

​	作者提出了一套情绪增强模型，以不同的方式纳入情绪信息，以增强二元压力预测任务。提出的所有三种模型都实现了与最先进的微调BERT基线相当的性能，而且，更重要的是，我们展示了它们导致了更可解释的模型。	**(Written by Hao Fu)**	[(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=%24Emotion-Infused%5C%3BModels%5C%3Bfor%5C%3BExplainable%5C%3BPsychological%5C%3BStress%5C%3BDetection&btnG=)

# Commonsense knowledge

2016：

2017：

2018：

2019：

1. $KagNet:\;Knowledge-Aware\;Graph\;Networks\;for\;Commonsense\;Reasoning$ $\textcolor{Red}{(EMNLP,\;CCF-B)}$

   $\bullet\;Motivation:$

      针对很多有关机器推理的数据集，常识推理的任务就是从候选答案集合中选择正确的。由于错误答案通常也和上下文相关，所以增大了推理的难度。

   $\bullet\;Method:$

      作者提出一种用于回答常识问题的文本推理框架，该框架使用外部的结构化知识库，用来增强推理结果的可解释性。该框架首先根据Q&A pair从外部知识库中获取子图shema graph。然后使用本文提出的框架KagNet（Knowledge-aware Graph Network）对shema graph进行表示学习，并利用该representations对答案进行评分。KagNet基于GCN和LSTMs，并结合了基于路径的分层注意力网络。使用注意力机制产生的中间注意力得分，让推理过程更加具有可解释性。

   $\bullet\;Experimental\;Result:$

      该论文使用ConceptNet作为外部知识库，在问答（推理）数据集CommonsenseQA上取得了SOA效果。**(Written by Weilun Yu)**  [(BibTex)](https://static.aminer.cn/storage/pdf/arxiv/19/1909/1909.02151.pdf)


2020：

1. $Graph-Based\;Reasoning\;over\;Heterogeneous\;External\;Knowledge\;for\;Commonsense\;Question\;Answering$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

   $\bullet\;Motivation:$

      常识问答往往需要没有在问题中显著表达的背景知识，即如何从外部知识中获取证据并根据证据做出预测。

      来自结构化的知识源包含概念之间的结构关系，对于推理很有帮助，但是它们的覆盖率低。而纯文本知识源是对结构化知识的补充，可以提供丰富且覆盖面广的证据。最近的研究还没有同时利用这两类知识源进行推理的，因此在这项工作中，自动从这两个异构知识源中提取证据，并根据提取的证据回答问题。

   $\bullet\;Method:$

      分为知识提取和基于图的推理两个部分。知识提取：根据给定的问题和选项，从ConceptNet中自动提取图路径，从维基百科纯文本中自动提取句子，再为两种知识源分别构建图。基于图的推理：包含两个模块，基于图的上下文表示学习模块和基于图的推理模块。

   $\bullet\;Experimental\;Result:$

      使用CommonsenseQA数据集进行了实验。实验证实了结合使用ConceptNet和Wikipedia效果得到了很大的提升，说明异构知识源的性能要优于单个知识源和不同知识源。  **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/pdf/1909.05311.pdf)

   

2. $PIQA:\;Reasoning\;about\;Physical\;Commonsense\;in\;Natural\;Language$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

   $\bullet\;Motivation:$

      作者希望人工智能系统能够在不经历物理世界的情况下可靠地回答物理常识问题，捕获有关日常物品的常识知识，包括它们的物理特性、承受能力以及如何操纵它们。因此设计了一个关于物理常识推理任务和相应的基准数据集 PIQA（Physical Interaction： Question Answering）进行评估。

   $\bullet\;Method:$

      PIQA 数据集由 16,000 多个训练的 QA 对组成，另外分别提供了约 2K 和 3K 进行开发和测试。目的长度平均为 7.8 个单词，正确和不正确的解决方案平均长度为 21.3  个单词，正确和不正确解决方案所使用的单词之间至少有 85%  的重叠。通过对名词，动词，形容词，副词出现的词频统计，验证了数据集确实是和物理现象强相关的。比如，出现词频最高的形容词中包括状态（干燥的、干净的、烫的），形状（小的、锋利的、平坦的），形式（快速的、仔细的），这些属性通常决定了解决方案的正确与否。

   $\bullet\;Experimental\;Result:$

      作者在 GPT ，BERT 和 RoBERTa 模型上进行了实验测试，结果表明最好的模型距离人类仍有差不多20%的差距（GPT 69.2%, BERT 66.8%, RoBERTa 77.1%。人类是94.9%。）    **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/pdf/1911.11641.pdf)

2021：

# Self-supervised Learning in conversation

2016:

2017:

2018:

1. $BERT: \;Pre-training\;of\;Deep\;Bidirectional\;Transformers\;for\;Language\;Understanding$ $\textcolor{Red}{(NAACL, \;CCF-C)}$

   $\bullet\;Motivation:$

   ​    作者认为当前的技术严重限制了预训练表示的能力，特别是对于微调方法。主要限制是标准语言模型是单向的，这限制了在预训练期间可以使用的体系结构的选择。例如，在OpenAI GPT中，作者使用了从左到右的体系结构，其中每个令牌只能处理Transformer自我关注层中的前一个令牌。这些限制对于句子级别任务来说是次优的，并且在将基于微调的方法应用于令牌级别任务（例如SQuAD问答）时可能是毁灭性的，在这些任务中，从两个方向合并上下文至关重要。

   $\bullet\;Method:$

      用Transformer的双向编码器表示来改进基于微调的方法。预训练模型BERT通过提出一个新的预训练目标来解决单向约束：“掩盖语言模型”（MLM），被掩盖的语言模型从输入中随机地掩盖一些标记，并且目标是仅基于其上下文来预测被掩盖的单词的原始词汇id。MLM目标允许表示融合左右上下文，这允许我们预训练一个深度双向Transformer。除了masked，还引入了一个“下一句预测”任务，联合预训练文本对表示。

   $\bullet\;Experimental\;Result:$

      BERT在大量的句子级和令牌级任务上实现了最先进的性能，优于许多具有任务特定体系结构的系统。另外作者还做了对BERT的广泛消融，证明了BERT的双向性质是最重要的部分。   **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/pdf/1810.04805.pdf)

2019:

2020:

​	1.**$Latent\;Emotion\;Memory\;for\;Multi-Label\;Emotion\;Classification$ $\textcolor{Red}{(AAAI,\;CCF-A)}$**

​	$\bullet\;Motivation:$

​	现有的方法通常将问题建模为多标签分类任务。然而，以前的方法有两个问题，限制了任务的性能。首先，这些模型没有考虑句子中先前的情绪分布。二是不能有效地捕捉到与相应情绪密切相关的情境信息。

​	$\bullet\;Method:$

​	本文提出了一种用于多标签情绪分类的潜在情绪记忆网络(LEM)。该模型可以在不需要外部知识的情况下学习潜在情绪分布，并有效地将其引入分类网络。

​	$\bullet\;Experimental\;Result:$

​	在两个数据集上的结果显示，作者的模型优于强大的基线，实现了最先进的性能，证明了为任务建模丰富的情绪相关性的有用性。	**(Written by Hao Fu)**       [(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Latent+Emotion+Memory+for+Multi-Label+Emotion+Classification&btnG=)

​    2.$Self-supervised \; Learning \; for \; ECG-based \; Emotion \; Recognition$$\textcolor{Red}{(ICASSP,CCF-B)}$

​    $\bullet Motivation:$

​    作者意图使用自监督学习且基于心电图 (ECG) 的来进行情绪识别。

​    $\bullet Method:$

​     作者提出的架构由两个主要网络组成，一个信号转换识别网络和一个情感识别网络。首先，在自监督学习步骤中，使用未标记的数据成功地训练前一个网络来检测特定的预先确定的信号转换。接下来，该网络的卷积层的权重被转移到情感识别网络，并训练两个密集层以对唤醒和效价分数进行分类。

​    $\bullet Experimental \; Result:$

​     作者提出的自监督方法有助于模型学习情感识别所需的 ECG 特征流形，其性能与模型的完全监督版本相同或更好。作者提出的方法通过两个公开可用的数据集 SWELL 和 AMIGOS 在基于 ECG 的情绪识别方面优于最先进的方法。进一步的分析突出了本文自我监督方法的优势，即需要更少的数据来获得可接受的结果。**(Written by Hongfei Xue)**[(BibTex)](https://static.aminer.cn/storage/pdf/arxiv/19/1910/1910.07497.pdf)

3.$SELF-SUPERVISED \; ADVERSARIAL \; TRAINING$$\textcolor{Red}{(ICASSP,CCF-B)}$

​	$\bullet Motivation:$

   最近的工作表明，神经网络容易受到对抗样本的影响。为了摆脱困境，许多工作尝试以各种方式强化模型，其中对抗性训练是学习鲁棒特征表示以抵抗对抗性攻击的有效方法。同时，自监督学习旨在从数据本身中学习鲁棒性和语义嵌入。基于这些观点，作者在本文中引入了针对对抗性示例的自监督学习。

​	$\bullet Method:$

   作者提出了结合 k-最近邻的自监督表示进行分类。为了进一步加强防御能力，提出了自监督对抗训练，最大化原始示例和相应对抗示例之间的互信息。

​	$\bullet Experimental \; Result:$

   实验结果表明，自监督表示在鲁棒性方面优于其监督版本，自监督对抗训练可以进一步有效地提高防御能力**(Written by Hongfei Xue)**[(BibTex)](https://static.aminer.cn/storage/pdf/arxiv/19/1911/1911.06470.pdf)     

2021:

​	1.$Self-Supervised \; Test-Time \; Learning \; for \; Reading \; Comprehension$ $\textcolor{Red}{(NAACL,CCF-C)}$		

​	$\bullet Motivation:$

​	1)常见的QA模型在回答问题时依赖于所使用的训练数据集，而在所提供的数据集当中有些信息可能会随着时间的推移发生改变，这就会导致模型输出错误的结果。 

​	2)与此同时，有监督的QA模型在对抗性样本(adversarial example)、域外样本(domain shift out of domain)和含有偏见(bias)的样本上表现很差。

​	3)阅读理解任务需要大规模标注，成本较高。 

​	$\bullet Method:$

​	作者提出了一种无监督方法“test-time learning” (TTL)来完成阅读理解任务。让模型在进测试(预测)时根据问题的context上下文，通过自我监督的形式合成训练所需要的问答对，从而进行无监督式的学习，省去了在训练集上的训练过程。

​	$\bullet Experimental \; Result:$

​	提出了Test-time-learning（TTL），一种无监督抽取式问答的训练框架。并根据训练和上下文扩展方法的不同给出了TTL的四个变体，其中使用K-neighboring contexts of the test context方法效果最好。使用四种问答对生成方法进行无监督的抽取式阅读理解模型训练，其中使用QA-SRL作为问答对的生成方法效果最好。文中还比较了大模型（BERT-large）和小模型（DistilBERT)的效果，结果显示两者之间差距不大。**(Written by Hongfei Xue)** [(BibTex)](https://arxiv.org/pdf/2103.11263)

​	2.$Self-supervised \; Bilingual \; Syntactic \; Alignment \; for \; Neural \; Machine \; Translation$ $\textcolor{Red}{(AAAI,CCF-A)}$

​	$\bullet Motivation:$

​	虽然各种神经机器翻译 (NMT) 方法已将单语言句法知识集成到序列的语言表示中，但尚无关于将目标语言的句法结构与相应的源语言句法结构对齐的研究

​	$\bullet Method:$

​	基于 NMT 的词对齐，我们的 SyntAligner 首先对齐源句和目标句的句法结构，然后通过在它们的互信息上引入下限来最大化它们的相互依赖性。在 SyntAligner 中，跨度粒度的句法结构通过将源或目标词隐藏状态转换为源或目标句法跨度向量来表示。边界敏感的跨度注意机制然后捕获源和目标句法跨度向量之间的相关性，它还捕获跨度边界词之间的自我注意作为对齐偏差。最后，基于自监督双语句法互信息最大化的学习目标动态采样对齐的句法跨度以最大化它们的相互依赖性。

​	$\bullet Experimental \; Result:$

​	虽然单语言句法知识已被广泛用于 NMT 任务，但一个开放的挑战是在经典的序列到序列建模中表征源和目标句法结构之间的依赖关系。 作者向前迈进了一步，不仅对齐双语句法结构，还引入了基于自监督互信息最大化的训练目标，结合传统的监督交叉熵训练目标，实现了基于双语句法一致性的翻译。**(Written by Hongfei Xue)** [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-452.ZhangT.pdf)

​    3.$Learning\;Modality-Specific\;Representations\;with\;Self-Supervised\;Multi-Task\;Learning\;for\;Multimodal\;Sentiment\;Analysis$$\textcolor{Red}{(AAAI,\;CCF-A)}$

​    $\bullet\;Motivation:$

   由于多模态标注只能给三个模态定一个统一的标签，现有的方法在获取差异化信息方面受到限制。但是，额外的单模态注释会带来很高的时间和劳动力成本。

​    $\bullet\;Method:$

   本文基于自监督学习策略设计了标签生成模块用于获得每一个单独模态的标签，并且联合多模态和单模态学习任务分别学习一致性和不同性。另外，还在训练阶段设计了权重调节策略来平衡不同子任务之间的学习进展，这是为了指导子任务将重点放在模态之间差异较大的采样上。

​    $\bullet\;Experimental\;Result:$

   本文在MOSI和MOSEI数据集上做了实验，实验结果证明本文的方法优于当前SOTA方法，并且在具有人工标注的SIMS数据上，验证了该方法取得了与人工标注的单模态标签相当的性能。**(Written by Yuzhao Chen)**  [(BibTex)](https://arxiv.org/abs/2102.04830)

​    4.$Learning \; Modality-Specific \; Representations \; with \; Self-Supervised \; Multi-Task Learning \; for \; Multimodal \; Sentiment \; Analysis$$\textcolor{Red}{(AAAI,CCF-A)}$

​	$\bullet Motivation:$

​    有效的模态表示应该包含两部分特征：一致性和差异性。由于统一的多模态注释，现有方法在捕获差异化信息方面受到限制。然而，额外的单模态注释是高时间和劳动力成本。

​	$\bullet Method:$

​    在本文中，作者设计了一个基于自监督学习策略的标签生成模块来获得独立的单峰监督。然后，联合训练多模态和单模态任务，分别学习一致性和差异性。此外，在训练阶段，作者设计了权重调整策略来平衡不同子任务之间的学习进度。即引导子任务专注于模态监督差异较大的样本。

​	$\bullet Experimental \; Result:$

​    作者设计了一种基于自监督方法的单峰标签生成策略，节省了大量人力成本。 大量实验验证了自动生成的单峰标签的可靠性和稳定性，这为多模态表示学习提供一个新的视角。但是在生成的音频和视觉标签受预处理特征的限制不够显着，所以单模态和多模态学习之间的关系还需要继续探索。**(Written by Hongfei Xue)**[(BibTex)](https://arxiv.org/pdf/2102.04830)

# Others (NLP)

2016:

1.$Emotion \;Distribution \;Learning\; from\; Texts$$\textcolor{Red}{(EMNLP,\;CCF-B)}$

​	$\bullet\;Motivation:$

​	社交媒体的出现和繁荣让用户能够分享自己的观点和观点。了解用户的情绪状态可能会提供创造新业务机会的潜力。从文本中自动识别用户的情绪状态，并将其划分为喜悦、愤怒、厌恶等有限的类别，可视为文本分类问题。然而，它引入了一个具有挑战性的学习场景，在一个句子中经常会出现不同强度的多种情绪。此外，一些情绪更常同时出现，而其他情绪很少同时出现。

​	$\bullet\;Method:$

​	将基本情绪之间的关系作为约束纳入学习框架，提高情绪检测的准确性。为了避免训练数据中包含的噪声信息，基于情绪轮理论对关系约束进行了设置。通过引入情绪分布学习框架，可以使用许多不同的标准来度量真实分布和预测分布之间的距离，如平方x2，欧几里德，Jeffery 's散度除了在logistic回归模型中使用的Kullback-Leibler散度外，还有很多不同的标准。基于普鲁契克情绪轮理论捕捉基本情绪之间的关系，避免训练数据中含有干扰信息，本文对此轮进行了改进。为了与MLL方法进行比较，需要将预测分布中的标签划分为相关集和不相关集。为此，在标签集中增加一个额外的虚标y0，即扩展的标签集Y ' = Y∪{y0}={y0, y1, y2，…yc}。利用训练过程中设置的新的扩展标签，学习最优参数向量θ∗。因为y0是直接区分相关和不相关情绪的标签，所以初始化为MLL中使用的阈值。给定一个句子x '，它的情绪分布由p(y|x ';θ∗)预测。强度值y0将预测分布分成两个集合。强度值大于y0的情绪视为相关情绪，其余情绪视为无关情绪。因此，EDL实际上实现了MLL的功能，而不需要手工设置阈值。

​	$\bullet\;Experimental\;Result:$

​	实验结果表明，该方法能有效地处理情绪分布检测问题，性能明显优于现有的情绪检测方法和多标签学习方法。**(Written by Wenhua Zhu)**     [(BibTex)]([palm.seu.edu.cn/xgeng/files/emnlp16.pdf](http://palm.seu.edu.cn/xgeng/files/emnlp16.pdf))

2017:

1. $Model-Agnostic\; Meta-Learning\; for\; Fast \;Adaptation\; of \;Deep\; Networks\;  $$\textcolor{Red}{(ICML,\;CCF-A)}$

   $\bullet\;Motivation:$

      快速学习是人类智慧的一大特点，无论是从几个样本中识别物体还是通过几分钟的体验学习新技能。我们的人工智能体应该具有从少量样本中快速学习和自适应一个模型，并且对大数据样本依然可有效使用的能力。为了克服快速和可适应性性学习的挑战，本文提出基于元学习的未知模型，目的是在多样的学习任务中训练一个模型，仅用少量的训练样本就可以很快的处理新的学习任务。

   $\bullet\;Method:$

      主要流程：首先获得不同任务的分布表示（矢量级别的），设置两个不同的学习步长a,b，初始化模型参数后开始训练，先在任务分布表示中采样一个batch，在该batch中有不同的任务，对每一个子任务进行K-examples的评估损失和梯度，采用SGD更新参数值，这样实现了小样本的元学习（个人观点，因为是在这里体现了样本少），batch走完后，利用步长b再次计算损失和梯度（此时模型的参数是被batch更新过的），利用SGD获取最终的参数。该过程的迭代次数可以变化。以此达到在新任务中使用少量的梯度步骤便可获得最大化效率。（问题：这些任务是否是有关联的呢?相同任务的内部参数自然是要优于随机参数的；如果任务跨度太大，模型还有意义吗？）

   $\bullet\;Experimental\;Result:$

      本文实验表明，该MAML方法可以很好地用于分类，回归和强化学习任务中，可以快速学习。就从算法流程来看，应该可以很好的嵌入多任务学习中。**(Written by Wenhua Zhu)**     [(BibTex)]([Model-agnostic meta-learning for fast adaptation of deep networks | Proceedings of the 34th International Conference on Machine Learning - Volume 70 (acm.org)](https://dl.acm.org/doi/10.5555/3305381.3305498))

2018:

1.$Label\; Enhancement\; for\; Label\; Distribution\; Learning \; $$\textcolor{Red}{(IJCAL,\;CCF-A)}$

​	$\bullet\;Motivation:$

​	多标记学习任务MLL处理一个示例对应多个标记的情况，其目标是学习一个从示例到相关标记集合的映射，在MLL中，现有方法一般都是采用均匀标记分布假设，也就是各个相关标记对于示例的重要程度被当做是相等的。然而，对于许多真实世界中的学习问题，不同相关标记的重要程度往往是不同的。为此，标记分布学习将不同标记的重要程度用标记分布来刻画。

​	$\bullet\;Method:$

​	LDL任务的主要困难之一就是，标签分布是十分难以获取的。大多数的分类数据集都不具备这样的条件，都只有一些ligical label。所谓logical label，就是指one-hot或者multi-one-hot的label。要获取真实的标签分布，理论上是需要对同一样本进行大量的打标，得到其统计分布的，但这背后的人工成本是无法承受的。既然无法从外部得到样本的标签分布，那就使用样本集自身的特征空间来构造出这样的标签分布。经典LE方法：**Fuzzy C-Means(FCM)**，**Label Propagation（LP）**和**.Mainifold Learning（LM）**[1]。本文的方法基于图的思想，在训练标签预测模型的同时，也考虑学习标签间的相似性。

[1]: https://cloud.tencent.com/developer/article/1771806

​	$\bullet\;Experimental\;Result:$

​	将生成的和一些已有的带标签分布的数据集中的标签分布处理为逻辑标签，运行 GLLE 算法还原为标签分布，计算与原标签分布的相似度或距离作为评估。GLLE的效果很好，但是LP也是又好又简单，GLLE的调参麻烦。**(Written by Wenhua Zhu)**     [(BibTex)]([Label Enhancement for Label Distribution Learning (aminer.cn)](https://static.aminer.cn/upload/pdf/program/5b67b46417c44aac1c8612a4_0.pdf))

2019:

1.$Utilizing \; BERT \; for \; Aspect-Based \; Sentiment \; Analysis \; via \; Constructing \; Auxiliary \; Sentence$$\textcolor{Red}{(NAACL,CCF-C)}$

​	$\bullet Motivation:$

   最近，预训练的语言模型，已经显示出它们在缓解特征工程的努力。 尤其是BERT在QA和NLI方面取得了优异的成绩。 然而，直接使用预训练的 BERT 模型在ABSA 任务中并没有太大的改进。 我们认为这是由于对预训练的 BERT 模型使用不当造成的。

​	$\bullet Method:$

   BERT 的输入表示既可以表示单个文本句子，也可以表示一对文本句子，可以将ABSA 转换为句子对分类任务，并对预训练的 BERT 进行微调。

​	$\bullet Experimental \; Result:$

   提出了ABSA（细粒度情感分析任务）的新解决方案，将其转换为句子对分类任务。对预训练的 BERT 模型进行了微调，并在 SentiHood 和 SemEval-2014 任务 4 数据集上取得了最新的最新成果。**(Written by Hongfei Xue)**[(BibTex)](https://arxiv.org/pdf/1903.09588.pdf)

2.$Heterogeneous\;Graph\;Attention\;Network$ $\textcolor{Red}{(WWW, \;CCF-A)}$ 

$\bullet\;Motivation:$

   GNN在深度学习领域表现出了强大的性能。但是，在包含不同节点和边的HIN领域，GNN做的还不够完善。作者基于此提出了一种新的异构图神经网络分层注意力机制，涉及到节点级别和语义级别。

$\bullet\;Method:$

   模型分为Node-level Attention和Semantic-level Attention两部分。首先使用指定的元路径获取邻居节点。然后使用分层注意力：节点注意力，元路径注意力聚合邻居从而获取目标节点的嵌入。最后根据分类任务训练模型。

$\bullet\;Experimental\;Result:$

   实验过程用到了DBLP、ACM、IMDB三个数据集，相比于GCN、GAT、HAN of Node、HAN of Semantic、HAN，从分类、聚类的实验结果来看，HAN基本上都是最优的。 **(Written by Weilun Yu)**  [(BibTex)](https://dl.acm.org/doi/10.1145/3308558.3313562)



3.$Graph\;Transformer\;Networks$  $\textcolor{Red}{(NeurIPS, \;CCF-A)}$

$\bullet\;Motivation:$

   异构图分析的很多文章都需要指定元路径，但是这需要很强的先验知识，元路径选的不好会极大的影响模型的效果。为此作者设计了Graph Transformer Networks(GTN)可以自动的逐步生成对任务有用的元路径，省去了人工指定带来的偏差。

$\bullet\;Method:$

   模型构造分为卷积层GCN和GT层。卷积层用了以往图卷积网络的聚合方式。GT层输入有K个通道，每个通道为NxN矩阵，然后经过1x1xK的卷积进行处理生成NxN的中间态邻接矩阵Q1。得到两个软选择的邻接矩阵Q1,Q2，新生成meta-path图对应的邻接矩阵就是A(1)=Q1*Q2。将GT层和GCN层结合起来，构成GTN模型。

$\bullet\;Experimental\;Result:$

   实验结果表明，GTN可以学习一种新的图结构，其中包含有用的元路径用于学习更有效的节点表示，性能较之预定义的元路径更优。 **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/pdf/1911.06455.pdf)

4.$Multi-Label\; Learning\; with\; Label\; Enhancement  $$\textcolor{Red}{(arXiv)}$

​	$\bullet\;Motivation:$

​	多标签学习的任务是为不可见的实例预测一组相关的标签。 传统的多标签学习算法将每个类标签视为对应标签与实例是否相关的逻辑指示器，即+1表示与实例相关，-1表示与实例不相关。 用-1或+1表示的标号称为逻辑标号。 逻辑标签不能反映不同的标签重要性。 然而，对于现实世界的多标签学习问题，每个可能的标签的重要性通常是不同的。 在实际应用中，直接获取标签的重要信息是很困难的。 因此，我们需要一种从逻辑多标签数据中重构标签本质重要性的方法。

​	$\bullet\;Method:$

​	 为了解决这个问题，我们假设每个多标签实例都由一个潜在实值标签向量来描述，它可以反映对应标签的重要性。 这种标号称为数字标号。 利用逻辑标签信息和特征空间中的拓扑结构，从逻辑多标签数据中重构数字标签的过程称为标签增强。 在本文中，我们提出了一种新的多标签学习框架LEMLL，即标签增强多标签学习，将数字标签的回归和标签增强整合到一个统一的框架中。 

​	$\bullet\;Experimental\;Result:$

​	大量的对比研究表明，标签增强可以显著提高多标签学习的性能，LEMLL可以有效地从逻辑多标签数据中重构潜在的标签重要性信息。**(Written by Wenhua Zhu)**     [(BibTex)]([[1706.08323\] Multi-Label Learning with Label Enhancement (arxiv.org)](https://arxiv.org/abs/1706.08323))

​	5.$Classification\; with\; Label \;Distribution\; Learning$$\textcolor{Red}{(IJCAL,\;CCF-A)}$

​	$\bullet\;Motivation:$

​	标签分布学习(LDL)是一种新的学习范式，其目标是最小化模型输出与基本事实标签分布之间的距离。我们注意到，在实际应用中，学习到的标签分布模型通常被视为一个分类模型，与最高模型输出相对应的标签作为预测标签，这不幸地提升了训练短语和测试短语之间的不一致。

​	$\bullet\;Method:$

​	本文提出了一种新的标签分布学习分类算法(LDL4C)。首先，用绝对损耗代替kl发散作为LDL4C的度量。其次，利用信息熵对样本进行加权。第三，采用大边缘分类器提高识别精度。我们揭示了LDL4C在理论上寻求的是泛化和区别化之间的平衡。LDL的训练阶段和测试阶段的目标不一致在训练阶段，LDL的目标是最小化模型输出与ground-truth标签分布之间的距离，而在测试阶段，目标是最小化0/1误差。在本文中，我们解决了这种不一致性。为了缓解这种不一致性，我们提出了三种改进方法，即绝对损失法、熵信息加权法和大边缘法。应用绝对损失和引入大边缘是受到理论论证的启发，用信息熵重新加权样本是基于观察LDL的度量值与相应分类模型的度量值之间的差距。

​	$\bullet\;Experimental\;Result:$

​	在17个实词数据集上，我们将LDL4C与现有的LDL算法进行了比较，实验结果证明了LDL4C在分类中的有效性。**(Written by Wenhua Zhu)**     [(BibTex)

6.$Lexicon\; Enhanced\; Chinese \;Sequence\; Labeling\; Using\; BERT\; Adapter  $$ \textcolor{Red}{(ACL,\;CCF-A)}$

​	$\bullet\;Motivation:$

​	近年来，将外部词汇信息特征与预训练模型相融合是提高序列标注任务（如NER）效果的重要方法之一，比如FLAT、WC-LSTM等，但是，现有方法仅通过浅层模型表示和随机初始化的序列层融合词汇特征，并未与预训练模型如BERT进行融合。本文作者提出了用于中文序列标签的Lexicon增强BERT（LEBERT），通过一个Lexicon adapter层将外部词汇信息直接融合到BERT层中，与现有方法相比，LEBERT模型有助于在BERT的较低层进行深度词汇知识融合。

​	$\bullet\;Method:$

​	常见一种将词汇信息与预训练模型相融合的方案是将预训练模型（如BERT)输出与词汇特征通过一个融合层（比如线性层）得到融合向量。本文作者认为该方案并没有充分利用到预训练模型的表示能力，因为外部词汇信息未融合到预训练模型之中，于是提出了另一种融合方案，该融合方案将外部词汇信息与BERT模型中的某个层中，这使得字信息与词汇能够通过BERT模型强大的表示能力进行更有效的融合,LEBERT将字符和词典特征都作为输入，即将中文句子转换成一个Char-Words Pair Sequence。在Transformer层之间应用一个Lexicon Adapter层连接，使得词汇信息能够有效地融合到BERT中。将输入数据构建成Char-Words Pair Sequence形式之后，句子中的每个位置包含了字符特征和词汇特征。为了把词汇特征融合到BERT当中，作者设计了Lexicon Adapter结构，Lexicon Adapter的输入为Char-Words Pair Sequence。每个字符包含多个词，对于不同任务而言，每个词的贡献不一样，因此，为了从所有词汇列表中获得最相关的词，作者使用了注意力机制对$V_i$的m个词向量进行融合。LEBERT可以看做是Lexicon Adapter和BERT的组合，其中Lexicon Adapter层应用到了BERT当中的某一个transformer层中。

​	$\bullet\;Experimental\;Result:$

​	为了探究LEBERT在序列标注任务上的有效性，本文在三个任务共10个数据集上实验：中文命名实体提取、中文分词和中文词性标注。LEBERT在NER任务上的效果，性能超过目前最先进的词增强NER模型，中文分词任务、中文词性标注任务中达到了最优效果。Lexicon Adapter层的不同位置实验结果表明LA层应用到浅层实现了更好的性能，这可能是因为浅层促进了预训练模型表示特征和词汇特征之间更多层次的相互作用。而在LA应用到多层中会损害性能，可能原因是多层集成导致过度拟合。**(Written by Wenhua Zhu)**     [(BibTex)



2020:

1.$Enhancing\;Extractive\;Text\;Summarization\;with\;Topic-Aware\;Graph\;Neural\;Networks$ $\textcolor{Red}{(COLING,\;CCF-B)}$

$\bullet\;Motivation:$

   现有的摘要抽取模型很难捕捉到内部关系，尤其是在长文档中。同时经常忽略主题信息对获取重要内容的影响。基于此，作者提出一种基于图神经网络的抽    取摘要模型，能够通过图结构的文档表示来有效地捕获内容间的关系。

$\bullet\;Method:$

   模型由三部分组成，1) document encoder文档编码器, 2) neural topic model神经主题模型,3) graph  attention  layer图形注意层。文档编码器是在给定输入文档的情况下，通过预训练的BERT学习每个句子的上下文表示。神经主题模型用来学习文档主题分布和一组主题表示。图形关注层构建一个包含主题和句子的异构文档图，然后同时更新它们的节点表示。在图形编码后，句子表示进一步与主题结合，然后发送到句子分类器来计算最终的标签。

$\bullet\;Experimental\;Result:$

   在四个数据集上进行了实验，模型在新闻文章数据集上取得了与最先进的摘要模型相当的结果，在科学论文数据集上显著优于现有的方法，表明它在各种文档类型和长度上具有很强的鲁棒性。   **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/ftp/arxiv/papers/2010/2010.06253.pdf)

2.$Where\;to\;Go\;Next:\;Modeling\;Long-\;and\;Short-TermUser\;Preferences\;for\;Point-of-Interest\;Recommendation\;$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

 $\bullet\;Motivation:$

​	本文作者指出现有基于rnn的方法在对用户的短期偏好建模时，要么忽略了用户的长期偏好，要么忽略了最近访问的Point-of-Interest (POI)之间的地理关系，导致推荐结果不可靠。

 $\bullet\;Method:$

​	本文提出了一种基于长短期偏好模型( Long- and Short-Term Preference Mod-eling (LSTPM))的下一个(POI)推荐方法。特别地，该模型由一个用于长期偏好建模的非局部网络和一个用于短期偏好学习的地理扩张RNN组成。

 $\bullet\;Experimental\;Result:$

​	与现有的推荐方法相比，作者在本文中提出的方法大大提高了推荐的精度。虽然作者提出的方法优于所有基线，但是低回忆的NDGG分数仍是POI推荐中的一个共同问题。	**(Written by Hao Fu)**      [(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Where+to+Go+Next%3A+Modeling+Long-+and+Short-Term+User+Preferences+for+Point-of-Interest+Recommendation&btnG=)

3.$A\;Co-Interactive\;Transformer\;for\;Joint\;Slot\;Filling\;and\;Intent\;Detection$ $\textcolor{Red}{(ICASSP,\;CCF-B)}$

 $\bullet\;Motivation:$

​	意图检测和插槽填充是构建口语理解系统的两个主要任务。这两个任务是密切相关的，一个任务的信息可以在另一个任务中利用。以往的研究要么分别模拟两个任务，要么只考虑从意图到槽的单一信息流。

  $\bullet\;Method:$

​	作者提出了一个协同互动变压器，以考虑两个任务之间的交叉影响。提出了一个协同交互模块，通过建立两个相关任务之间的双向连接来考虑交叉影响，而不是采用普通Transformer中的自注意机制。

  $\bullet\;Experimental\;Result:$

​	作者提出了一个联合模型槽填充和意图检测的协同交互转换器，以建立两个任务之间的方向连接，从而充分利用相互交互的知识。此外，所提出的协同交互模块可以进行堆叠，逐步更好地模拟相互之间的交互。	**(Written by Hao Fu)**      [(BibTex)](https://ieeexplore.ieee.org/abstract/document/9414110)

4.$Two-Level\;Transformer\;and\;Auxiliary\;Coherence\;Modeling\;for\;Improved\;Text\;Segmentation$ $\textcolor{Red}{(AAAI, \;CCF-A)}$

$\bullet\;Motivation:$

   文本的连贯性与文本的分割具有本质上的紧密联系，分割后同一部分的文本之间的连贯性强于不同部分的文本。依据语义连贯性解构长文本能够提升文本的可读性，有益于下游任务，而现存的文本分割方法都仅仅隐式的使用连贯性这项特征。作者希望提出一种监督模型除了以预测分割结果作为目标以外，还能对连贯性进行建模并应用在训练过程中。

$\bullet\;Method:$

   由两层Transformer构成的监督模型，低层编码句子，高层编码句子序列。接收定长句子序列作为输入，字符编码由预训练词嵌入和位置嵌入连接得到。句子序列首先通过字符级Transformer得到句子表示，再经句子级Transformer强化上下文信息。编码器输出经过一前馈二分类器对各句进行分类。另将编码后的句子序列输入另一前馈网络获取一个连贯性分数。

$\bullet\;Experimental\;Result:$

   在两项任务上进行训练，分别为预测句子分段标签和对比正确分段和错误分段的连贯性。该模型在多个文本分割数据集上取得sota，且能够实现向其他语言的零样本迁移。  **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/abs/1710.10903)

5.$Revisiting \; Pre-trained \; Models \; for \; Chinese \; Natural \; Language \; Processing$$\textcolor{Red}{(EMNLP,CCF-B)}$

$\bullet Motivation:$

   来自 Transformers (BERT) 的双向编码器表示在各种 NLP 任务中显示出惊人的改进，并且已经提出了连续的变体以进一步提高预训练语言模型的性能。 本文的目标是重新审视中文预训练语言模型，以检查它们在非英语语言中的有效性，并向社区发布中文预训练语言模型系列。

$\bullet Method:$

   提出了一个新的预训练模型MacBERT，通过用其相似的单词来掩盖单词，从而缩小训练前和微调阶段之间的差距。为了进一步加快对中文NLP的研究，创建了中文预训练模型系列并发布到社区。

$\bullet Experimental \; Result:$

   MacBERT 在BERT(Bidirectional Encoder Representations from Transformers )的各个改进版本之上的，持续优化训练的策略：（1）对于MLM任务，使用全词mask和ngram mask策略，mask的词使用相似词替换，减少训练和微调之间的误差：（2）使用albert的SOP任务；在下游的任务中，比之前的bert版本效果均要好。**(Written by Hongfei Xue)**[(BibTex)](https://aclanthology.org/2020.findings-emnlp.58.pdf)

6.$Neural\;Extractive\;Summarization\;with\;Hierarchical\;Attentive\;Heterogeneous$ $\textcolor{Red}{(EMNLP, \;CCF-B)}$ 

$\bullet\;Motivation:$

   在给定的篇章中，选出其中关键的句子作为这篇文章的摘要。以往的抽取式摘要工作有两个缺陷：依赖前文句子的预测标签，来判断当前句子是否应该被选择，这存在误差级联和曝光偏差的问题；以往工作总是在所有的文章中选择Top K个句子作为摘要句子，然而，在现实中，将不同篇章的摘要句子数量规定为同一个常量是不合理的。

$\bullet\;Method:$

   提出了HAHSum (Hierarchical Attentive Heterogeneous Graph for Text Summarization) 模型，将每篇文章建模为一个异质图，图中包含三种类型的节点(word, entity, sentence)对不同语义粒度的信息建模，和四种类型的边来表示不同的结构信息；基于这些边和点， HAHSum包含三种子图，可以分别用三种邻接矩阵表示:词/实体级别子图；词/实体与句子相互交互的子图；句子级别的子图。具体HAHSum模型有以下几个模块组成：ALBERT Encoder：用ALBERT进行基础的编码，得到每个词和句子的表示；Abstract Layer：学习每个词的语义表示，具体由三层图注意力构成：第一个GAT Layer: 得到word-word间的交互的词节点表示；后两层GAT: 得到交互句子表示后的词表示以及句子节点的初始表示；Redundancy Layer: 目的在于建模句子间的信息冗余关系；Output Layer: 同时对所有句子的标签(是否保留为摘要句子)进行预测。

$\bullet\;Experimental\;Result:$

   作者分别在CNN/DailyMail 、NYT 、Newsroom(Ext)三个数据集上进行了实验，都取得了sota效果。 **(Written by Weilun Yu)**  [(BibTex)](https://aclanthology.org/2020.emnlp-main.295.pdf)

7.$Look\;at\;the\;First\;Sentence:\;Position\;Bias\;in\;Question\;Answering$$\textcolor{Red}{(EMNLP,\;CCF-B)}$

$\bullet\;Motivation:$

  许多提取的问题回答模型被训练来预测答案的开始和结束位置。预测答案作为位置的选择主要是由于其简单性和有效性。

$\bullet\;Method:$

  这篇文章提出了一个有趣的问题：答案分布可能在训练集中存在高度偏移，例如多个答案固定分布在第 k 句，这种偏移可能会误导模型。文章首先在多个模型上验证了这种误导的确存在，研究了偏移模型的失效原因，随后用多种去偏移化方法训练模型。证明了答案位置的先验分布有助于建立位置去偏移模型，改善模型性能。

$\bullet\;Experimental\;Result:$

  实验中发现，使用答案位置的先验分布为模型降低偏移效果非常有效。**(Written by Yuzhao Chen)** [(BibTex)](https://arxiv.org/abs/2004.14602)



2021:

1.$Who\;Responded\;to\;Whom:\;The\;Joint\;Effects\;of\;Latent\;Topics\;and\;Discourse\;in\;Conversation\;Structure$ $\textcolor{Red}{(EMNLP,\;CCF-B)}$

$\bullet\;Motivation:$

   捕捉多方对话中谁对谁的回应是至关重要的，这是建立和理解对话结构的基础。

$\bullet\;Method:$

   作者定义了initiation-response pairs（发起-响应 对），并参考了来自不同参与者的对话话语的发起和响应。首先在结合上下文cr和cq的情况下学习响应r和候选发起q的潜在主题和潜在话语因素。然后，进行话语匹配，用来测量主题一致性和话语依赖性。最后，预测S(q,r)-r响应q的可能性。

$\bullet\;Experimental\;Result:$

   收集两个对话数据集，来自CMV subreddit的英文CMV数据集和来自Wangwang客户服务平台的另一个中文名称为CS的CMV数据集用于实验。两个数据集的比较结果，本文提出的模型在所有设置下都取得了最好的结果。   **(Written by Weilun Yu)**  [(BibTex)](https://static.aminer.cn/storage/pdf/arxiv/21/2104/2104.08601.pdf)

2.$Informer:\;Beyond\;Efficient\;Transformer\;for\;Long\;Sequence\;Time-Series\;Forecasting$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

   Transformer存在self-attention时间复杂度和空间复杂度过高、多层会导致长输入消耗的显存过多和预测长输出时速度太慢的问题。基于此，作者提出了Informer改进Transformer。

$\bullet\;Method:$

   Informer的改进有三个部分，用ProbSparse self-attention代替普通self-attention，降低时空复杂度。self-attention distilling operation：在每两层之间过滤出决定性的attention score，降低网络宽度，解决消耗显存过多的问题。Generative Style Decoder使输出长序列只需一步，解决输出速度太慢的问题。

$\bullet\;Experimental\;Result:$

   作者在单变量和多变量时间序列下进行预测，单变量下，Informer的表现比其他模型都好，且随时间窗口长度增加，预测错误率的增加缓慢；Informer比使用传统self-attention的Informer表现好，说明sparse的假设是正确的。多变量下，比其他模型好，但没有单变量那么突出。   **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/pdf/2012.07436.pdf)



3.$TWAG:\;A\;Topic-guided\;Wikipedia\;Abstract\;Generator$$\textcolor{Red}{(ACL,\;CCF-A)}$

$\bullet\;Motivation:$

   目前，大多数的摘要生成方法都将文档视作为普通文本(plain text)，而忽略了文档中的实体信息和文档结构信息。而维基百科的词条介绍本身附带人工归纳的目录信息(content table)，其中涉及的方面(aspect)可以作为相应段落话题(topic)的归纳。

$\bullet\;Method:$

   该篇文章便是将目录页所归纳的方面作为摘要生成的关键指导信息，进一步优化生成式摘要的效果。作者提出了TWAG，一种利用维基百科中的主题信息建立的两阶段抽象神经维基百科摘要生成模型，它能够生成全面的摘要。模拟了人类识别对象的方式，使用分类器将输入文档划分为主题，然后根据每个抽象句子预测的主题分布进行主题感知抽象生成。

$\bullet\;Experimental\;Result:$

   文章在WikiCatSum数据集上进行了实验，其包含了商业、电影、动物3个领域的词条。作者通过词条目录构造了相应的主题标签。与摘要生成的基础模型相比，文章提出的模型都有较大提升。**(Written by Yuzhao Chen)**  [(BibTex)](https://arxiv.org/abs/2106.15135)



4.$An\;Adaptive\;Hybrid\;Framework\;for\;Cross-domain\;Aspect-based\;Sentiment\;Analysis$$\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

   跨领域细粒度情感分析任务旨在利用源域中的有用知识来提取方面项并预测它们在目标域中的情感极性。在这些方法中，源数据和目标数据都被用来通过欺骗域鉴别器来学习域不变特征。但是，任务分类器只在源数据上进行训练，导致任务分类器无法利用目标数据中的aspect和sentiment信息。

$\bullet\;Method:$

   本文提出了一个关于跨领域细粒度情感分析任务的自适应混合框架(AHF)。将基于伪标签的半监督学习和对抗训练整合到一个统一的网络中。因此，目标数据不仅可以通过域识别器的训练来对特征进行对齐，还可以用来细化任务分类器。此外，作者还设计了一个自适应mean teacher模型作为网络的半监督部分，它可以缓解噪声伪标签对目标数据的影响。

$\bullet\;Experimental\;Result:$

   在公共数据集上的大量实验结果表明，本文的AHF框架始终优于其他的方法。**(Written by Yuzhao Chen)** [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-2184.ZhouY.pdf)



5.$A\;Joint\;Training\;Dual-MRC\;Framework\;for\;Aspect\;Based\;Sentiment\;Analysis$$\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

   细粒度的情感分析任务(ABSA)任务中涉及三类对象：方面项提取、观点项提取和方面级别的情感分类。在最近的工作中，3个提取任务同时进行被提出，如在一个句子中提取（方面项、观点项、情感极性）的三元组。然而，早先的方法都难以在一个统一的端到端的结构中处理所有的子任务。

$\bullet\;Method:$

   作者将主要工作放在了提取(a,o,s)三元组上，在该论文中，作者提出了一个合并的训练结构来处理所有的ABSA子任务。作者使用了BERT作为骨干网络，并且使用了一个基于跨度的模型来预测ATs/OTs在句子中的起始位置。将原始的三元组的提取任务转化为两个机器阅读理解(MRC)问题。这个三元组的提取任务可以被分解为AE(AT Extraction)，AOE(aspect-oriented OT extraction)和SC(aspect-level sentiment classification)任务，用left MRC处理AE，用right MRC处理AOE和SC。

$\bullet\;Experimental\;Result:$

   本文在这些子任务上进行了实验，在几个基准数据集上得到的结果证明了提出的框架的有效性，它显著优于现有的最先进的方法。**(Written by Yuzhao Chen)** [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-5353.MaoY.pdf)



6.$Hi-Transformer:\;Hierarchical\;Interactive\;Transformer\;for\;Efficient\;and\;Effective\;Long\;Document\;Modeling$ $\textcolor{Red}{(ACL, \;CCF-A)}$ 

$\bullet\;Motivation:$

   文档的长度较长，如果用 Transformer 去建模长文档，计算开销会很大。通常的做法是对长文档进行截断，但是这样会造成文档输入信息不全，影响最终的文档建模效果。对此，作者希望基于长文档由多个句子组成，不同句子的语义既相对完整自洽这两个点进行改进。

$\bullet\;Method:$

   作者设计了层次化和交互式的Transformer模型Hi-Transformer来实现高效和准确的长文档建模。首先用 Sentence Transformer来学习每个句子的语义表示。然后用Document Transformer从文档内部所有句子的语义表示中建模整个文档的 Global context，并得到 Document context-aware 的句子语义表示，进而将其输入到另一个 Sentence Transformer 中，以实现利用 Global document context 来增强每个句子语义学习的目标。最后，使用层次池化方法获得文档的表示。

$\bullet\;Experimental\;Result:$

   在 Amazon、IMDB 和 MIND 等三个长文档数据集上开展了实验。实验结果显示 Hi-Transformer 在长文档建模上的性能要优于 Transformer及其多个加速变体， Hi-Transformer 的计算复杂度显著小于 Transformer，并与已有的一些加速变体相当。之后进一步比较了 Transformer 和 Hi-Transformer 在不同文档长度下的性能和速度。当输入同样长度文档时，二者的性能非常接近。当文档长度较长时，Hi-Transformer 的速度显著优于 Transformer。因此，Hi-Transformer 能够处理  Transformer 由于速度和显存限制而无法处理的较长文档，并且能够取得和 Transformer 接近的效果。   **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/abs/2106.01040)

7.$DeepRapper:\;Neural\;Rap\;Generation\;with\;Rhyme\;and\;Rhythm\;Modeling$ $\textcolor{Red}{(ACL, \;CCF-A)}$ 

$\bullet\;Motivation:$

   作者想要设计出自动生成rap的模型。但是还存在一些挑战：一方面，由于没有现存的含有节奏信息的数据集，之前的 Rap 生成系统只能生成纯歌词；另一方面，之前的 Rap 生成系统对于押韵的建模也有所欠缺，很难自动生成多押、连押和连环押等高质量 Rap 的必要成分。作者希望设计出一个基于 Transformer 的 Rap 生成模型，来生成押韵且有节奏信息的 Rap 歌词。

$\bullet\;Method:$

   针对数据缺乏的问题，首先设计了一个收集数据的 Pipeline，收集了大量歌曲数据，并且对歌曲进行了一系列处理，建立了三个大规模的数据集：D-RAP、D-SONG、D-LYRIC。

   DeepRapper 采用了基于 Transformer 的自回归语言生成模型。为了更好地对“押韵“建模，首先采用了反向生成的方式，从右到左生成一句话里的歌词。因为押韵词语通常位于句子末尾，这样的反向处理有利于生成多押（N-gram rhyme）的 Rap。然后又引入了韵母 Embedding 和相对位置 Embedding，以更好捕捉押韵词语与句子中位置的关系，这同样利于生成多押的 Rap。最后在生成时引入韵脚约束，以灵活调整下一个词的概率，在不影响自动生成 Rap 的同时，给押韵的词语分配更多的概率，这不仅有利于生成多押，还有利于连押。而且对于可以获得的极少的连环押数据，DeepRapper 也在连环押句子中的每个韵脚后嵌入了一个特殊Token，从而赋予了 DeepRapper 生成连环押 Rap 句子的能力。对于节奏的建模，DeepRapper 在歌词中插入了一个特殊的 [BEAT] Token，显式地将节奏信息和歌词信息融合，将节奏预测简化成语言模型里特殊 Token 的预测。

$\bullet\;Experimental\;Result:$

   比较了 DeepRapper 客观和主观的评估结果，并与两个基线模型进行了比较。Baseline 与 DeepRapper 结构相同，但是没有韵律模型；Baseline+PT 则是采用了预训练的 Baseline。结果显示，DeepRapper 在客观指标 Perplexity (PPL)、Rhyme Accuracy (RA)、 Rhyme Density (RD)和主观指标 Theme (主题是否鲜明)、Fluency (语言是否流畅)、Quality (韵脚质量)、 Diversity (韵脚多样化)上都远远超出了各个 Baseline。   **(Written by Weilun Yu)**  [(BibTex)](https://arxiv.org/abs/2107.01875)

8.$Fast\; Multi-Instance\; Multi-Label \;Learning\; $$\textcolor{Red}{(AAAI,\;CCF-A)}$

​	$\bullet\;Motivation :$

​	在多案例多标签学习中（MIML），一个复杂目标往往被多个案例表示且同时与多个标签相关，MIML方法可以有效的用于很多应用，但是因为大的时间消耗无法有效处理大数据集。

​	$\bullet\;Method :$

​	本文首先构建了一个由所有标签共享的低维子空间，然后训练标签的具体线性模型，通过随机梯度下降去优化近似ranking损失。具体过程，首先将一个问题分解成案例级任务，预测每个案例的标签，然后即可得到该问题的多标签类别。这个过程中设计了一个Ranking loss函数去评估模型，训练参数，Ranking是指如果该案例对于不相关标签的预测值，越大说明性能越差。

​	$\bullet\;Experiment\; Result :$

​	实验结果显示，fastMIML方法明显优于经典方法，时间消耗最少，尤其是在处理30K bags和279K instances时，目前没有方法可以在24小时内返回结果，但是本文的方法只需要12分钟，此外，本文方法还能找到对每个标签最优代表性的案例，可以提供一个理解输入模式和输出语义关系的机会。**(Written by Wenhua Zhu)**     [(BibTex)]([Fast Multi-Instance Multi-Label Learning. - AMiner](https://www.aminer.cn/pub/53e9ade2b7602d97037ea35b/fast-multi-instance-multi-label-learning))

9.$Multitask\;Learning\;for\;Emotion\;and\;Personality\;Detection\;$ $\textcolor{Red}{(TAC,\;CCF-B)}$

​	$\bullet\;Motivation :$

​	由于个人数字足迹的大量出现，基于学习的深度个性检测越发重要。很多研究者认为性格特点和情绪有很强烈的关联，本文基于此做了一些多任务学习的工作。

​	$\bullet\;Method :$

​	本文设计了一个新的多任务学习框架（SOGMTL），可以同时预测性格特点和情绪。主体框架是由嵌入层，卷积层，池化层，稠密层构成，为了实现不同任务之间的信息共享，在每一层后添加一个门机制。文中比较了三个门机制，SiG, CAG和SiLG，他们各有自己的优势和不足，为了克服这些问题，作者提出了SOG方法，它在SIG中将sigmoid函数改成softmax函数去构造一个选择门。在多任务训练中由于不同任务面对的数据集是不同的，因此需要设计好自适应的训练框架用于不同的子任务。

​	$\bullet\;Experiment\; Result :$

​	实验结果显示，CNN在这些任务上是要优于BERT和LSTM的，本文所添加的MAML结构对于框架的性能提升也起了很大的作用。**(Written by Wenhua Zhu)**     [(BibTex)]([Multitask Learning for Emotion and Personality Detection - AMiner](https://www.aminer.cn/pub/5ff8278791e0116ed225e223/multitask-learning-for-emotion-and-personality-detection))

10.$Topic-driven\;and\;Knowledge-Aware\;Transformer\;for\;Dialogue\;Emotion\;Detection\;$ $\textcolor{Red}{(ACL,\;CCF-A)}$

​	$\bullet\;Motivation :$

​	情感检测在对话中是具有极大挑战的，因为好的识别效果往往需要对对话主题，相关常识以及情感状态之间复杂的转换模式有很好的识别。

​	$\bullet\;Method :$

​	本文提出了一个主题驱动和知识感知转换器来解决这些问题，首先设计了主题扩充语言模型，然后有一个专门用于主题检测的层，将主题扩充与导出的常识语句结合起来。更具体来说，首先是获得会话的主题，采用VHRED用于主题发现，用预训练语言模型取代其中的RNN编码器和解码器，此外，使用多头注意力取代LSTM去对潜在主题矢量之间的依赖性的建模。在常识结合过程中。首先以知识图形式表示各事件的关联，有SBERT 和COMET两种计算会话与事件相关性的方法，将相关性最高的事件作为常识与主题结合，进行对话情感检测。

​	$\bullet\;Experiment\; Result :$

​	在四个数据集上和四个基准模型进行比较实验，本文的模型在多数结果上要由于他们，在消融实验中，也表明框架设置是十分有效的。**(Written by Wenhua Zhu)**     [(BibTex)]([Topic-Driven And Knowledge-Aware Transformer For Dialogue Emotion Detection - AMiner](https://www.aminer.cn/pub/60bad81191e01102e59b6a80/topic-driven-and-knowledge-aware-transformer-for-dialogue-emotion-detection))

11.**$Multi-modal\;Multi-label\;Emotion\;Recognition\;Heterogeneous\;Hierarchical\;Message\;Passing$ $\textcolor{Red}{(AAAI,\;CCF-A)}$**

​    $\bullet\;Motivation:$

​	多模态情绪识别是情感计算领域的一个重要研究课题，近年来已成为研究热点。然而，几乎所有现有的研究都对每种情绪进行多重二值分类，主要集中在完整的时间序列数据上。

​    $\bullet\;Method:$

​	本文提出了一个异构层次的消息传递网络来有效地建模上面的依赖关系。此外，我们提出了一种新的基于部分时间序列内容的多模式多标签情感数据集，以显示我们的模型的优势泛化。

​    $\bullet\;Experimental\;Result:$

​	针对多模式多标签情感识别所面临的挑战，提出了一种异构层次信息传递网络(HHMPN)。这种方法可以很容易地在完整时间序列数据和部分时间序列数据上执行。此外，特性到特性、特性到标签、标签到标签和模式到标签的依赖问题可以通过作者方法中的核心模块很好地捕获。	**(Written by Hao Fu)**      [(BibTex)](https://ojs.aaai.org/index.php/AAAI/article/view/17686)

12.$Dual\;Graph\;Convolutional\;Networks\;for\;Aspect-based\;Sentiment\;Analysis$$\textcolor{Red}{(ACL,\;CCF-A)}$

​    $\bullet\;Motivation:$

   最近，在依存树上的图神经网络已经被探索来明确地建模aspects和 opinion words之间的联系。然而，由于依赖性解析结果的不准确性以及在线评论的非正式表达和复杂性，改进范围有限。

​    $\bullet\;Method:$

​       为了克服这些挑战，本文提出了一种双图卷积网络(DualGCN)模型，能够同时考虑语法结构的互补性和语义相关性。设计了一个具有丰富语法知识的SynGCN模块，来减轻依赖性解析错误。并设计了一个具有自我注意机制的SemGCN模块获取语义相关性。此外，还提出了正交和差分正则化，通过约束SemGCN模块中的 attention分数来精确地捕获单词之间的语义相关性。正交正则化鼓励SemGCN学习语义相关的单词，使得每个单词的重叠较少，差分正则化鼓励SemGCN学习SynGCN没有捕捉到的信息。

​    $\bullet\;Experimental\;Result:$

​       在三个公共数据集上的实验结果表明，该DualGCN模型优于最先进的方法，并验证了该模型的有效性。**(Written by Yuzhao Chen)**  [(BibTex)](https://aclanthology.org/2021.acl-long.494/)

13.$Reinforced\;History\;Backtracking\;for\;Conversational\;Question\;Answering$$\textcolor{Red}{(AAAI,\;CCF-A)}$

​    $\bullet\;Motivation:$

​       对上下文历史建模是问答系统中的关键步骤。为了利用语境历史，现有的研究往往是将整个语境作为输入，这存在以下两个问题：首先，对长历史进行建模的成本可能很高，因为它需要更多的计算资源。第二，长上下文历史中会包含许多不相关的信息，这使得对目标信息进行建模变的困难。

​    $\bullet\;Method:$

​       本文针对会话问答（ConvQA）环境下会话历史建模问题，提出了一种新的解决方案。在传统的机器阅读理解（MRC）模型中，加入了一个增强回溯器来过滤不相关的历史，而不是将历史作为一个整体来评估它们。并把会话历史选择问题建模为一个顺序决策过程，该过程可以通过强化学习来解决。通过与预先训练的机器阅读理解(MRC)模型交互，增强回溯器能够生成良好的选择策略。针对稀疏奖励问题，进一步地提出了一种新的训练方案。

​    $\bullet\;Experimental\;Result:$

​       本文在大型会话问题答疑数据集QuAC上进行了广泛的实验，结果表明，该方法可以帮助缓解由于较长的上下文历史而产生的问题。采用强化学习学习会话历史选择策略有助于提高回答预测性能。**(Written by Yuzhao Chen)** [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-1260.QiuM.pdf)

14.$Towards\;Generative\;Aspect-Based\;Sentiment\;Analysis$$\textcolor{Red}{(ACL,\;CCF-A)}$

​    $\bullet\;Motivation:$

​       大多数现有工作会以区别的方式处理ABSA问题，设计各种特定于任务的分类网络进行预测。 尽管它们很有效，但这些方法忽略了ABSA问题中丰富的标签语义，并且需要广泛的特定于任务的设计。

​    $\bullet\;Method:$

​       本文提出在一个统一的生成框架中处理各种ABSA任务，通过将自然语言标签编码到目标输出中，可以充分利用丰富的标签语义。此外，这种统一的生成模型可以适应多个任务，不需要引入其他特定于任务的模型设计。并设计了两种类型的样式，即注释式和提取式建模，旨在通过将每个ABSA任务表述为文本生成问题来实现训练过程。给定一个句子，前者在这个句子上添加注释，以便在构建目标句子时包含标签信息；而后者直接采用所需的自然语言标签将输入的句子作为目标。

​    $\bullet\;Experimental\;Result:$

​       本文在多个基准数据集上对四个ABSA任务进行了实验，提出的方法几乎在所有情况下都超越了以前的最先进的技术。这也验证了所提出框架的强大通用性，该框架可以适应任意ABSA任务。**(Written by Yuzhao Chen)** [(BibTex)](https://aclanthology.org/2021.acl-short.64/)

15.$Uncertainty \; and \; Surprisal \; Jointly \; Deliver \; the \; Punchline: \; Exploiting \; Incongruity-Based \; Features \; for \; Humor \; Recognition$$\textcolor{Red}{(ACL,CCF-A)}$

​	$\bullet\;Motivation:$

​        幽默识别作为一个文本分类问题，已经被广泛研究。然而，大多数现有的工作并没有研究真正的笑话机制来理解幽默。

​	$\bullet\;Method:$

​       作者将所有笑话分解为两个不同的部分：场景和笑话，并进一步探讨它们之间的特殊关系。受幽默不协调理论的启发，作者将场景建模为发展语义不确定性的部分，以及破坏观众期望的笑话。随着功能越来越强大的语言模型的出现，这个模型能够将设置和笑话输入GPT-2语言模型，并计算笑话的不确定性和惊喜值。

​	$\bullet\;Experimental \; Result:$

​       通过对SeaGracle 2021任务7数据集进行实验，发现这两个特征与现有的基线相比，具有更好的讲非笑话笑话的能力。**(Written by Hongfei Xue)**[(BibTex)](https://arxiv.org/pdf/2012.12007.pdf)

16.$Dynamic\;Hybrid\;Relation\;Network\;for\;Cross-Domain\;Context-Dependent\;Semantic\;Parsing$$\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

   近年来，交叉领域的上下文关联语义解析已成为一个新的研究热点，这个问题的关键是如何利用交互历史中的自然语言表达和数据库模式的上下文信息。

$\bullet\;Method:$

  本文提出了一种新的框架，称之为动态图框架，该框架基于动态进化图的结构，能够有效的对上下文语义表达，token，数据库结构以及它们之间的相互作用进行建模，把这些复杂的信息结合起来训练。该框架采用了一种动态记忆衰减机制，结合归纳偏差来整合丰富的上下文关系表示，通过一个强大的重新排序模型来进一步增强，来衡量前面的对话对当前对话是否有影响。

$\bullet\;Experimental\;Result:$

   本文在两个大规模交叉领域的上下文关联的基准SParC和CoSQL上评估了提出的模型，在两个数据集上都取得了最先进的性能，大大优于所有现有的模型。

**(Written by Yuzhao Chen)**  [(BibTex)](https://arxiv.org/abs/2101.01686)

17.$Keyword-Guided\;Neural\;Conversational\;Model$$\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

   本文研究了在开放域对话代理上施加对话目标/关键词的问题，在这种情况下，需要代理将对话平稳快速地引导到目标关键词。本文提出了关键字选择中现有研究两个局限性：1)训练和评估数据集中多噪声；2)依靠词嵌入之间相似性近目标关键词可能会不可靠。

$\bullet\;Method:$

   在本文中，作者假设人类对话是基于常识的，并提出了一种关键词引导的神经对话模型，使用外部常识知识图CKG进行关键字转换，并提出了两种基于GNN的模型，将常识知识分别用于下一轮关键字预测和关键字增强响应检索。并提出了一个大规模的从Reddit获得的开放域对话数据集来完成这个任务。

$\bullet\;Experimental\;Result:$

   大量的实验结果表明，在CKG上的关键字转换提高了整体对话的平滑性，并允许代理更快地到达目标。此外，利用常识性的三元组，还可以大大提高下一轮的关键字预测和关键字增强响应检索的性能。

**(Written by Yuzhao Chen)** [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-8746.ZhongP.pdf)

18.$SMIL\;Multimodal\;Learning\;with\;Severely\;Missing\;Modality$$\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

   多模式学习中，人们往往假设训练数据是完整的，即所有训练实例中每个模态都是完整的。尽管有研究者致力于开发新的方法来解决测试数据的模态不完全性，例如测试集中缺少部分模态，但是很少有人能够处理训练过程中的模态缺失。

$\bullet\;Method:$

   本文是第一个系统地研究严重缺失模态的多模态学习问题的工作。首次从灵活性和效率两个方面正式研究了缺失模态的多模态学习，灵活性方面是指在训练、测试或两者中都有缺失的模式，效率方面是指大多数训练数据的模态都不完整。从技术上讲，文章提出了一种名为SMIL的新方法，该方法利用贝叶斯元学习统一实现了两个目标。

$\bullet\;Experimental\;Result:$

   本文在MM-IMDb、CMU-MOSI和avMNIST上进行了大量实验，验证了SMIL能优于包括AE和GAN在内的生成基准线，达到最先进的性能。

**(Written by Yuzhao Chen)** [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-437.MaM.pdf)

19.$Dependency-driven\;Relation\;Extraction\;with\;Attentive\;Graph\;Convolutional\;Networks$ $\textcolor{Red}{(ACL, \;CCF-A)}$ 

$\bullet\;Motivation:$

   关系抽取是NLP 的一项重要任务，其目标是识别文本中两个实体之间的关系类型。在已有的研究里，句法信息（譬如依存句法）被广泛应用于关系抽取任务，利用句法中的有用信息帮助模型提升性能。依存句法关系以及关系类型能够提供丰富的上下文信息，帮助模型识别实体之间的关系标签，不过，并不是所有依存句法知识都是有用的，有些依存句法知识会成为噪声，影响模型的性能。

$\bullet\;Method:$

   作者提出了注意力图卷积神经网络模型 A-GCN，基于剪枝的依存句法知识，对词与词之间的依存关系以及关系类型进行上下文建模，通过注意力机制区分不同上下文特征的重要性，识别句法知识中的噪声，从而提升模型在关系抽取任务中的性能。

​    具体地，对于每一个输入的文本，首先使用依存句法工具自动处理文本并生成依存句法树，构建词与词之间的关系图及其关系类型，然后使用BERT作为编码器，提取文本序列的表征 ，并将文本序列表征和关联矩阵、依存类型矩阵输入A-GCN模块。在A-GCN模块里，对于序列中的每一个词，将其与相关上下文词的依存关系和关系类型作为上下文特征进行编码，同时，为了区分不同上下文特征的重要性，采用注意力机制，通过计算词与词之间的点积，以此构建注意力矩阵，作为权重分配给其上下文特征，进而识别句法知识中的噪声，突出重要信息的作用。最后，基于 A-GCN 的输出，预测两个实体之间的关系标签。

$\bullet\;Experimental\;Result:$

   该论文在两个基准数据集上评测了模型的性能。先比较了与其他SOTA模型在两个基准数据集上 F1 值对比。从实验结果可以看出，该研究提出的注意力图卷积神经网络模型在两个基准数据集上都达到了目前最高的关系抽取任务成绩。此外，对不同类型的依存信息进行了分析，展示了模型利用不同类型依存信息在两个基准数据集上的性能。从结果看，基于 L+G 构建关联图能使模型 A-GCN 达到最佳效果。**(Written by Weilun Yu)**  [(BibTex)](https://aclanthology.org/2021.acl-long.344.pdf)

20.$Unsupervised\;Multi-hop\;Question\;Answering\;by\;Question\;Generation$$\textcolor{Red}{(ACL,\;CCF-A)}$

$\bullet\;Motivation:$

   获取多跳问答(QA)的训练数据是非常耗时并且是资源密集型的。

$\bullet\;Method:$

  文章称这是第一个研究无监督多跳QA的工作。这篇文章研究的是无监督学习进行多跳问题生成，从而实现问答。文章提出了一种叫做 MGA-QG 的框架，能够从文本中或文本和表格中选择和生成相关信息，随后集成这些信息，构建多跳问答数据集，文章构建的是两跳。通过 operators, reasoning graphs 和 filtration 生成多种类型的多跳问题，可以在无监督领域和 few-shot 学习领域为问答模型提供良好的支持。

$\bullet\;Experimental\;Result:$

  只通过这些生成的数据集，就能达到 61% 和 83% 的 HybridQA 和 HotpotQA 的监督学习的效果。利用这些无监督学习数据集，能够显著降低对人类标注数据集的需求。 **(Written by Yuzhao Chen)**  [(BibTex)](https://arxiv.org/abs/2010.12623)



21.$Text\;Modular\;Networks:\;Learning\;to\;Decompose\;Tasks\;in\;the\;Language\;of\;Existing\;Models$$\textcolor{Red}{(ACL,\;CCF-A)}$

$\bullet\;Motivation:$

  将复杂问题分解为可回答的简单问题，从而可以解决多跳推理和数字推理的问题，提升可解释性、稳定性。

$\bullet\;Method:$

  这篇文章提出了一个名为 TMNs (Text Modular Networks) 的通用框架，通过一系列子模型，将数据集内的复杂问题分解为简单问题。子模型可以是任意模型，它们在框架中都被认为是黑盒模型。同时，这一分解过程是远程监督的，不需要人类标记数据。分解的子模型被称为 NextGen。随后，文章基于 TMNs 框架构建了一个问答系统 ModularQA。该系统由 a neural factoid single-span QA model 和 a symbolic calculator 组成。

$\bullet\;Experimental\;Result:$

  这篇文章提出的框架具有良好的可解释性、稳定性，需要更少的数据，就可以实现问答。 **(Written by Yuzhao Chen)** [(BibTex)](https://arxiv.org/abs/2009.00751)

22.$Entity\;Structure\;Within\;and\;Throughout:\;Modeling\;Mention\;Dependencies\;for\;Document-Level\;Relation\;Extraction$$\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

   实体作为关系提取任务中的基本要素，表现出一定的结构。

$\bullet\;Method:$

   本文创新性地提出了实体结构（Entity Structure）这一概念，以依赖（dependency）的形式，对实体提及在文档中的分布进行定义，并设计了结构化自注意力网络（SSAN）在上下文编码的同时对实体结构进行建模。本文在每个自我注意构建块中设计了两个可选的转换模块，以产生注意偏差，从而自适应地规范其注意流。

$\bullet\;Experimental\;Result:$

   实验表明，SSAN能够有效地在深度网络中引入实体结构的先验，指导注意力机制的传播，以增强模型对实体间交互关系的推理能力。SSAN在包括DocRED在内的多个常用文档级关系抽取任务上取得了当前最优效果。**(Written by Yuzhao Chen)**  [(BibTex)](https://arxiv.org/abs/2102.10249)

23.$ERNIE-ViL:\;Knowledge\;Enhanced\;Vision-Language\;Representations\;through\;Scene\;Graphs$$\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

   视觉-语言预训练的目标是通过对齐语料学习多模态的通用联合表示，将各个模态之间的语义对齐信号融合到联合表示中，从而提升下游任务效果。已有的视觉语言预训练方法在预训练过程中没有区分普通词和语义词，学到的联合表示无法刻画模态间细粒度语义的对齐，如场景中物体、物体属性、物体间关系这些深度理解场景所必备的细粒度语义。

$\bullet\;Method:$

   本文提出了知识增强的视觉-语言预训练技术ERNIE-ViL，将包含细粒度语义信息的场景图先验知识融入预训练过程，创建了物体预测、属性预测、关系预测三个预训练任务，在预训练过程中更加关注细粒度语义的跨模态对齐，从而学习到能够刻画更好跨模态语义对齐信息的联合表示。

$\bullet\;Experimental\;Result:$

   ERNIE-ViL在视觉问答、视觉常识推理、引用表达式理解、跨模态文本检索、跨模态图像检索等5个多模态典型任务上取得了SOTA效果，同时，在视觉常识推理VCR榜单上取得第一。**(Written by Yuzhao Chen)**  [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-6208.YuFei.pdf)

24.$MVFNet:\;Multi-View\;Fusion\;Network\;for\;Efficient\;Video\;Recognition$$\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

   视频识别作为视频理解的基础技术，是近几年非常热门的计算机视觉研究方向。现有的基于3D卷积网络的方法识别精度优异但计算量偏大，基于2D网络的方法虽然相对轻量但精度不及3D卷积网络。

$\bullet\;Method:$

   本文提出一种轻量的多视角融合模块用于高效率且高性能的视频识别，该模块是一个即插即用的模块，能够直接插入到现有的2D卷积网络中构成一个简单有效的模型，称为MVFNet。此外，MVFNet可以视为一种通用的视频建模框架，通过设置模块内的参数，MVFNet可转化为经典的C2D，SlowOnly和TSM网络。

$\bullet\;Experimental\;Result:$

   实验结果显示，在五个视频benchmark上，MVFNet仅仅使用2D卷积网络的计算量就能够取得与当前最先进的3D卷积网络媲美甚至更高的性能。**(Written by Yuzhao Chen)**  [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-1523.WuW.pdf)

25.$Multimodal \;Emotion\; Recognition \;and\; Sentiment\; Analysis \;via\; Attention \;Enhanced \;Recurrent\; Model$$ 

$\bullet\;Motivation:$

随着在线网站中用户生成视频的激增，如何从这些视频中自动感知和理解人类的情感/情绪变得尤为重要。

$\bullet\;Method:$

 由于良好的特征对于鲁棒情绪识别至关重要，我们首先探索了一系列来自音频、视觉和文本模态的特征，包括低级手工制作的特征和来自监督/非监督预训练模型的高级深度表示。对于时间模型，我们利用长短时记忆(LSTM)循环神经网络和自我注意机制来捕捉特征序列中复杂的时间动态。假设LSTM和自我注意机制的结合可以提高模型的长期时间情境建模能力，更适合连续情绪识别和离散情绪分类。为了提高模型的性能，我们采用了一种简单而有效的融合方法，即后期融合，来整合来自不同模式的信息。由于MuSe-Sent中的离散情感类是由MuSe-Wilder中的连续情感标注派生而来，因此我们也利用它们之间的关系来提高MuSe-Sent中的情感分类性能。

$\bullet\;Experimental\;Result:$

使用晚期融合来利用来自不同模式的互补信息。我们利用MuSe-Wilder的连续预测来辅助MuSe-Sent的离散分类，我们发现价电子分类的性能可以大大提高。最佳提交结果表明，我们提出的方法在MuSe-Wilder和MuSe-Sent两种情况下都比基线系统获得了明显更好的性能。 **(Written by Wenhua Zhu)**    [(BibTex)]([Multimodal Emotion Recognition and Sentiment Analysis via Attention Enhanced Recurrent Model | Proceedings of the 2nd on Multimodal Sentiment Analysis Challenge (acm.org)](https://dl.acm.org/doi/10.1145/3475957.3484456))



26.$BiERU:\; Bidirectional\; Emotional\; Recurrent \;Unit \;for\; Conversational\; Sentiment\; Analysis$$ \textcolor{Red}{(arXiv)}$

$\bullet\;Motivation:$

近年来，会话情感分析的应用越来越多，如情感分析、推荐系统、人机交互等，引起了越来越多的关注。会话情感分析与单句情感分析的主要区别在于语境信息的存在，语境信息在对话中会影响话语的情感。然而，如何有效地编码对话中的语境信息仍然是一个挑战。现有的方法采用复杂的深度学习结构来区分会话中的不同主体，然后对上下文信息进行建模。本文提出了一种快速、紧凑、参数高效的面向对象的双向情感循环单元框架，用于会话情感分析。

$\bullet\;Method:$

本文提出了一种基于情绪递归单元(ERU)、一种包含广义神经张量块(GNTB)和双通道特征提取器(TFE)的递归神经网络的快速、紧凑、参数高效的无党派框架，用于会话情绪分析。语境信息是对话情感分析和单句情感分析任务的主要区别。在会话中进行情感分析主要有三个步骤:获取语境信息、捕捉语境信息对话语的影响、提取情感特征进行分类。现有的对话情感分析方法cLSTM[4]、CMN[5]、DialogueRNN[2]、DialogueGCN[6]利用复杂的深度神经网络结构来捕获上下文信息，描述上下文信息对话语的影响。我们重新定义会话情感分析的形式，并提供一个紧凑的结构来更好地编码上下文信息，捕捉上下文信息对话语的影响，并提取特征进行情感分类。

$\bullet\;Experimental\;Result:$

证明了在简化模型结构的同时提高模型性能是可行的。在大多数情况下，我们的模型在三个标准数据集上的表现优于目前最先进的模型。 **(Written by Wenhua Zhu)**    [(BibTex)]([BiERU: Bidirectional emotional recurrent unit for conversational sentiment analysis - ScienceDirect](https://www.sciencedirect.com/science/article/pii/S0925231221014351))

27.$Simpson’s\;Bias\;in\;NLP\;Training$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

​	在大多数机器学习任务中，我们通过测量一个种群水平度量f  (S;M)来评估一个模型。此类评估指标的示例包括用于(二进制)识别的精度/召回率，用于多类分类的F1评分，以及用于语言生成的BLEU指标。

$\bullet\;Method:$

​	本文在几个自然语言处理任务中系统地研究了上述假设。作者从理论和实验两方面表明，一些流行的样本级损失设计g可能与任务的真实总体级度量f不一致，因此受训优化前者的模型在本质上可能低于后者的最优，我们作者称之为辛普森偏差。因为它与统计学和社会科学中的经典悖论——辛普森颠倒悖论有着深刻的联系。

$\bullet\;Experimental\;Result:$

​	在本文中，作者创造了一个新的概念，辛普森偏差，因为它在诱导ML的次优训练和在诱导统计学上的辛普森悖论中的作用相似。作者对ML中的Simpson偏倚提出了一个理论分类，揭示了在ML的广泛度量中如何体现类似的效果，从简单的准确性到复杂的BLEU。对于某些集合形式的度量，证明了通过添加特殊的和不常见的(如负的)平滑常数来构造可证明无偏的平均形式代理是可能的。	**(Written by Hao Fu)**      [(BibTex)](https://ojs.aaai.org/index.php/AAAI/article/view/17679)

28.$Improving\;Clinical\;Document\;Understanding\;on\;COVID-19\;Research\;with\;Spark\;NLP$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

​	在COVID-19全球大流行之后，研究该病毒的科学论文数量大幅增加，导致对自动识字审查的兴趣增加。

$\bullet\;Method:$

​	作者提出了一个临床文本挖掘系统，该系统在三个方面进行了改进。首先，它可以识别100多种不同的实体类型，包括健康、解剖学、风险因素和不良事件的社会决定因素，以及其他常用的临床和生物医学实体。其次，文本处理管道包括断言状态检测，以区分存在、不存在、有条件的临床事实或关于病人以外的人的临床事实。第三，使用的深度学习模型比以前更准确，利用了先进的预先训练的命名实体识别模型的集成管道，并改进了断言状态检测的以前表现最好的基准。

$\bullet\;Experimental\;Result:$

​	结果表明，在CORD-19中提出的论文包括各种各样的实体类型，这种新的NLP管道可以识别，并断言状态检测是对这些实体的一个有用的过滤器。这预示着下游分析的丰裕性，可以使用这些结构化和规范化的数据来完成——例如聚类、降维、语义相似度、可视化或基于图的分析来识别相关概念。	**(Written by Hao Fu)**      [(BibTex)](https://scholar.google.com/scholar?hl=zh-CN&as_sdt=0%2C5&q=Improving+Clinical+Document+Understanding+on+COVID-19+Research+with+Spark+NLP&btnG=)

29.$Building\;Interpretable\;Interaction\;Trees\;for\;Deep\;NLP\;Models$ $\textcolor{Red}{(AAAI,\;CCF-A)}$

$\bullet\;Motivation:$

​	本文提出了一种方法来解开和量化编码在DNN中的单词之间的交互作用，用于自然语言处理。

$\bullet\;Method:$

​	作者构建了一棵树来编码DNN提取的显著交互作用。本文提出了六个指标来分析句子成分之间的相互作用的性质。交互是基于单词的shapleyvalue定义的，这被认为是一个无偏估计的单词贡献到网络预测。我们的方法用于量化BERT、ELMo、LSTM、CNN和Transformer网络中编码的单词交互。

$\bullet\;Experimental\;Result:$

​	在本文中，作者定义并提取了DNN中单词之间的交互利益，并使用树结构对单词之间的交互进行分层组织。此外，本文还定义了6个度量标准来理清和量化词语之间的交互作用。作者的方法可以作为一种客观诊断不同dnn的通用工具，为NLP任务提供了新的见解。	**(Written by Hao Fu)**      [(BibTex)](https://ojs.aaai.org/index.php/AAAI/article/view/17685)
