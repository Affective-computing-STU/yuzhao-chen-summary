# Emotion recognition in conversation(ERC)

2016:

2017:

2018

2019:

2020:

2021:

# Recognizing emotion cause

2016：

2017：

2018：

2019：

2020：

2021：



# Commonsense knowledge

2016：

2017：

2018：

2019：

2020：

2021：

# Self-supervised Learning in conversation

2016:

2017:

2018:

2019:

2020:

2021:

# Affective Computing

2016:

2017:

2018:

2019:

2020:

2021:

# Others (NLP)

2016:

2017:

2018:

2019:

2020:

1. $Look\;at\;the\;First\;Sentence:\;Position\;Bias\;in\;Question\;Answering$$\textcolor{Red}{(EMNLP,\;CCF-B)}$

   $\bullet\;Motivation:$

     许多提取的问题回答模型被训练来预测答案的开始和结束位置。预测答案作为位置的选择主要是由于其简单性和有效性。

   $\bullet\;Method:$

     这篇文章提出了一个有趣的问题：答案分布可能在训练集中存在高度偏移，例如多个答案固定分布在第 k 句，这种偏移可能会误导模型。文章首先在多个模型上验证了这种误导的确存在，研究了偏移模型的失效原因，随后用多种去偏移化方法训练模型。证明了答案位置的先验分布有助于建立位置去偏移模型，改善模型性能。

   $\bullet\;Experimental\;Result:$

     实验中发现，使用答案位置的先验分布为模型降低偏移效果非常有效。**(Written by Yuzhao Chen)** [(BibTex)](https://arxiv.org/abs/2004.14602)

2021:

1. $Unsupervised\;Multi-hop\;Question\;Answering\;by\;Question\;Generation$$\textcolor{Red}{(ACL,\;CCF-A)}$

   $\bullet\;Motivation:$

      获取多跳问答(QA)的训练数据是非常耗时并且是资源密集型的。

   $\bullet\;Method:$

     文章称这是第一个研究无监督多跳QA的工作。这篇文章研究的是无监督学习进行多跳问题生成，从而实现问答。文章提出了一种叫做 MGA-QG 的框架，能够从文本中或文本和表格中选择和生成相关信息，随后集成这些信息，构建多跳问答数据集，文章构建的是两跳。通过 operators, reasoning graphs 和 filtration 生成多种类型的多跳问题，可以在无监督领域和 few-shot 学习领域为问答模型提供良好的支持。

   $\bullet\;Experimental\;Result:$

     只通过这些生成的数据集，就能达到 61% 和 83% 的 HybridQA 和 HotpotQA 的监督学习的效果。利用这些无监督学习数据集，能够显著降低对人类标注数据集的需求。 **(Written by Yuzhao Chen)**  [(BibTex)](https://arxiv.org/abs/2010.12623)

   

2. $Text\;Modular\;Networks:\;Learning\;to\;Decompose\;Tasks\;in\;the\;Language\;of\;Existing\;Models$$\textcolor{Red}{(ACL,\;CCF-A)}$

   $\bullet\;Motivation:$

     将复杂问题分解为可回答的简单问题，从而可以解决多跳推理和数字推理的问题，提升可解释性、稳定性。

   $\bullet\;Method:$

     这篇文章提出了一个名为 TMNs (Text Modular Networks) 的通用框架，通过一系列子模型，将数据集内的复杂问题分解为简单问题。子模型可以是任意模型，它们在框架中都被认为是黑盒模型。同时，这一分解过程是远程监督的，不需要人类标记数据。分解的子模型被称为 NextGen。随后，文章基于 TMNs 框架构建了一个问答系统 ModularQA。该系统由 a neural factoid single-span QA model 和 a symbolic calculator 组成。

   $\bullet\;Experimental\;Result:$

     这篇文章提出的框架具有良好的可解释性、稳定性，需要更少的数据，就可以实现问答。 **(Written by Yuzhao Chen)** [(BibTex)](https://arxiv.org/abs/2009.00751)

​        
