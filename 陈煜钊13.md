# Emotion recognition in conversation(ERC)

2016:

2017:

2018

2019:

2020:

2021:

# Recognizing emotion cause

2016：

2017：

2018：

2019：

2020：

2021：



# Commonsense knowledge

2016：

2017：

2018：

2019：

2020：

2021：

# Self-supervised Learning in conversation

2016:

2017:

2018:

2019:

2020:

2021:

# Affective Computing

2016:

2017:

2018:

2019:

2020:

2021:

# Others (NLP)

2016:

2017:

1. $Deeper\;Attention\;to\;Abusive\;User\;Content\;Moderation$$\textcolor{Red}{(EMNLP,\;CCF-B)}$

   $\bullet\;Motivation:$

      作者尝试了一个新的公开可用的数据集，其中有来自希腊体育新闻门户网站的160万条经过审核的用户评论，以及一个现有的数据集，其中有11.5万条Wikipedia英语对话页面评论。

   $\bullet\;Method:$

      作者提出了一种新颖的、深度的、特定分类的注意机制进一步提高了RNN的整体结果，并且可以直接突出可疑词，而不需要在训练数据中包含突出词。并且作者考虑了全自动和半自动调节，以及两者的阈值调优和评估方法。

   $\bullet\;Experimental\;Result:$

      实验结果表明，GRU RNN操作词嵌入比之前的技术表现得更好，它使用带有字符或单词n-gram特征的LR或MLP分类器，也优于普通CNN操作的单词嵌入，以及使用带有精确分数的自动构建单词列表的基线。**(Written by Yuzhao Chen)**[(BibTex)](https://aclanthology.org/D17-1117.pdf)

   

2. $Get\;To\;The\;Point:\;Summarization\;with\;Pointer-Generator\;Networks$$\textcolor{Red}{(ACL,\;CCF-A)}$

   $\bullet\;Motivation:$

      作者认为生成式摘要任务中，对于传统的seq2seq+attention的模型架构，存在以下几个缺点：生成的摘要内容不准确；容易产生重复的内容，不能处理OOV（out-of-vocabulary）词汇。

   $\bullet\;Method:$

      本文作者在标准seq2seq+attention的基础之上做了改进，提出了一个新的体系结构，作者采用Pointer-Generator Network，在保留生成新词的同时，还可以从原文中抽取内容，促使生成更准确的摘要，并且使用Coverage记录已经生成的内容，从而减少内容重复。

   $\bullet\;Experimental\;Result:$

      作者将提出的模型应用于CNN / Daily Mail的摘要任务，比目前最先进的模型至少高出2个ROUGE点。**(Written by Yuzhao Chen)**[(BibTex)](https://arxiv.org/abs/1704.04368)




2018:

1. $Neural\;Latent\;Extractive\;Document\;Summarization$$\textcolor{Red}{(EMNLP,\;CCF-B)}$

   $\bullet\;Motivation:$

      抽取式摘要模型需要句子级别的标签，这些标签通常是启发式创建的(例如，使用基于规则的方法)，因为大多数摘要数据集只有文档摘要部分。

   $\bullet\;Method:$

      由于这些标签可能是次优的，作者提出了一个隐变量提取模型，其中句子被视为隐变量，带有激活变量的句子被用来推测重要摘要。即把句子对应的label视为句子的隐变量。不是最大化每个句子到训练数据的可能性，而是最大化生成摘要是这个人工摘要整体的可能性。

   $\bullet\;Experimental\;Result:$

      在CNN/Dailymail数据集上的实验表明，作者的模型在启发式近似标签上训练的强提取基线上有所改进，而且与几个最新的模型相比也具有竞争力。**(Written by Yuzhao Chen)**[(BibTex)](https://arxiv.org/abs/1808.07187)

2019:

2020:

2021:

