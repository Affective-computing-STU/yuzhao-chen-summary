# Emotion recognition in conversation(ERC)

2016:

2017:

2018

2019:

2020:

2021:

# Recognizing emotion cause

2016：

2017：

2018：

2019：

2020：

2021：



# Commonsense knowledge

2016：

2017：

2018：

2019：

2020：

2021：

# Self-supervised Learning in conversation

2016:

2017:

2018:

2019:

2020:

2021:

# Affective Computing

2016:

2017:

2018:

2019:

2020:

2021:

# Others (NLP)

2016:

2017:

2018:

2019:

2020:

2021:

1. $Dual\;Graph\;Convolutional\;Networks\;for\;Aspect-based\;Sentiment\;Analysis$$\textcolor{Red}{(ACL,\;CCF-A)}$

   $\bullet\;Motivation:$

      最近，在依存树上的图神经网络已经被探索来明确地建模aspects和 opinion words之间的联系。然而，由于依赖性解析结果的不准确性以及在线评论的非正式表达和复杂性，改进范围有限。

   $\bullet\;Method:$

      为了克服这些挑战，本文提出了一种双图卷积网络(DualGCN)模型，能够同时考虑语法结构的互补性和语义相关性。设计了一个具有丰富语法知识的SynGCN模块，来减轻依赖性解析错误。并设计了一个具有自我注意机制的SemGCN模块获取语义相关性。此外，还提出了正交和差分正则化，通过约束SemGCN模块中的 attention分数来精确地捕获单词之间的语义相关性。正交正则化鼓励SemGCN学习语义相关的单词，使得每个单词的重叠较少，差分正则化鼓励SemGCN学习SynGCN没有捕捉到的信息。

   $\bullet\;Experimental\;Result:$

      在三个公共数据集上的实验结果表明，该DualGCN模型优于最先进的方法，并验证了该模型的有效性。**(Written by Yuzhao Chen)**  [(BibTex)](https://aclanthology.org/2021.acl-long.494/)

   

2. $Reinforced\;History\;Backtracking\;for\;Conversational\;Question\;Answering$$\textcolor{Red}{(AAAI,\;CCF-A)}$

   $\bullet\;Motivation:$

      对上下文历史建模是问答系统中的关键步骤。为了利用语境历史，现有的研究往往是将整个语境作为输入，这存在以下两个问题：首先，对长历史进行建模的成本可能很高，因为它需要更多的计算资源。第二，长上下文历史中会包含许多不相关的信息，这使得对目标信息进行建模变的困难。

   $\bullet\;Method:$

      本文针对会话问答（ConvQA）环境下会话历史建模问题，提出了一种新的解决方案。在传统的机器阅读理解（MRC）模型中，加入了一个增强回溯器来过滤不相关的历史，而不是将历史作为一个整体来评估它们。并把会话历史选择问题建模为一个顺序决策过程，该过程可以通过强化学习来解决。通过与预先训练的机器阅读理解(MRC)模型交互，增强回溯器能够生成良好的选择策略。针对稀疏奖励问题，进一步地提出了一种新的训练方案。

   $\bullet\;Experimental\;Result:$

      本文在大型会话问题答疑数据集QuAC上进行了广泛的实验，结果表明，该方法可以帮助缓解由于较长的上下文历史而产生的问题。采用强化学习学习会话历史选择策略有助于提高回答预测性能。**(Written by Yuzhao Chen)** [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-1260.QiuM.pdf)

   

3. $Towards\;Generative\;Aspect-Based\;Sentiment\;Analysis$$\textcolor{Red}{(ACL,\;CCF-A)}$

   $\bullet\;Motivation:$

      大多数现有工作会以区别的方式处理ABSA问题，设计各种特定于任务的分类网络进行预测。 尽管它们很有效，但这些方法忽略了ABSA问题中丰富的标签语义，并且需要广泛的特定于任务的设计。

   $\bullet\;Method:$

      本文提出在一个统一的生成框架中处理各种ABSA任务，通过将自然语言标签编码到目标输出中，可以充分利用丰富的标签语义。此外，这种统一的生成模型可以适应多个任务，不需要引入其他特定于任务的模型设计。并设计了两种类型的样式，即注释式和提取式建模，旨在通过将每个ABSA任务表述为文本生成问题来实现训练过程。给定一个句子，前者在这个句子上添加注释，以便在构建目标句子时包含标签信息；而后者直接采用所需的自然语言标签将输入的句子作为目标。

   $\bullet\;Experimental\;Result:$

      本文在多个基准数据集上对四个ABSA任务进行了实验，提出的方法几乎在所有情况下都超越了以前的最先进的技术。这也验证了所提出框架的强大通用性，该框架可以适应任意ABSA任务。**(Written by Yuzhao Chen)** [(BibTex)](https://aclanthology.org/2021.acl-short.64/)
