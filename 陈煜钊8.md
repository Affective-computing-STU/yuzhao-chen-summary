# Emotion recognition in conversation(ERC)

2016:

2017:

2018

2019:

2020:

2021:

# Recognizing emotion cause

2016：

2017：

2018：

2019：

2020：

2021：



# Commonsense knowledge

2016：

2017：

2018：

2019：

2020：

2021：

# Self-supervised Learning in conversation

2016:

2017:

2018:

2019:

2020:

2021:

# Affective Computing

2016:

2017:

2018:

2019:

2020:

2021:

# Others (NLP)

2016:

2017:

2018:

2019:

2020:

2021:

1. $Dynamic\;Hybrid\;Relation\;Network\;for\;Cross-Domain\;Context-Dependent\;Semantic\;Parsing$$\textcolor{Red}{(AAAI,\;CCF-A)}$

   $\bullet\;Motivation:$

      近年来，交叉领域的上下文关联语义解析已成为一个新的研究热点，这个问题的关键是如何利用交互历史中的自然语言表达和数据库模式的上下文信息。

   $\bullet\;Method:$

     本文提出了一种新的框架，称之为动态图框架，该框架基于动态进化图的结构，能够有效的对上下文语义表达，token，数据库结构以及它们之间的相互作用进行建模，把这些复杂的信息结合起来训练。该框架采用了一种动态记忆衰减机制，结合归纳偏差来整合丰富的上下文关系表示，通过一个强大的重新排序模型来进一步增强，来衡量前面的对话对当前对话是否有影响。

   $\bullet\;Experimental\;Result:$

      本文在两个大规模交叉领域的上下文关联的基准SParC和CoSQL上评估了提出的模型，在两个数据集上都取得了最先进的性能，大大优于所有现有的模型。

   **(Written by Yuzhao Chen)**  [(BibTex)](https://arxiv.org/abs/2101.01686)

   

2. $Keyword-Guided\;Neural\;Conversational\;Model$$\textcolor{Red}{(AAAI,\;CCF-A)}$

   $\bullet\;Motivation:$

      本文研究了在开放域对话代理上施加对话目标/关键词的问题，在这种情况下，需要代理将对话平稳快速地引导到目标关键词。本文提出了关键字选择中现有研究两个局限性：1)训练和评估数据集中多噪声；2)依靠词嵌入之间相似性近目标关键词可能会不可靠。

   $\bullet\;Method:$

      在本文中，作者假设人类对话是基于常识的，并提出了一种关键词引导的神经对话模型，使用外部常识知识图CKG进行关键字转换，并提出了两种基于GNN的模型，将常识知识分别用于下一轮关键字预测和关键字增强响应检索。并提出了一个大规模的从Reddit获得的开放域对话数据集来完成这个任务。

   $\bullet\;Experimental\;Result:$

      大量的实验结果表明，在CKG上的关键字转换提高了整体对话的平滑性，并允许代理更快地到达目标。此外，利用常识性的三元组，还可以大大提高下一轮的关键字预测和关键字增强响应检索的性能。

   **(Written by Yuzhao Chen)** [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-8746.ZhongP.pdf)

   

3. $SMIL\;Multimodal\;Learning\;with\;Severely\;Missing\;Modality$$\textcolor{Red}{(AAAI,\;CCF-A)}$

   $\bullet\;Motivation:$

      多模式学习中，人们往往假设训练数据是完整的，即所有训练实例中每个模态都是完整的。尽管有研究者致力于开发新的方法来解决测试数据的模态不完全性，例如测试集中缺少部分模态，但是很少有人能够处理训练过程中的模态缺失。

   $\bullet\;Method:$

      本文是第一个系统地研究严重缺失模态的多模态学习问题的工作。首次从灵活性和效率两个方面正式研究了缺失模态的多模态学习，灵活性方面是指在训练、测试或两者中都有缺失的模式，效率方面是指大多数训练数据的模态都不完整。从技术上讲，文章提出了一种名为SMIL的新方法，该方法利用贝叶斯元学习统一实现了两个目标。

   $\bullet\;Experimental\;Result:$

      本文在MM-IMDb、CMU-MOSI和avMNIST上进行了大量实验，验证了SMIL能优于包括AE和GAN在内的生成基准线，达到最先进的性能。

   **(Written by Yuzhao Chen)** [(BibTex)](https://www.aaai.org/AAAI21Papers/AAAI-437.MaM.pdf)
